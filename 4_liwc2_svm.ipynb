{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__LIWC__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn import decomposition\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_data(input_data, target, ratio=0.3, rand_state=42):\n",
    "    return train_test_split(input_data, target, test_size=ratio, stratify=target, random_state=rand_state)\n",
    "\n",
    "def apply_grid_search_cv(pipe, param_grid, X_train, y_train, X_test, y_test, print_flag=True, score_matrix=f1_score, n_jobs=-1, cv=5):\n",
    "    grid_search = GridSearchCV(pipe, param_grid=param_grid, scoring=make_scorer(score_matrix), n_jobs=n_jobs, cv=cv)\n",
    "    t0 = time()\n",
    "    res = grid_search.fit(X_train, y_train)\n",
    "    if print_flag:\n",
    "        print(\"done in %0.3fs\" % (time() - t0))\n",
    "        print(\"best params:\")\n",
    "        print(res.best_params_)\n",
    "        print(\"Best cross-validation score: {:.3f}\".format(grid_search.best_score_))\n",
    "        print(\"Test-set score: {:.3f}\".format(grid_search.score(X_test, y_test)))        \n",
    "    return grid_search\n",
    "\n",
    "def save_class_report_cv(grid_search, X_test, y_test, target_names, filename):\n",
    "    y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    df.to_csv(filename)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cross_validation_results(grid_search, filename, print_flag=True):\n",
    "    param_keys = list(grid_search.cv_results_[\"params\"][0].keys())\n",
    "    matrix_list = [\"mean_test_score\", \"std_test_score\", \"rank_test_score\", \"mean_fit_time\"] \n",
    "    col = param_keys + matrix_list\n",
    "\n",
    "    cv_results = []\n",
    "    cv_results.append(col)    \n",
    "    \n",
    "    for param, score, std, rank, time in zip(grid_search.cv_results_[\"params\"], grid_search.cv_results_[\"mean_test_score\"],grid_search.cv_results_[\"std_test_score\"],\n",
    "                                             grid_search.cv_results_[\"rank_test_score\"], grid_search.cv_results_[\"mean_fit_time\"]):\n",
    "        row_item = list(param.values())\n",
    "        row_item.append(score)\n",
    "        row_item.append(std)\n",
    "        row_item.append(rank)\n",
    "        row_item.append(time)\n",
    "        cv_results.append(row_item)\n",
    "        \n",
    "    cv_results = pd.DataFrame(cv_results) \n",
    "    header = cv_results.iloc[0] \n",
    "    cv_results = cv_results[1:]\n",
    "    cv_results = cv_results.rename(columns = header)\n",
    "    cv_results = cv_results.sort_values(by=['rank_test_score'])\n",
    "    cv_results.to_csv(filename)\n",
    "    if print_flag:\n",
    "        print(cv_results.head(6))\n",
    "#        print(cv_results.tail(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels = pd .read_csv(\"data/LIWC2015_mod5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels = hotels.drop(hotels.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deceptive</th>\n",
       "      <th>hotel</th>\n",
       "      <th>polarity</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>lower_case</th>\n",
       "      <th>lc_no_punct</th>\n",
       "      <th>norm</th>\n",
       "      <th>norm_lemma</th>\n",
       "      <th>norm_stem</th>\n",
       "      <th>norm_lemma_stopword</th>\n",
       "      <th>norm_stem_stopword</th>\n",
       "      <th>ADJ_count</th>\n",
       "      <th>ADP_count</th>\n",
       "      <th>ADV_count</th>\n",
       "      <th>AUX_count</th>\n",
       "      <th>CCONJ_count</th>\n",
       "      <th>DET_count</th>\n",
       "      <th>INTJ_count</th>\n",
       "      <th>NOUN_count</th>\n",
       "      <th>NUM_count</th>\n",
       "      <th>PART_count</th>\n",
       "      <th>PRON_count</th>\n",
       "      <th>PROPN_count</th>\n",
       "      <th>PUNCT_count</th>\n",
       "      <th>SCONJ_count</th>\n",
       "      <th>SYM_count</th>\n",
       "      <th>VERB_count</th>\n",
       "      <th>X_count</th>\n",
       "      <th>class</th>\n",
       "      <th>WC</th>\n",
       "      <th>Analytic</th>\n",
       "      <th>Clout</th>\n",
       "      <th>Authentic</th>\n",
       "      <th>Tone</th>\n",
       "      <th>WPS</th>\n",
       "      <th>Sixltr</th>\n",
       "      <th>Dic</th>\n",
       "      <th>function</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>ppron</th>\n",
       "      <th>i</th>\n",
       "      <th>we</th>\n",
       "      <th>you</th>\n",
       "      <th>shehe</th>\n",
       "      <th>they</th>\n",
       "      <th>ipron</th>\n",
       "      <th>article</th>\n",
       "      <th>prep</th>\n",
       "      <th>auxverb</th>\n",
       "      <th>adverb</th>\n",
       "      <th>conj</th>\n",
       "      <th>negate</th>\n",
       "      <th>verb</th>\n",
       "      <th>adj</th>\n",
       "      <th>compare</th>\n",
       "      <th>interrog</th>\n",
       "      <th>number</th>\n",
       "      <th>quant</th>\n",
       "      <th>affect</th>\n",
       "      <th>posemo</th>\n",
       "      <th>negemo</th>\n",
       "      <th>anx</th>\n",
       "      <th>anger</th>\n",
       "      <th>sad</th>\n",
       "      <th>social</th>\n",
       "      <th>family</th>\n",
       "      <th>friend</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>cogproc</th>\n",
       "      <th>insight</th>\n",
       "      <th>cause</th>\n",
       "      <th>discrep</th>\n",
       "      <th>tentat</th>\n",
       "      <th>certain</th>\n",
       "      <th>differ</th>\n",
       "      <th>percept</th>\n",
       "      <th>see</th>\n",
       "      <th>hear</th>\n",
       "      <th>feel</th>\n",
       "      <th>bio</th>\n",
       "      <th>body</th>\n",
       "      <th>health</th>\n",
       "      <th>sexual</th>\n",
       "      <th>ingest</th>\n",
       "      <th>drives</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>achieve</th>\n",
       "      <th>power</th>\n",
       "      <th>reward</th>\n",
       "      <th>risk</th>\n",
       "      <th>focuspast</th>\n",
       "      <th>focuspresent</th>\n",
       "      <th>focusfuture</th>\n",
       "      <th>relativ</th>\n",
       "      <th>motion</th>\n",
       "      <th>space</th>\n",
       "      <th>time</th>\n",
       "      <th>work</th>\n",
       "      <th>leisure</th>\n",
       "      <th>home</th>\n",
       "      <th>money</th>\n",
       "      <th>relig</th>\n",
       "      <th>death</th>\n",
       "      <th>informal</th>\n",
       "      <th>swear</th>\n",
       "      <th>netspeak</th>\n",
       "      <th>assent</th>\n",
       "      <th>nonflu</th>\n",
       "      <th>filler</th>\n",
       "      <th>AllPunc</th>\n",
       "      <th>Period</th>\n",
       "      <th>Comma</th>\n",
       "      <th>Colon</th>\n",
       "      <th>SemiC</th>\n",
       "      <th>QMark</th>\n",
       "      <th>Exclam</th>\n",
       "      <th>Dash</th>\n",
       "      <th>Quote</th>\n",
       "      <th>Apostro</th>\n",
       "      <th>Parenth</th>\n",
       "      <th>OtherP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.00000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.00000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.00000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1596</td>\n",
       "      <td>1596</td>\n",
       "      <td>1596</td>\n",
       "      <td>1596</td>\n",
       "      <td>1596</td>\n",
       "      <td>1596</td>\n",
       "      <td>1596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>allegro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MTurk</td>\n",
       "      <td>My daughter and I woke in the morning wanting ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the omni was chosen for it's location whichwor...</td>\n",
       "      <td>the omni was chosen for it s location whichwor...</td>\n",
       "      <td>the omni was chosen for it s location whichwor...</td>\n",
       "      <td>my daughter and i woke in the morning wanting ...</td>\n",
       "      <td>i d been search for a cool non chain hotel for...</td>\n",
       "      <td>disappointed   stay  chicago monoco   stay ma...</td>\n",
       "      <td>omni wa chosen    locat whichwork  perfectli ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>800</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>806.391250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.099315</td>\n",
       "      <td>0.105465</td>\n",
       "      <td>0.073256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.249986</td>\n",
       "      <td>0.013510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.196686</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>149.373125</td>\n",
       "      <td>71.799387</td>\n",
       "      <td>54.789069</td>\n",
       "      <td>62.433331</td>\n",
       "      <td>66.708150</td>\n",
       "      <td>16.388063</td>\n",
       "      <td>17.162369</td>\n",
       "      <td>88.76245</td>\n",
       "      <td>53.783787</td>\n",
       "      <td>11.534156</td>\n",
       "      <td>7.623800</td>\n",
       "      <td>3.905612</td>\n",
       "      <td>2.055000</td>\n",
       "      <td>0.660881</td>\n",
       "      <td>0.218681</td>\n",
       "      <td>0.783550</td>\n",
       "      <td>3.895581</td>\n",
       "      <td>9.806800</td>\n",
       "      <td>12.801825</td>\n",
       "      <td>8.915756</td>\n",
       "      <td>5.446219</td>\n",
       "      <td>6.384119</td>\n",
       "      <td>1.677969</td>\n",
       "      <td>15.360131</td>\n",
       "      <td>6.050400</td>\n",
       "      <td>2.071431</td>\n",
       "      <td>0.933763</td>\n",
       "      <td>1.591325</td>\n",
       "      <td>1.943287</td>\n",
       "      <td>5.907506</td>\n",
       "      <td>4.553938</td>\n",
       "      <td>1.12075</td>\n",
       "      <td>0.163806</td>\n",
       "      <td>0.199269</td>\n",
       "      <td>0.203594</td>\n",
       "      <td>7.505700</td>\n",
       "      <td>0.359981</td>\n",
       "      <td>0.442594</td>\n",
       "      <td>0.325388</td>\n",
       "      <td>0.327144</td>\n",
       "      <td>8.955763</td>\n",
       "      <td>1.145400</td>\n",
       "      <td>0.797769</td>\n",
       "      <td>1.566944</td>\n",
       "      <td>1.757069</td>\n",
       "      <td>1.761981</td>\n",
       "      <td>2.854931</td>\n",
       "      <td>2.181400</td>\n",
       "      <td>0.910044</td>\n",
       "      <td>0.462844</td>\n",
       "      <td>0.480525</td>\n",
       "      <td>1.801225</td>\n",
       "      <td>0.252956</td>\n",
       "      <td>0.231481</td>\n",
       "      <td>0.010756</td>\n",
       "      <td>1.208150</td>\n",
       "      <td>8.111631</td>\n",
       "      <td>3.241900</td>\n",
       "      <td>1.098881</td>\n",
       "      <td>2.213175</td>\n",
       "      <td>1.785962</td>\n",
       "      <td>0.384556</td>\n",
       "      <td>7.265406</td>\n",
       "      <td>6.288981</td>\n",
       "      <td>0.765519</td>\n",
       "      <td>17.468119</td>\n",
       "      <td>2.915563</td>\n",
       "      <td>11.037831</td>\n",
       "      <td>4.889250</td>\n",
       "      <td>2.436375</td>\n",
       "      <td>3.751388</td>\n",
       "      <td>2.768525</td>\n",
       "      <td>1.240731</td>\n",
       "      <td>0.022150</td>\n",
       "      <td>0.020550</td>\n",
       "      <td>0.406875</td>\n",
       "      <td>0.018712</td>\n",
       "      <td>0.043844</td>\n",
       "      <td>0.149638</td>\n",
       "      <td>0.181806</td>\n",
       "      <td>0.00905</td>\n",
       "      <td>14.055519</td>\n",
       "      <td>6.612544</td>\n",
       "      <td>3.591619</td>\n",
       "      <td>0.087137</td>\n",
       "      <td>0.066175</td>\n",
       "      <td>0.076775</td>\n",
       "      <td>0.767031</td>\n",
       "      <td>0.681212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.280112</td>\n",
       "      <td>0.526700</td>\n",
       "      <td>0.366150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>467.260647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033587</td>\n",
       "      <td>0.026239</td>\n",
       "      <td>0.027617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038522</td>\n",
       "      <td>0.014884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034197</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>1.118384</td>\n",
       "      <td>87.739431</td>\n",
       "      <td>18.697766</td>\n",
       "      <td>25.821830</td>\n",
       "      <td>26.023894</td>\n",
       "      <td>34.070231</td>\n",
       "      <td>7.226241</td>\n",
       "      <td>4.382680</td>\n",
       "      <td>4.14512</td>\n",
       "      <td>5.090643</td>\n",
       "      <td>3.915191</td>\n",
       "      <td>3.297535</td>\n",
       "      <td>3.034989</td>\n",
       "      <td>2.542078</td>\n",
       "      <td>1.105959</td>\n",
       "      <td>0.570362</td>\n",
       "      <td>1.037403</td>\n",
       "      <td>1.975704</td>\n",
       "      <td>2.581639</td>\n",
       "      <td>2.861762</td>\n",
       "      <td>2.497208</td>\n",
       "      <td>2.447376</td>\n",
       "      <td>1.966778</td>\n",
       "      <td>1.399532</td>\n",
       "      <td>3.391309</td>\n",
       "      <td>2.658416</td>\n",
       "      <td>1.498134</td>\n",
       "      <td>0.925727</td>\n",
       "      <td>1.507279</td>\n",
       "      <td>1.403120</td>\n",
       "      <td>2.870457</td>\n",
       "      <td>3.081086</td>\n",
       "      <td>1.28789</td>\n",
       "      <td>0.397944</td>\n",
       "      <td>0.464278</td>\n",
       "      <td>0.424580</td>\n",
       "      <td>4.030817</td>\n",
       "      <td>0.734593</td>\n",
       "      <td>0.696959</td>\n",
       "      <td>0.721457</td>\n",
       "      <td>0.650519</td>\n",
       "      <td>3.416747</td>\n",
       "      <td>1.065891</td>\n",
       "      <td>0.839687</td>\n",
       "      <td>1.235211</td>\n",
       "      <td>1.336183</td>\n",
       "      <td>1.384616</td>\n",
       "      <td>1.940218</td>\n",
       "      <td>1.597797</td>\n",
       "      <td>1.086196</td>\n",
       "      <td>0.745820</td>\n",
       "      <td>0.750665</td>\n",
       "      <td>1.694788</td>\n",
       "      <td>0.488442</td>\n",
       "      <td>0.484716</td>\n",
       "      <td>0.091442</td>\n",
       "      <td>1.498268</td>\n",
       "      <td>3.705509</td>\n",
       "      <td>3.115135</td>\n",
       "      <td>1.071992</td>\n",
       "      <td>1.435299</td>\n",
       "      <td>1.474134</td>\n",
       "      <td>0.623480</td>\n",
       "      <td>3.413554</td>\n",
       "      <td>3.136674</td>\n",
       "      <td>0.876047</td>\n",
       "      <td>4.175587</td>\n",
       "      <td>1.561330</td>\n",
       "      <td>3.249295</td>\n",
       "      <td>2.529072</td>\n",
       "      <td>1.699430</td>\n",
       "      <td>2.162818</td>\n",
       "      <td>1.720677</td>\n",
       "      <td>1.269930</td>\n",
       "      <td>0.142495</td>\n",
       "      <td>0.137384</td>\n",
       "      <td>0.680934</td>\n",
       "      <td>0.124303</td>\n",
       "      <td>0.211320</td>\n",
       "      <td>0.410125</td>\n",
       "      <td>0.454386</td>\n",
       "      <td>0.08024</td>\n",
       "      <td>5.047531</td>\n",
       "      <td>2.942552</td>\n",
       "      <td>2.465118</td>\n",
       "      <td>0.397933</td>\n",
       "      <td>0.322842</td>\n",
       "      <td>0.351067</td>\n",
       "      <td>1.384438</td>\n",
       "      <td>1.239694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.450216</td>\n",
       "      <td>1.094702</td>\n",
       "      <td>0.850661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115942</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>3.860000</td>\n",
       "      <td>3.480000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.230000</td>\n",
       "      <td>5.450000</td>\n",
       "      <td>71.79000</td>\n",
       "      <td>31.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.690000</td>\n",
       "      <td>1.090000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.220000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.540000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>487.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.075330</td>\n",
       "      <td>0.090526</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.223832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>60.275000</td>\n",
       "      <td>32.465000</td>\n",
       "      <td>42.347500</td>\n",
       "      <td>35.755000</td>\n",
       "      <td>12.725000</td>\n",
       "      <td>14.167500</td>\n",
       "      <td>86.30000</td>\n",
       "      <td>50.932500</td>\n",
       "      <td>8.890000</td>\n",
       "      <td>5.327500</td>\n",
       "      <td>1.390000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.610000</td>\n",
       "      <td>8.107500</td>\n",
       "      <td>10.987500</td>\n",
       "      <td>7.280000</td>\n",
       "      <td>3.730000</td>\n",
       "      <td>5.050000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>13.152500</td>\n",
       "      <td>4.210000</td>\n",
       "      <td>1.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.967500</td>\n",
       "      <td>3.920000</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.620000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.630000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.797500</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>1.470000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>0.617500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.230000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.095000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.777500</td>\n",
       "      <td>1.830000</td>\n",
       "      <td>8.847500</td>\n",
       "      <td>3.080000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>1.590000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>10.520000</td>\n",
       "      <td>4.960000</td>\n",
       "      <td>1.740000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.096541</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.072289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.247807</td>\n",
       "      <td>0.010363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>75.015000</td>\n",
       "      <td>54.525000</td>\n",
       "      <td>66.740000</td>\n",
       "      <td>81.230000</td>\n",
       "      <td>15.400000</td>\n",
       "      <td>16.985000</td>\n",
       "      <td>89.12500</td>\n",
       "      <td>54.430000</td>\n",
       "      <td>11.585000</td>\n",
       "      <td>7.765000</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>9.785000</td>\n",
       "      <td>12.850000</td>\n",
       "      <td>8.940000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>6.320000</td>\n",
       "      <td>1.490000</td>\n",
       "      <td>15.380000</td>\n",
       "      <td>5.710000</td>\n",
       "      <td>1.850000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.325000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>5.490000</td>\n",
       "      <td>3.965000</td>\n",
       "      <td>0.82000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.045000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.860000</td>\n",
       "      <td>1.030000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>1.610000</td>\n",
       "      <td>1.540000</td>\n",
       "      <td>2.675000</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.480000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>7.785000</td>\n",
       "      <td>2.455000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>1.520000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.505000</td>\n",
       "      <td>5.850000</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>17.430000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>10.820000</td>\n",
       "      <td>4.710000</td>\n",
       "      <td>2.150000</td>\n",
       "      <td>3.475000</td>\n",
       "      <td>2.610000</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>13.395000</td>\n",
       "      <td>6.095000</td>\n",
       "      <td>3.340000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>987.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.119300</td>\n",
       "      <td>0.121527</td>\n",
       "      <td>0.090109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141747</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.274336</td>\n",
       "      <td>0.020426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>87.052500</td>\n",
       "      <td>77.235000</td>\n",
       "      <td>84.275000</td>\n",
       "      <td>98.870000</td>\n",
       "      <td>18.632500</td>\n",
       "      <td>19.652500</td>\n",
       "      <td>91.55000</td>\n",
       "      <td>57.272500</td>\n",
       "      <td>14.180000</td>\n",
       "      <td>9.880000</td>\n",
       "      <td>5.940000</td>\n",
       "      <td>3.555000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>11.490000</td>\n",
       "      <td>14.750000</td>\n",
       "      <td>10.370000</td>\n",
       "      <td>6.850000</td>\n",
       "      <td>7.612500</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>17.687500</td>\n",
       "      <td>7.485000</td>\n",
       "      <td>2.940000</td>\n",
       "      <td>1.490000</td>\n",
       "      <td>2.352500</td>\n",
       "      <td>2.762500</td>\n",
       "      <td>7.320000</td>\n",
       "      <td>6.435000</td>\n",
       "      <td>1.81000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.232500</td>\n",
       "      <td>10.095000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.352500</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>1.722500</td>\n",
       "      <td>1.290000</td>\n",
       "      <td>2.290000</td>\n",
       "      <td>2.590000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.980000</td>\n",
       "      <td>3.030000</td>\n",
       "      <td>1.430000</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.580000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.870000</td>\n",
       "      <td>10.470000</td>\n",
       "      <td>5.072500</td>\n",
       "      <td>1.632500</td>\n",
       "      <td>3.030000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.702500</td>\n",
       "      <td>9.640000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.220000</td>\n",
       "      <td>20.132500</td>\n",
       "      <td>3.810000</td>\n",
       "      <td>13.060000</td>\n",
       "      <td>6.380000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>4.942500</td>\n",
       "      <td>3.722500</td>\n",
       "      <td>1.850000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>16.670000</td>\n",
       "      <td>7.690000</td>\n",
       "      <td>5.130000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.015000</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.052500</td>\n",
       "      <td>0.682500</td>\n",
       "      <td>0.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4159.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.206522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.418750</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>784.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>36.710000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>67.530000</td>\n",
       "      <td>23.810000</td>\n",
       "      <td>20.950000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>7.530000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>8.570000</td>\n",
       "      <td>13.560000</td>\n",
       "      <td>18.450000</td>\n",
       "      <td>22.730000</td>\n",
       "      <td>19.120000</td>\n",
       "      <td>17.650000</td>\n",
       "      <td>15.620000</td>\n",
       "      <td>10.670000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>10.530000</td>\n",
       "      <td>4.650000</td>\n",
       "      <td>18.030000</td>\n",
       "      <td>8.330000</td>\n",
       "      <td>20.340000</td>\n",
       "      <td>18.870000</td>\n",
       "      <td>9.38000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.560000</td>\n",
       "      <td>3.360000</td>\n",
       "      <td>23.810000</td>\n",
       "      <td>5.660000</td>\n",
       "      <td>5.710000</td>\n",
       "      <td>7.740000</td>\n",
       "      <td>5.690000</td>\n",
       "      <td>23.480000</td>\n",
       "      <td>8.510000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.330000</td>\n",
       "      <td>9.260000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>11.340000</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>6.980000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>4.230000</td>\n",
       "      <td>5.130000</td>\n",
       "      <td>1.720000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>15.150000</td>\n",
       "      <td>10.530000</td>\n",
       "      <td>10.530000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.060000</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>20.690000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>33.330000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.400000</td>\n",
       "      <td>16.480000</td>\n",
       "      <td>13.330000</td>\n",
       "      <td>15.560000</td>\n",
       "      <td>13.240000</td>\n",
       "      <td>7.590000</td>\n",
       "      <td>2.170000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.870000</td>\n",
       "      <td>3.920000</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>1.15000</td>\n",
       "      <td>50.420000</td>\n",
       "      <td>37.820000</td>\n",
       "      <td>26.670000</td>\n",
       "      <td>8.330000</td>\n",
       "      <td>4.850000</td>\n",
       "      <td>5.450000</td>\n",
       "      <td>10.640000</td>\n",
       "      <td>12.680000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.450000</td>\n",
       "      <td>8.890000</td>\n",
       "      <td>6.830000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          deceptive    hotel     polarity source  \\\n",
       "count   1600.000000     1600  1600.000000   1600   \n",
       "unique          NaN       20          NaN      3   \n",
       "top             NaN  allegro          NaN  MTurk   \n",
       "freq            NaN       80          NaN    800   \n",
       "mean       0.500000      NaN     0.500000    NaN   \n",
       "std        0.500156      NaN     0.500156    NaN   \n",
       "min        0.000000      NaN     0.000000    NaN   \n",
       "25%        0.000000      NaN     0.000000    NaN   \n",
       "50%        0.500000      NaN     0.500000    NaN   \n",
       "75%        1.000000      NaN     1.000000    NaN   \n",
       "max        1.000000      NaN     1.000000    NaN   \n",
       "\n",
       "                                                     text  text_length  \\\n",
       "count                                                1600  1600.000000   \n",
       "unique                                               1596          NaN   \n",
       "top     My daughter and I woke in the morning wanting ...          NaN   \n",
       "freq                                                    2          NaN   \n",
       "mean                                                  NaN   806.391250   \n",
       "std                                                   NaN   467.260647   \n",
       "min                                                   NaN   151.000000   \n",
       "25%                                                   NaN   487.000000   \n",
       "50%                                                   NaN   700.000000   \n",
       "75%                                                   NaN   987.500000   \n",
       "max                                                   NaN  4159.000000   \n",
       "\n",
       "                                               lower_case  \\\n",
       "count                                                1600   \n",
       "unique                                               1596   \n",
       "top     the omni was chosen for it's location whichwor...   \n",
       "freq                                                    2   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                              lc_no_punct  \\\n",
       "count                                                1600   \n",
       "unique                                               1596   \n",
       "top     the omni was chosen for it s location whichwor...   \n",
       "freq                                                    2   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                                     norm  \\\n",
       "count                                                1600   \n",
       "unique                                               1596   \n",
       "top     the omni was chosen for it s location whichwor...   \n",
       "freq                                                    2   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                               norm_lemma  \\\n",
       "count                                                1600   \n",
       "unique                                               1596   \n",
       "top     my daughter and i woke in the morning wanting ...   \n",
       "freq                                                    2   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                                norm_stem  \\\n",
       "count                                                1600   \n",
       "unique                                               1596   \n",
       "top     i d been search for a cool non chain hotel for...   \n",
       "freq                                                    2   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                      norm_lemma_stopword  \\\n",
       "count                                                1600   \n",
       "unique                                               1596   \n",
       "top      disappointed   stay  chicago monoco   stay ma...   \n",
       "freq                                                    2   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                       norm_stem_stopword    ADJ_count  \\\n",
       "count                                                1600  1600.000000   \n",
       "unique                                               1596          NaN   \n",
       "top      omni wa chosen    locat whichwork  perfectli ...          NaN   \n",
       "freq                                                    2          NaN   \n",
       "mean                                                  NaN     0.099315   \n",
       "std                                                   NaN     0.033587   \n",
       "min                                                   NaN     0.019048   \n",
       "25%                                                   NaN     0.075330   \n",
       "50%                                                   NaN     0.096541   \n",
       "75%                                                   NaN     0.119300   \n",
       "max                                                   NaN     0.266667   \n",
       "\n",
       "          ADP_count    ADV_count  AUX_count  CCONJ_count    DET_count  \\\n",
       "count   1600.000000  1600.000000     1600.0       1600.0  1600.000000   \n",
       "unique          NaN          NaN        NaN          NaN          NaN   \n",
       "top             NaN          NaN        NaN          NaN          NaN   \n",
       "freq            NaN          NaN        NaN          NaN          NaN   \n",
       "mean       0.105465     0.073256        0.0          0.0     0.124403   \n",
       "std        0.026239     0.027617        0.0          0.0     0.028481   \n",
       "min        0.000000     0.000000        0.0          0.0     0.000000   \n",
       "25%        0.090526     0.054348        0.0          0.0     0.106557   \n",
       "50%        0.106667     0.072289        0.0          0.0     0.124160   \n",
       "75%        0.121527     0.090109        0.0          0.0     0.141747   \n",
       "max        0.192308     0.206522        0.0          0.0     0.236842   \n",
       "\n",
       "        INTJ_count   NOUN_count    NUM_count  PART_count   PRON_count  \\\n",
       "count       1600.0  1600.000000  1600.000000      1600.0  1600.000000   \n",
       "unique         NaN          NaN          NaN         NaN          NaN   \n",
       "top            NaN          NaN          NaN         NaN          NaN   \n",
       "freq           NaN          NaN          NaN         NaN          NaN   \n",
       "mean           0.0     0.249986     0.013510         0.0     0.063546   \n",
       "std            0.0     0.038522     0.014884         0.0     0.030471   \n",
       "min            0.0     0.115942     0.000000         0.0     0.000000   \n",
       "25%            0.0     0.223832     0.000000         0.0     0.041667   \n",
       "50%            0.0     0.247807     0.010363         0.0     0.061377   \n",
       "75%            0.0     0.274336     0.020426         0.0     0.083333   \n",
       "max            0.0     0.418750     0.180328         0.0     0.228571   \n",
       "\n",
       "        PROPN_count  PUNCT_count  SCONJ_count  SYM_count   VERB_count  \\\n",
       "count        1600.0       1600.0       1600.0     1600.0  1600.000000   \n",
       "unique          NaN          NaN          NaN        NaN          NaN   \n",
       "top             NaN          NaN          NaN        NaN          NaN   \n",
       "freq            NaN          NaN          NaN        NaN          NaN   \n",
       "mean            0.0          0.0          0.0        0.0     0.196686   \n",
       "std             0.0          0.0          0.0        0.0     0.034197   \n",
       "min             0.0          0.0          0.0        0.0     0.043478   \n",
       "25%             0.0          0.0          0.0        0.0     0.175676   \n",
       "50%             0.0          0.0          0.0        0.0     0.197346   \n",
       "75%             0.0          0.0          0.0        0.0     0.220000   \n",
       "max             0.0          0.0          0.0        0.0     0.315789   \n",
       "\n",
       "            X_count        class           WC     Analytic        Clout  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.000160     2.500000   149.373125    71.799387    54.789069   \n",
       "std        0.001135     1.118384    87.739431    18.697766    25.821830   \n",
       "min        0.000000     1.000000    25.000000     3.860000     3.480000   \n",
       "25%        0.000000     1.750000    89.000000    60.275000    32.465000   \n",
       "50%        0.000000     2.500000   128.000000    75.015000    54.525000   \n",
       "75%        0.000000     3.250000   183.000000    87.052500    77.235000   \n",
       "max        0.015625     4.000000   784.000000    99.000000    99.000000   \n",
       "\n",
       "          Authentic         Tone          WPS       Sixltr         Dic  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.000000  1600.00000   \n",
       "unique          NaN          NaN          NaN          NaN         NaN   \n",
       "top             NaN          NaN          NaN          NaN         NaN   \n",
       "freq            NaN          NaN          NaN          NaN         NaN   \n",
       "mean      62.433331    66.708150    16.388063    17.162369    88.76245   \n",
       "std       26.023894    34.070231     7.226241     4.382680     4.14512   \n",
       "min        1.000000     1.000000     5.230000     5.450000    71.79000   \n",
       "25%       42.347500    35.755000    12.725000    14.167500    86.30000   \n",
       "50%       66.740000    81.230000    15.400000    16.985000    89.12500   \n",
       "75%       84.275000    98.870000    18.632500    19.652500    91.55000   \n",
       "max       99.000000    99.000000    97.000000    36.710000   100.00000   \n",
       "\n",
       "           function      pronoun        ppron            i           we  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      53.783787    11.534156     7.623800     3.905612     2.055000   \n",
       "std        5.090643     3.915191     3.297535     3.034989     2.542078   \n",
       "min       31.750000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       50.932500     8.890000     5.327500     1.390000     0.000000   \n",
       "50%       54.430000    11.585000     7.765000     3.450000     0.935000   \n",
       "75%       57.272500    14.180000     9.880000     5.940000     3.555000   \n",
       "max       67.530000    23.810000    20.950000    15.000000    12.000000   \n",
       "\n",
       "                you        shehe         they        ipron      article  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.660881     0.218681     0.783550     3.895581     9.806800   \n",
       "std        1.105959     0.570362     1.037403     1.975704     2.581639   \n",
       "min        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%        0.000000     0.000000     0.000000     2.610000     8.107500   \n",
       "50%        0.000000     0.000000     0.490000     3.750000     9.785000   \n",
       "75%        0.980000     0.000000     1.200000     5.000000    11.490000   \n",
       "max        7.530000     6.500000     8.570000    13.560000    18.450000   \n",
       "\n",
       "               prep      auxverb       adverb         conj       negate  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      12.801825     8.915756     5.446219     6.384119     1.677969   \n",
       "std        2.861762     2.497208     2.447376     1.966778     1.399532   \n",
       "min        1.690000     1.090000     0.000000     0.000000     0.000000   \n",
       "25%       10.987500     7.280000     3.730000     5.050000     0.687500   \n",
       "50%       12.850000     8.940000     5.260000     6.320000     1.490000   \n",
       "75%       14.750000    10.370000     6.850000     7.612500     2.500000   \n",
       "max       22.730000    19.120000    17.650000    15.620000    10.670000   \n",
       "\n",
       "               verb          adj      compare     interrog       number  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      15.360131     6.050400     2.071431     0.933763     1.591325   \n",
       "std        3.391309     2.658416     1.498134     0.925727     1.507279   \n",
       "min        2.220000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       13.152500     4.210000     1.020000     0.000000     0.430000   \n",
       "50%       15.380000     5.710000     1.850000     0.800000     1.325000   \n",
       "75%       17.687500     7.485000     2.940000     1.490000     2.352500   \n",
       "max       27.500000    19.050000    10.530000     4.650000    18.030000   \n",
       "\n",
       "              quant       affect       posemo      negemo          anx  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.00000  1600.000000   \n",
       "unique          NaN          NaN          NaN         NaN          NaN   \n",
       "top             NaN          NaN          NaN         NaN          NaN   \n",
       "freq            NaN          NaN          NaN         NaN          NaN   \n",
       "mean       1.943287     5.907506     4.553938     1.12075     0.163806   \n",
       "std        1.403120     2.870457     3.081086     1.28789     0.397944   \n",
       "min        0.000000     0.000000     0.000000     0.00000     0.000000   \n",
       "25%        0.967500     3.920000     2.210000     0.00000     0.000000   \n",
       "50%        1.750000     5.490000     3.965000     0.82000     0.000000   \n",
       "75%        2.762500     7.320000     6.435000     1.81000     0.000000   \n",
       "max        8.330000    20.340000    18.870000     9.38000     5.000000   \n",
       "\n",
       "              anger          sad       social       family       friend  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.199269     0.203594     7.505700     0.359981     0.442594   \n",
       "std        0.464278     0.424580     4.030817     0.734593     0.696959   \n",
       "min        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%        0.000000     0.000000     4.620000     0.000000     0.000000   \n",
       "50%        0.000000     0.000000     7.045000     0.000000     0.000000   \n",
       "75%        0.000000     0.232500    10.095000     0.510000     0.760000   \n",
       "max        5.560000     3.360000    23.810000     5.660000     5.710000   \n",
       "\n",
       "             female         male      cogproc      insight        cause  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.325388     0.327144     8.955763     1.145400     0.797769   \n",
       "std        0.721457     0.650519     3.416747     1.065891     0.839687   \n",
       "min        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%        0.000000     0.000000     6.630000     0.000000     0.000000   \n",
       "50%        0.000000     0.000000     8.860000     1.030000     0.690000   \n",
       "75%        0.352500     0.480000    11.110000     1.722500     1.290000   \n",
       "max        7.740000     5.690000    23.480000     8.510000     4.600000   \n",
       "\n",
       "            discrep       tentat      certain       differ      percept  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       1.566944     1.757069     1.761981     2.854931     2.181400   \n",
       "std        1.235211     1.336183     1.384616     1.940218     1.597797   \n",
       "min        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%        0.690000     0.797500     0.810000     1.470000     1.100000   \n",
       "50%        1.450000     1.610000     1.540000     2.675000     1.950000   \n",
       "75%        2.290000     2.590000     2.500000     3.980000     3.030000   \n",
       "max        8.000000     8.330000     9.260000    12.500000    11.340000   \n",
       "\n",
       "                see         hear         feel          bio         body  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.910044     0.462844     0.480525     1.801225     0.252956   \n",
       "std        1.086196     0.745820     0.750665     1.694788     0.488442   \n",
       "min        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%        0.000000     0.000000     0.000000     0.577500     0.000000   \n",
       "50%        0.690000     0.000000     0.000000     1.480000     0.000000   \n",
       "75%        1.430000     0.780000     0.800000     2.580000     0.400000   \n",
       "max        8.250000     6.800000     6.980000    12.500000     4.230000   \n",
       "\n",
       "             health       sexual       ingest       drives  affiliation  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.231481     0.010756     1.208150     8.111631     3.241900   \n",
       "std        0.484716     0.091442     1.498268     3.705509     3.115135   \n",
       "min        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%        0.000000     0.000000     0.000000     5.260000     0.617500   \n",
       "50%        0.000000     0.000000     0.790000     7.785000     2.455000   \n",
       "75%        0.320000     0.000000     1.870000    10.470000     5.072500   \n",
       "max        5.130000     1.720000    12.500000    24.000000    15.150000   \n",
       "\n",
       "            achieve        power       reward         risk    focuspast  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       1.098881     2.213175     1.785962     0.384556     7.265406   \n",
       "std        1.071992     1.435299     1.474134     0.623480     3.413554   \n",
       "min        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%        0.000000     1.230000     0.760000     0.000000     5.000000   \n",
       "50%        0.950000     2.020000     1.520000     0.000000     7.505000   \n",
       "75%        1.632500     3.030000     2.500000     0.702500     9.640000   \n",
       "max       10.530000    10.530000    10.000000     6.060000    18.750000   \n",
       "\n",
       "        focuspresent  focusfuture      relativ       motion        space  \\\n",
       "count    1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "unique           NaN          NaN          NaN          NaN          NaN   \n",
       "top              NaN          NaN          NaN          NaN          NaN   \n",
       "freq             NaN          NaN          NaN          NaN          NaN   \n",
       "mean        6.288981     0.765519    17.468119     2.915563    11.037831   \n",
       "std         3.136674     0.876047     4.175587     1.561330     3.249295   \n",
       "min         0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%         4.095000     0.000000    14.777500     1.830000     8.847500   \n",
       "50%         5.850000     0.590000    17.430000     2.780000    10.820000   \n",
       "75%         8.000000     1.220000    20.132500     3.810000    13.060000   \n",
       "max        20.690000     7.270000    33.330000    10.000000    23.400000   \n",
       "\n",
       "               time         work      leisure         home        money  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       4.889250     2.436375     3.751388     2.768525     1.240731   \n",
       "std        2.529072     1.699430     2.162818     1.720677     1.269930   \n",
       "min        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%        3.080000     1.270000     2.200000     1.590000     0.000000   \n",
       "50%        4.710000     2.150000     3.475000     2.610000     0.970000   \n",
       "75%        6.380000     3.230000     4.942500     3.722500     1.850000   \n",
       "max       16.480000    13.330000    15.560000    13.240000     7.590000   \n",
       "\n",
       "              relig        death     informal        swear     netspeak  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.022150     0.020550     0.406875     0.018712     0.043844   \n",
       "std        0.142495     0.137384     0.680934     0.124303     0.211320   \n",
       "min        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%        0.000000     0.000000     0.680000     0.000000     0.000000   \n",
       "max        2.170000     1.750000     6.250000     2.000000     2.870000   \n",
       "\n",
       "             assent       nonflu      filler      AllPunc       Period  \\\n",
       "count   1600.000000  1600.000000  1600.00000  1600.000000  1600.000000   \n",
       "unique          NaN          NaN         NaN          NaN          NaN   \n",
       "top             NaN          NaN         NaN          NaN          NaN   \n",
       "freq            NaN          NaN         NaN          NaN          NaN   \n",
       "mean       0.149638     0.181806     0.00905    14.055519     6.612544   \n",
       "std        0.410125     0.454386     0.08024     5.047531     2.942552   \n",
       "min        0.000000     0.000000     0.00000     1.540000     0.000000   \n",
       "25%        0.000000     0.000000     0.00000    10.520000     4.960000   \n",
       "50%        0.000000     0.000000     0.00000    13.395000     6.095000   \n",
       "75%        0.000000     0.000000     0.00000    16.670000     7.690000   \n",
       "max        3.920000     6.250000     1.15000    50.420000    37.820000   \n",
       "\n",
       "              Comma        Colon        SemiC        QMark       Exclam  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       3.591619     0.087137     0.066175     0.076775     0.767031   \n",
       "std        2.465118     0.397933     0.322842     0.351067     1.384438   \n",
       "min        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%        1.740000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%        3.340000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%        5.130000     0.000000     0.000000     0.000000     1.015000   \n",
       "max       26.670000     8.330000     4.850000     5.450000    10.640000   \n",
       "\n",
       "               Dash   Quote      Apostro      Parenth       OtherP  \n",
       "count   1600.000000  1600.0  1600.000000  1600.000000  1600.000000  \n",
       "unique          NaN     NaN          NaN          NaN          NaN  \n",
       "top             NaN     NaN          NaN          NaN          NaN  \n",
       "freq            NaN     NaN          NaN          NaN          NaN  \n",
       "mean       0.681212     0.0     1.280112     0.526700     0.366150  \n",
       "std        1.239694     0.0     1.450216     1.094702     0.850661  \n",
       "min        0.000000     0.0     0.000000     0.000000     0.000000  \n",
       "25%        0.000000     0.0     0.000000     0.000000     0.000000  \n",
       "50%        0.000000     0.0     0.920000     0.000000     0.000000  \n",
       "75%        1.010000     0.0     2.052500     0.682500     0.380000  \n",
       "max       12.680000     0.0    10.450000     8.890000     6.830000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotels.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc = hotels.loc[:, \"WC\":\"OtherP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WC</th>\n",
       "      <th>Analytic</th>\n",
       "      <th>Clout</th>\n",
       "      <th>Authentic</th>\n",
       "      <th>Tone</th>\n",
       "      <th>WPS</th>\n",
       "      <th>Sixltr</th>\n",
       "      <th>Dic</th>\n",
       "      <th>function</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>ppron</th>\n",
       "      <th>i</th>\n",
       "      <th>we</th>\n",
       "      <th>you</th>\n",
       "      <th>shehe</th>\n",
       "      <th>they</th>\n",
       "      <th>ipron</th>\n",
       "      <th>article</th>\n",
       "      <th>prep</th>\n",
       "      <th>auxverb</th>\n",
       "      <th>adverb</th>\n",
       "      <th>conj</th>\n",
       "      <th>negate</th>\n",
       "      <th>verb</th>\n",
       "      <th>adj</th>\n",
       "      <th>compare</th>\n",
       "      <th>interrog</th>\n",
       "      <th>number</th>\n",
       "      <th>quant</th>\n",
       "      <th>affect</th>\n",
       "      <th>posemo</th>\n",
       "      <th>negemo</th>\n",
       "      <th>anx</th>\n",
       "      <th>anger</th>\n",
       "      <th>sad</th>\n",
       "      <th>social</th>\n",
       "      <th>family</th>\n",
       "      <th>friend</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>cogproc</th>\n",
       "      <th>insight</th>\n",
       "      <th>cause</th>\n",
       "      <th>discrep</th>\n",
       "      <th>tentat</th>\n",
       "      <th>certain</th>\n",
       "      <th>differ</th>\n",
       "      <th>percept</th>\n",
       "      <th>see</th>\n",
       "      <th>hear</th>\n",
       "      <th>feel</th>\n",
       "      <th>bio</th>\n",
       "      <th>body</th>\n",
       "      <th>health</th>\n",
       "      <th>sexual</th>\n",
       "      <th>ingest</th>\n",
       "      <th>drives</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>achieve</th>\n",
       "      <th>power</th>\n",
       "      <th>reward</th>\n",
       "      <th>risk</th>\n",
       "      <th>focuspast</th>\n",
       "      <th>focuspresent</th>\n",
       "      <th>focusfuture</th>\n",
       "      <th>relativ</th>\n",
       "      <th>motion</th>\n",
       "      <th>space</th>\n",
       "      <th>time</th>\n",
       "      <th>work</th>\n",
       "      <th>leisure</th>\n",
       "      <th>home</th>\n",
       "      <th>money</th>\n",
       "      <th>relig</th>\n",
       "      <th>death</th>\n",
       "      <th>informal</th>\n",
       "      <th>swear</th>\n",
       "      <th>netspeak</th>\n",
       "      <th>assent</th>\n",
       "      <th>nonflu</th>\n",
       "      <th>filler</th>\n",
       "      <th>AllPunc</th>\n",
       "      <th>Period</th>\n",
       "      <th>Comma</th>\n",
       "      <th>Colon</th>\n",
       "      <th>SemiC</th>\n",
       "      <th>QMark</th>\n",
       "      <th>Exclam</th>\n",
       "      <th>Dash</th>\n",
       "      <th>Quote</th>\n",
       "      <th>Apostro</th>\n",
       "      <th>Parenth</th>\n",
       "      <th>OtherP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>61.61</td>\n",
       "      <td>61.05</td>\n",
       "      <td>35.01</td>\n",
       "      <td>77.39</td>\n",
       "      <td>13.38</td>\n",
       "      <td>13.08</td>\n",
       "      <td>82.24</td>\n",
       "      <td>49.53</td>\n",
       "      <td>6.54</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>7.48</td>\n",
       "      <td>10.28</td>\n",
       "      <td>10.28</td>\n",
       "      <td>9.35</td>\n",
       "      <td>6.54</td>\n",
       "      <td>1.87</td>\n",
       "      <td>12.15</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.93</td>\n",
       "      <td>4.67</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.54</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.74</td>\n",
       "      <td>6.54</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.35</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.95</td>\n",
       "      <td>1.87</td>\n",
       "      <td>8.41</td>\n",
       "      <td>6.54</td>\n",
       "      <td>0.93</td>\n",
       "      <td>3.74</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.82</td>\n",
       "      <td>11.21</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>97.59</td>\n",
       "      <td>41.03</td>\n",
       "      <td>19.82</td>\n",
       "      <td>94.75</td>\n",
       "      <td>8.80</td>\n",
       "      <td>29.55</td>\n",
       "      <td>77.27</td>\n",
       "      <td>31.82</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.27</td>\n",
       "      <td>6.82</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.55</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.82</td>\n",
       "      <td>13.64</td>\n",
       "      <td>6.82</td>\n",
       "      <td>2.27</td>\n",
       "      <td>2.27</td>\n",
       "      <td>6.82</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.27</td>\n",
       "      <td>6.82</td>\n",
       "      <td>6.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.27</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.64</td>\n",
       "      <td>2.27</td>\n",
       "      <td>11.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.55</td>\n",
       "      <td>6.82</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>11.36</td>\n",
       "      <td>9.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    WC  Analytic  Clout  Authentic   Tone    WPS  Sixltr    Dic  function  \\\n",
       "0  107     61.61  61.05      35.01  77.39  13.38   13.08  82.24     49.53   \n",
       "1   44     97.59  41.03      19.82  94.75   8.80   29.55  77.27     31.82   \n",
       "\n",
       "   pronoun  ppron     i    we   you  shehe  they  ipron  article   prep  \\\n",
       "0     6.54   3.74  0.93  1.87  0.93    0.0   0.0   2.80     7.48  10.28   \n",
       "1     2.27   0.00  0.00  0.00  0.00    0.0   0.0   2.27     6.82  13.64   \n",
       "\n",
       "   auxverb  adverb  conj  negate   verb    adj  compare  interrog  number  \\\n",
       "0    10.28    9.35  6.54    1.87  12.15   3.74     0.00      0.00    4.67   \n",
       "1     4.55    4.55  2.27    0.00   6.82  13.64     6.82      2.27    2.27   \n",
       "\n",
       "   quant  affect  posemo  negemo  anx  anger  sad  social  family  friend  \\\n",
       "0   0.93    4.67    3.74    0.93  0.0    0.0  0.0    6.54    0.93     0.0   \n",
       "1   6.82    4.55    4.55    0.00  0.0    0.0  0.0    0.00    0.00     0.0   \n",
       "\n",
       "   female  male  cogproc  insight  cause  discrep  tentat  certain  differ  \\\n",
       "0     0.0   0.0     5.61      0.0    0.0     0.93    0.00     0.93    3.74   \n",
       "1     0.0   0.0     4.55      0.0    0.0     0.00    2.27     0.00    2.27   \n",
       "\n",
       "   percept   see  hear  feel   bio  body  health  sexual  ingest  drives  \\\n",
       "0     0.00  0.00   0.0   0.0  3.74   0.0     0.0     0.0    3.74    6.54   \n",
       "1     6.82  6.82   0.0   0.0  4.55   0.0     0.0     0.0    4.55    4.55   \n",
       "\n",
       "   affiliation  achieve  power  reward  risk  focuspast  focuspresent  \\\n",
       "0         3.74     0.93   0.93    1.87   0.0       9.35          1.87   \n",
       "1         0.00     0.00   2.27    2.27   0.0       6.82          0.00   \n",
       "\n",
       "   focusfuture  relativ  motion  space  time  work  leisure  home  money  \\\n",
       "0          0.0    14.95    1.87   8.41  6.54  0.93     3.74  2.80   1.87   \n",
       "1          0.0    13.64    2.27  11.36  0.00  4.55     4.55  6.82   2.27   \n",
       "\n",
       "   relig  death  informal  swear  netspeak  assent  nonflu  filler  AllPunc  \\\n",
       "0    0.0    0.0       0.0    0.0       0.0     0.0     0.0     0.0    16.82   \n",
       "1    0.0    0.0       0.0    0.0       0.0     0.0     0.0     0.0    25.00   \n",
       "\n",
       "   Period  Comma  Colon  SemiC  QMark  Exclam  Dash  Quote  Apostro  Parenth  \\\n",
       "0   11.21   1.87    0.0    0.0    0.0     0.0   0.0      0      0.0     3.74   \n",
       "1   11.36   9.09    0.0    0.0    0.0     0.0   0.0      0      0.0     0.00   \n",
       "\n",
       "   OtherP  \n",
       "0    0.00  \n",
       "1    4.55  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liwc.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WC', 'Analytic', 'Clout', 'Authentic', 'Tone', 'WPS', 'Sixltr', 'Dic',\n",
       "       'function', 'pronoun', 'ppron', 'i', 'we', 'you', 'shehe', 'they',\n",
       "       'ipron', 'article', 'prep', 'auxverb', 'adverb', 'conj', 'negate',\n",
       "       'verb', 'adj', 'compare', 'interrog', 'number', 'quant', 'affect',\n",
       "       'posemo', 'negemo', 'anx', 'anger', 'sad', 'social', 'family', 'friend',\n",
       "       'female', 'male', 'cogproc', 'insight', 'cause', 'discrep', 'tentat',\n",
       "       'certain', 'differ', 'percept', 'see', 'hear', 'feel', 'bio', 'body',\n",
       "       'health', 'sexual', 'ingest', 'drives', 'affiliation', 'achieve',\n",
       "       'power', 'reward', 'risk', 'focuspast', 'focuspresent', 'focusfuture',\n",
       "       'relativ', 'motion', 'space', 'time', 'work', 'leisure', 'home',\n",
       "       'money', 'relig', 'death', 'informal', 'swear', 'netspeak', 'assent',\n",
       "       'nonflu', 'filler', 'AllPunc', 'Period', 'Comma', 'Colon', 'SemiC',\n",
       "       'QMark', 'Exclam', 'Dash', 'Quote', 'Apostro', 'Parenth', 'OtherP'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liwc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(liwc.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. Choose input data and target__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = liwc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = hotels[\"deceptive\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. Split data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_train_test_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3. Build pipeline__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_svm = [\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', SVC()),\n",
    "]\n",
    "\n",
    "pipe_svm = Pipeline(steps_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4. Construct parameters for cross validation testing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_svm = [\n",
    "    {       \n",
    "        'clf__kernel': ['rbf'], 'clf__C': [10, 100], \n",
    "         'clf__gamma': [0.01, 0.1]}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__5. Apply Grid Serach CV__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 3.958s\n",
      "best params:\n",
      "{'clf__C': 100, 'clf__gamma': 0.01, 'clf__kernel': 'rbf'}\n",
      "Best cross-validation score: 0.771\n",
      "Test-set score: 0.750\n"
     ]
    }
   ],
   "source": [
    "svm_grid_search = apply_grid_search_cv(pipe_svm, param_grid_svm, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__6. Save Classification Report to File__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>truthful</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deceptive</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1-score  precision  recall  support\n",
       "truthful          0.75       0.75    0.75    240.0\n",
       "deceptive         0.75       0.75    0.75    240.0\n",
       "micro avg         0.75       0.75    0.75    480.0\n",
       "macro avg         0.75       0.75    0.75    480.0\n",
       "weighted avg      0.75       0.75    0.75    480.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_class_report_cv(svm_grid_search, X_test, y_test, [\"truthful\", \"deceptive\"], \"output/svm_liwc1_report.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  clf__C clf__gamma clf__kernel mean_test_score std_test_score  \\\n",
      "3    100       0.01         rbf        0.770545      0.0209934   \n",
      "1     10       0.01         rbf        0.769851      0.0204686   \n",
      "2     10        0.1         rbf        0.626371      0.0921483   \n",
      "4    100        0.1         rbf        0.626371      0.0921483   \n",
      "\n",
      "  rank_test_score mean_fit_time  \n",
      "3               1      0.176827  \n",
      "1               2       0.18311  \n",
      "2               3      0.186729  \n",
      "4               3      0.147308  \n"
     ]
    }
   ],
   "source": [
    "save_cross_validation_results(svm_grid_search, \"output/svm_liwc1_validation_res.csv\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__7. Save model to file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['output/svm_liwc1.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(svm_grid_search.best_estimator_, 'output/svm_liwc1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__8. Sentiment Analysis__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.942s\n",
      "best params:\n",
      "{'clf__C': 10, 'clf__gamma': 0.01, 'clf__kernel': 'rbf'}\n",
      "Best cross-validation score: 0.892\n",
      "Test-set score: 0.873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "y = hotels[\"polarity\"]\n",
    "X_train, X_test, y_train, y_test = split_train_test_data(X, y)\n",
    "svm_grid_search_p = apply_grid_search_cv(pipe_svm, param_grid_svm, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  clf__C clf__gamma clf__kernel mean_test_score std_test_score  \\\n",
      "1     10       0.01         rbf        0.892358      0.0136111   \n",
      "3    100       0.01         rbf        0.892179      0.0137926   \n",
      "2     10        0.1         rbf        0.768246       0.018295   \n",
      "4    100        0.1         rbf        0.768246       0.018295   \n",
      "\n",
      "  rank_test_score mean_fit_time  \n",
      "1               1      0.112298  \n",
      "3               2      0.103919  \n",
      "2               3      0.180516  \n",
      "4               3      0.160171  \n"
     ]
    }
   ],
   "source": [
    "save_cross_validation_results(svm_grid_search_p, \"output/svm_liwc_sent_validation_res.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>0.873181</td>\n",
       "      <td>0.871369</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.872651</td>\n",
       "      <td>0.874477</td>\n",
       "      <td>0.870833</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.872917</td>\n",
       "      <td>0.872917</td>\n",
       "      <td>0.872917</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.872916</td>\n",
       "      <td>0.872923</td>\n",
       "      <td>0.872917</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.872916</td>\n",
       "      <td>0.872923</td>\n",
       "      <td>0.872917</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1-score  precision    recall  support\n",
       "negative      0.873181   0.871369  0.875000    240.0\n",
       "positive      0.872651   0.874477  0.870833    240.0\n",
       "micro avg     0.872917   0.872917  0.872917    480.0\n",
       "macro avg     0.872916   0.872923  0.872917    480.0\n",
       "weighted avg  0.872916   0.872923  0.872917    480.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_class_report_cv(svm_grid_search_p, X_test, y_test, [\"negative\", \"positive\"], \"output/svm_liwc_report_sent.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Combined TFIDF with LIWC Analysis__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>norm</th>\n",
       "      <th>WC</th>\n",
       "      <th>Analytic</th>\n",
       "      <th>Clout</th>\n",
       "      <th>Authentic</th>\n",
       "      <th>Tone</th>\n",
       "      <th>WPS</th>\n",
       "      <th>Sixltr</th>\n",
       "      <th>Dic</th>\n",
       "      <th>function</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>ppron</th>\n",
       "      <th>i</th>\n",
       "      <th>we</th>\n",
       "      <th>you</th>\n",
       "      <th>shehe</th>\n",
       "      <th>they</th>\n",
       "      <th>ipron</th>\n",
       "      <th>article</th>\n",
       "      <th>prep</th>\n",
       "      <th>auxverb</th>\n",
       "      <th>adverb</th>\n",
       "      <th>conj</th>\n",
       "      <th>negate</th>\n",
       "      <th>verb</th>\n",
       "      <th>adj</th>\n",
       "      <th>compare</th>\n",
       "      <th>interrog</th>\n",
       "      <th>number</th>\n",
       "      <th>quant</th>\n",
       "      <th>affect</th>\n",
       "      <th>posemo</th>\n",
       "      <th>negemo</th>\n",
       "      <th>anx</th>\n",
       "      <th>anger</th>\n",
       "      <th>sad</th>\n",
       "      <th>social</th>\n",
       "      <th>family</th>\n",
       "      <th>friend</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>cogproc</th>\n",
       "      <th>insight</th>\n",
       "      <th>cause</th>\n",
       "      <th>discrep</th>\n",
       "      <th>tentat</th>\n",
       "      <th>certain</th>\n",
       "      <th>differ</th>\n",
       "      <th>percept</th>\n",
       "      <th>see</th>\n",
       "      <th>hear</th>\n",
       "      <th>feel</th>\n",
       "      <th>bio</th>\n",
       "      <th>body</th>\n",
       "      <th>health</th>\n",
       "      <th>sexual</th>\n",
       "      <th>ingest</th>\n",
       "      <th>drives</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>achieve</th>\n",
       "      <th>power</th>\n",
       "      <th>reward</th>\n",
       "      <th>risk</th>\n",
       "      <th>focuspast</th>\n",
       "      <th>focuspresent</th>\n",
       "      <th>focusfuture</th>\n",
       "      <th>relativ</th>\n",
       "      <th>motion</th>\n",
       "      <th>space</th>\n",
       "      <th>time</th>\n",
       "      <th>work</th>\n",
       "      <th>leisure</th>\n",
       "      <th>home</th>\n",
       "      <th>money</th>\n",
       "      <th>relig</th>\n",
       "      <th>death</th>\n",
       "      <th>informal</th>\n",
       "      <th>swear</th>\n",
       "      <th>netspeak</th>\n",
       "      <th>assent</th>\n",
       "      <th>nonflu</th>\n",
       "      <th>filler</th>\n",
       "      <th>AllPunc</th>\n",
       "      <th>Period</th>\n",
       "      <th>Comma</th>\n",
       "      <th>Colon</th>\n",
       "      <th>SemiC</th>\n",
       "      <th>QMark</th>\n",
       "      <th>Exclam</th>\n",
       "      <th>Dash</th>\n",
       "      <th>Quote</th>\n",
       "      <th>Apostro</th>\n",
       "      <th>Parenth</th>\n",
       "      <th>OtherP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we stayed for a one night getaway with family ...</td>\n",
       "      <td>107</td>\n",
       "      <td>61.61</td>\n",
       "      <td>61.05</td>\n",
       "      <td>35.01</td>\n",
       "      <td>77.39</td>\n",
       "      <td>13.38</td>\n",
       "      <td>13.08</td>\n",
       "      <td>82.24</td>\n",
       "      <td>49.53</td>\n",
       "      <td>6.54</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>7.48</td>\n",
       "      <td>10.28</td>\n",
       "      <td>10.28</td>\n",
       "      <td>9.35</td>\n",
       "      <td>6.54</td>\n",
       "      <td>1.87</td>\n",
       "      <td>12.15</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.93</td>\n",
       "      <td>4.67</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.54</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.74</td>\n",
       "      <td>6.54</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.35</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.95</td>\n",
       "      <td>1.87</td>\n",
       "      <td>8.41</td>\n",
       "      <td>6.54</td>\n",
       "      <td>0.93</td>\n",
       "      <td>3.74</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.82</td>\n",
       "      <td>11.21</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>triple a rate with upgrade to view room was le...</td>\n",
       "      <td>44</td>\n",
       "      <td>97.59</td>\n",
       "      <td>41.03</td>\n",
       "      <td>19.82</td>\n",
       "      <td>94.75</td>\n",
       "      <td>8.80</td>\n",
       "      <td>29.55</td>\n",
       "      <td>77.27</td>\n",
       "      <td>31.82</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.27</td>\n",
       "      <td>6.82</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.55</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.82</td>\n",
       "      <td>13.64</td>\n",
       "      <td>6.82</td>\n",
       "      <td>2.27</td>\n",
       "      <td>2.27</td>\n",
       "      <td>6.82</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.27</td>\n",
       "      <td>6.82</td>\n",
       "      <td>6.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.27</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.64</td>\n",
       "      <td>2.27</td>\n",
       "      <td>11.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.55</td>\n",
       "      <td>6.82</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>11.36</td>\n",
       "      <td>9.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                norm   WC  Analytic  Clout  \\\n",
       "0  we stayed for a one night getaway with family ...  107     61.61  61.05   \n",
       "1  triple a rate with upgrade to view room was le...   44     97.59  41.03   \n",
       "\n",
       "   Authentic   Tone    WPS  Sixltr    Dic  function  pronoun  ppron     i  \\\n",
       "0      35.01  77.39  13.38   13.08  82.24     49.53     6.54   3.74  0.93   \n",
       "1      19.82  94.75   8.80   29.55  77.27     31.82     2.27   0.00  0.00   \n",
       "\n",
       "     we   you  shehe  they  ipron  article   prep  auxverb  adverb  conj  \\\n",
       "0  1.87  0.93    0.0   0.0   2.80     7.48  10.28    10.28    9.35  6.54   \n",
       "1  0.00  0.00    0.0   0.0   2.27     6.82  13.64     4.55    4.55  2.27   \n",
       "\n",
       "   negate   verb    adj  compare  interrog  number  quant  affect  posemo  \\\n",
       "0    1.87  12.15   3.74     0.00      0.00    4.67   0.93    4.67    3.74   \n",
       "1    0.00   6.82  13.64     6.82      2.27    2.27   6.82    4.55    4.55   \n",
       "\n",
       "   negemo  anx  anger  sad  social  family  friend  female  male  cogproc  \\\n",
       "0    0.93  0.0    0.0  0.0    6.54    0.93     0.0     0.0   0.0     5.61   \n",
       "1    0.00  0.0    0.0  0.0    0.00    0.00     0.0     0.0   0.0     4.55   \n",
       "\n",
       "   insight  cause  discrep  tentat  certain  differ  percept   see  hear  \\\n",
       "0      0.0    0.0     0.93    0.00     0.93    3.74     0.00  0.00   0.0   \n",
       "1      0.0    0.0     0.00    2.27     0.00    2.27     6.82  6.82   0.0   \n",
       "\n",
       "   feel   bio  body  health  sexual  ingest  drives  affiliation  achieve  \\\n",
       "0   0.0  3.74   0.0     0.0     0.0    3.74    6.54         3.74     0.93   \n",
       "1   0.0  4.55   0.0     0.0     0.0    4.55    4.55         0.00     0.00   \n",
       "\n",
       "   power  reward  risk  focuspast  focuspresent  focusfuture  relativ  motion  \\\n",
       "0   0.93    1.87   0.0       9.35          1.87          0.0    14.95    1.87   \n",
       "1   2.27    2.27   0.0       6.82          0.00          0.0    13.64    2.27   \n",
       "\n",
       "   space  time  work  leisure  home  money  relig  death  informal  swear  \\\n",
       "0   8.41  6.54  0.93     3.74  2.80   1.87    0.0    0.0       0.0    0.0   \n",
       "1  11.36  0.00  4.55     4.55  6.82   2.27    0.0    0.0       0.0    0.0   \n",
       "\n",
       "   netspeak  assent  nonflu  filler  AllPunc  Period  Comma  Colon  SemiC  \\\n",
       "0       0.0     0.0     0.0     0.0    16.82   11.21   1.87    0.0    0.0   \n",
       "1       0.0     0.0     0.0     0.0    25.00   11.36   9.09    0.0    0.0   \n",
       "\n",
       "   QMark  Exclam  Dash  Quote  Apostro  Parenth  OtherP  \n",
       "0    0.0     0.0   0.0      0      0.0     3.74    0.00  \n",
       "1    0.0     0.0   0.0      0      0.0     0.00    4.55  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotels_comb = pd.concat([hotels[\"norm\"], liwc], axis=1)\n",
    "hotels_comb.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. Choose input data and target__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hotels_comb\n",
    "y = hotels[\"deceptive\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. Split data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_train_test_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3. Build pipeline__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4. Construct parameters for cross validation testing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemExcluder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_frame):\n",
    "        #df = data_frame.loc[:, data_frame.columns != self.key]\n",
    "        df = data_frame.drop([self.key], axis=1)\n",
    "        return df\n",
    "    \n",
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_frame):\n",
    "        df = data_frame[self.key]\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_combined = [\n",
    "    ('preprocess', FeatureUnion(\n",
    "        transformer_list=[\n",
    "            ('terms', Pipeline([\n",
    "                ('selector', ItemSelector(key='norm')),\n",
    "                ('vect', CountVectorizer()),                \n",
    "                ('tfidf', TfidfTransformer())\n",
    "            ])),\n",
    "            ('liwc', Pipeline([\n",
    "                ('selector', ItemExcluder(key='norm')),         \n",
    "                ('scale', StandardScaler())\n",
    "            ]))                        \n",
    "        ]    \n",
    "    )),        \n",
    "    ('clf', SVC())\n",
    "]\n",
    "\n",
    "pipe_comb = Pipeline(steps_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_comb = [\n",
    "    {'preprocess__terms__vect__stop_words': ['english', None],\n",
    "        'preprocess__terms__vect__min_df': [1, 2], \n",
    "        'preprocess__terms__vect__ngram_range': [(1, 2), (1, 3)],    \n",
    "        'clf__kernel': ['rbf'], \n",
    "         'clf__gamma': [0.01, 0.1],\n",
    "         'clf__C': [1, 10, 100]}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__5. Apply Grid Serach CV__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 153.009s\n",
      "best params:\n",
      "{'clf__C': 1, 'clf__gamma': 0.01, 'clf__kernel': 'rbf', 'preprocess__terms__vect__min_df': 2, 'preprocess__terms__vect__ngram_range': (1, 3), 'preprocess__terms__vect__stop_words': 'english'}\n",
      "Best cross-validation score: 0.789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-set score: 0.799\n"
     ]
    }
   ],
   "source": [
    "svm_comb_grid_search = apply_grid_search_cv(pipe_comb, param_grid_comb, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__6. Save Reports to File__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  clf__C clf__gamma clf__kernel preprocess__terms__vect__min_df  \\\n",
      "7      1       0.01         rbf                               2   \n",
      "5      1       0.01         rbf                               2   \n",
      "6      1       0.01         rbf                               2   \n",
      "1      1       0.01         rbf                               1   \n",
      "2      1       0.01         rbf                               1   \n",
      "3      1       0.01         rbf                               1   \n",
      "\n",
      "  preprocess__terms__vect__ngram_range preprocess__terms__vect__stop_words  \\\n",
      "7                               (1, 3)                             english   \n",
      "5                               (1, 2)                             english   \n",
      "6                               (1, 2)                                None   \n",
      "1                               (1, 2)                             english   \n",
      "2                               (1, 2)                                None   \n",
      "3                               (1, 3)                             english   \n",
      "\n",
      "  mean_test_score std_test_score rank_test_score mean_fit_time  \n",
      "7        0.788715      0.0145636               1       2.10996  \n",
      "5        0.787656      0.0140143               2       1.56425  \n",
      "6        0.787243       0.014744               3       2.86181  \n",
      "1        0.786541      0.0143673               4        1.4593  \n",
      "2        0.786541      0.0143673               4       2.38943  \n",
      "3        0.786541      0.0143673               4       2.04387  \n"
     ]
    }
   ],
   "source": [
    "save_cross_validation_results(svm_comb_grid_search, \"output/svm_lwic_comb1_validation_res.csv\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>truthful</th>\n",
       "      <td>0.783550</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.754167</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deceptive</th>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.771318</td>\n",
       "      <td>0.829167</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.791373</td>\n",
       "      <td>0.793317</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.791373</td>\n",
       "      <td>0.793317</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1-score  precision    recall  support\n",
       "truthful      0.783550   0.815315  0.754167    240.0\n",
       "deceptive     0.799197   0.771318  0.829167    240.0\n",
       "micro avg     0.791667   0.791667  0.791667    480.0\n",
       "macro avg     0.791373   0.793317  0.791667    480.0\n",
       "weighted avg  0.791373   0.793317  0.791667    480.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_class_report_cv(svm_comb_grid_search, X_test, y_test, [\"truthful\", \"deceptive\"], \"output/svm_lwic_comb1_report.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__7. Save model to file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['output/svm_lwic_comb1.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(svm_comb_grid_search.best_estimator_, 'output/svm_lwic_comb1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__8. Sentiment__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 125.580s\n",
      "best params:\n",
      "{'clf__C': 1, 'clf__gamma': 0.01, 'clf__kernel': 'rbf', 'preprocess__terms__vect__min_df': 1, 'preprocess__terms__vect__ngram_range': (1, 2), 'preprocess__terms__vect__stop_words': 'english'}\n",
      "Best cross-validation score: 0.904\n",
      "Test-set score: 0.892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "y = hotels[\"polarity\"]\n",
    "X_train, X_test, y_train, y_test = split_train_test_data(X, y)\n",
    "grid_search_p = apply_grid_search_cv(pipe_comb, param_grid_comb, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  clf__C clf__gamma clf__kernel preprocess__terms__vect__min_df  \\\n",
      "1      1       0.01         rbf                               1   \n",
      "2      1       0.01         rbf                               1   \n",
      "3      1       0.01         rbf                               1   \n",
      "4      1       0.01         rbf                               1   \n",
      "5      1       0.01         rbf                               2   \n",
      "6      1       0.01         rbf                               2   \n",
      "\n",
      "  preprocess__terms__vect__ngram_range preprocess__terms__vect__stop_words  \\\n",
      "1                               (1, 2)                             english   \n",
      "2                               (1, 2)                                None   \n",
      "3                               (1, 3)                             english   \n",
      "4                               (1, 3)                                None   \n",
      "5                               (1, 2)                             english   \n",
      "6                               (1, 2)                                None   \n",
      "\n",
      "  mean_test_score std_test_score rank_test_score mean_fit_time  \n",
      "1         0.90403      0.0091795               1       1.07676  \n",
      "2         0.90403      0.0091795               1       1.71524  \n",
      "3         0.90403      0.0091795               1       1.59834  \n",
      "4         0.90403      0.0091795               1       2.87455  \n",
      "5         0.90403      0.0091795               1      0.947877  \n",
      "6         0.90403      0.0091795               1       1.53871  \n"
     ]
    }
   ],
   "source": [
    "save_cross_validation_results(grid_search_p, \"output/svm_lwic_comb1_validation_res_sent.csv\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>0.895277</td>\n",
       "      <td>0.882591</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.892178</td>\n",
       "      <td>0.905579</td>\n",
       "      <td>0.879167</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.893750</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.893727</td>\n",
       "      <td>0.894085</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.893727</td>\n",
       "      <td>0.894085</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1-score  precision    recall  support\n",
       "negative      0.895277   0.882591  0.908333    240.0\n",
       "positive      0.892178   0.905579  0.879167    240.0\n",
       "micro avg     0.893750   0.893750  0.893750    480.0\n",
       "macro avg     0.893727   0.894085  0.893750    480.0\n",
       "weighted avg  0.893727   0.894085  0.893750    480.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_class_report_cv(grid_search_p, X_test, y_test, [\"negative\", \"positive\"], \"output/svm_lwic_comb1_report_sent.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thesis]",
   "language": "python",
   "name": "conda-env-thesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
