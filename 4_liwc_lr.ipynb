{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__LIWC with Logistic Regression__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn import decomposition\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_data(input_data, target, ratio=0.3, rand_state=42):\n",
    "    return train_test_split(input_data, target, test_size=ratio, stratify=target, random_state=rand_state)\n",
    "\n",
    "def apply_grid_search_cv(pipe, param_grid, X_train, y_train, X_test, y_test, print_flag=True, score_matrix=f1_score, n_jobs=-1, cv=5):\n",
    "    grid_search = GridSearchCV(pipe, param_grid=param_grid, scoring=make_scorer(score_matrix), n_jobs=n_jobs, cv=cv)\n",
    "    t0 = time()\n",
    "    res = grid_search.fit(X_train, y_train)\n",
    "    if print_flag:\n",
    "        print(\"done in %0.3fs\" % (time() - t0))\n",
    "        print(\"best params:\")\n",
    "        print(res.best_params_)\n",
    "        print(\"Best cross-validation score: {:.3f}\".format(grid_search.best_score_))\n",
    "        print(\"Test-set score: {:.3f}\".format(grid_search.score(X_test, y_test)))        \n",
    "    return grid_search\n",
    "\n",
    "def save_class_report_cv(grid_search, X_test, y_test, target_names, filename):\n",
    "    y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    df.to_csv(filename)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cross_validation_results(grid_search, filename, print_flag=True):\n",
    "    param_keys = list(grid_search.cv_results_[\"params\"][0].keys())\n",
    "    matrix_list = [\"mean_test_score\", \"std_test_score\", \"rank_test_score\", \"mean_fit_time\"] \n",
    "    col = param_keys + matrix_list\n",
    "\n",
    "    cv_results = []\n",
    "    cv_results.append(col)    \n",
    "    \n",
    "    for param, score, std, rank, time in zip(grid_search.cv_results_[\"params\"], grid_search.cv_results_[\"mean_test_score\"],grid_search.cv_results_[\"std_test_score\"],\n",
    "                                             grid_search.cv_results_[\"rank_test_score\"], grid_search.cv_results_[\"mean_fit_time\"]):\n",
    "        row_item = list(param.values())\n",
    "        row_item.append(score)\n",
    "        row_item.append(std)\n",
    "        row_item.append(rank)\n",
    "        row_item.append(time)\n",
    "        cv_results.append(row_item)\n",
    "        \n",
    "    cv_results = pd.DataFrame(cv_results) \n",
    "    header = cv_results.iloc[0] \n",
    "    cv_results = cv_results[1:]\n",
    "    cv_results = cv_results.rename(columns = header)\n",
    "    cv_results = cv_results.sort_values(by=['rank_test_score'])\n",
    "    cv_results.to_csv(filename)\n",
    "    if print_flag:\n",
    "        print(cv_results.head(6))\n",
    "#        print(cv_results.tail(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels = pd .read_csv(\"data/LIWC2015_mod5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels = hotels.drop(hotels.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deceptive</th>\n",
       "      <th>hotel</th>\n",
       "      <th>polarity</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>lower_case</th>\n",
       "      <th>lc_no_punct</th>\n",
       "      <th>norm</th>\n",
       "      <th>norm_lemma</th>\n",
       "      <th>norm_stem</th>\n",
       "      <th>norm_lemma_stopword</th>\n",
       "      <th>norm_stem_stopword</th>\n",
       "      <th>ADJ_count</th>\n",
       "      <th>ADP_count</th>\n",
       "      <th>ADV_count</th>\n",
       "      <th>AUX_count</th>\n",
       "      <th>CCONJ_count</th>\n",
       "      <th>DET_count</th>\n",
       "      <th>INTJ_count</th>\n",
       "      <th>NOUN_count</th>\n",
       "      <th>NUM_count</th>\n",
       "      <th>PART_count</th>\n",
       "      <th>PRON_count</th>\n",
       "      <th>PROPN_count</th>\n",
       "      <th>PUNCT_count</th>\n",
       "      <th>SCONJ_count</th>\n",
       "      <th>SYM_count</th>\n",
       "      <th>VERB_count</th>\n",
       "      <th>X_count</th>\n",
       "      <th>class</th>\n",
       "      <th>WC</th>\n",
       "      <th>Analytic</th>\n",
       "      <th>Clout</th>\n",
       "      <th>Authentic</th>\n",
       "      <th>Tone</th>\n",
       "      <th>WPS</th>\n",
       "      <th>Sixltr</th>\n",
       "      <th>Dic</th>\n",
       "      <th>function</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>ppron</th>\n",
       "      <th>i</th>\n",
       "      <th>we</th>\n",
       "      <th>you</th>\n",
       "      <th>shehe</th>\n",
       "      <th>they</th>\n",
       "      <th>ipron</th>\n",
       "      <th>article</th>\n",
       "      <th>prep</th>\n",
       "      <th>auxverb</th>\n",
       "      <th>adverb</th>\n",
       "      <th>conj</th>\n",
       "      <th>negate</th>\n",
       "      <th>verb</th>\n",
       "      <th>adj</th>\n",
       "      <th>compare</th>\n",
       "      <th>interrog</th>\n",
       "      <th>number</th>\n",
       "      <th>quant</th>\n",
       "      <th>affect</th>\n",
       "      <th>posemo</th>\n",
       "      <th>negemo</th>\n",
       "      <th>anx</th>\n",
       "      <th>anger</th>\n",
       "      <th>sad</th>\n",
       "      <th>social</th>\n",
       "      <th>family</th>\n",
       "      <th>friend</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>cogproc</th>\n",
       "      <th>insight</th>\n",
       "      <th>cause</th>\n",
       "      <th>discrep</th>\n",
       "      <th>tentat</th>\n",
       "      <th>certain</th>\n",
       "      <th>differ</th>\n",
       "      <th>percept</th>\n",
       "      <th>see</th>\n",
       "      <th>hear</th>\n",
       "      <th>feel</th>\n",
       "      <th>bio</th>\n",
       "      <th>body</th>\n",
       "      <th>health</th>\n",
       "      <th>sexual</th>\n",
       "      <th>ingest</th>\n",
       "      <th>drives</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>achieve</th>\n",
       "      <th>power</th>\n",
       "      <th>reward</th>\n",
       "      <th>risk</th>\n",
       "      <th>focuspast</th>\n",
       "      <th>focuspresent</th>\n",
       "      <th>focusfuture</th>\n",
       "      <th>relativ</th>\n",
       "      <th>motion</th>\n",
       "      <th>space</th>\n",
       "      <th>time</th>\n",
       "      <th>work</th>\n",
       "      <th>leisure</th>\n",
       "      <th>home</th>\n",
       "      <th>money</th>\n",
       "      <th>relig</th>\n",
       "      <th>death</th>\n",
       "      <th>informal</th>\n",
       "      <th>swear</th>\n",
       "      <th>netspeak</th>\n",
       "      <th>assent</th>\n",
       "      <th>nonflu</th>\n",
       "      <th>filler</th>\n",
       "      <th>AllPunc</th>\n",
       "      <th>Period</th>\n",
       "      <th>Comma</th>\n",
       "      <th>Colon</th>\n",
       "      <th>SemiC</th>\n",
       "      <th>QMark</th>\n",
       "      <th>Exclam</th>\n",
       "      <th>Dash</th>\n",
       "      <th>Quote</th>\n",
       "      <th>Apostro</th>\n",
       "      <th>Parenth</th>\n",
       "      <th>OtherP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.00000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.00000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.00000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1596</td>\n",
       "      <td>1596</td>\n",
       "      <td>1596</td>\n",
       "      <td>1596</td>\n",
       "      <td>1596</td>\n",
       "      <td>1596</td>\n",
       "      <td>1596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>palmer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MTurk</td>\n",
       "      <td>I'd been searching for a cool, non-chain hotel...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my daughter and i woke in the morning wanting ...</td>\n",
       "      <td>the omni was chosen for it s location whichwor...</td>\n",
       "      <td>the omni was chosen for it s location whichwor...</td>\n",
       "      <td>very disappointed in our stay in chicago monoc...</td>\n",
       "      <td>veri disappoint in our stay in chicago monoco ...</td>\n",
       "      <td>search   cool non chain hotel   weekend get...</td>\n",
       "      <td>omni wa chosen    locat whichwork  perfectli ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>800</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>806.391250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.099315</td>\n",
       "      <td>0.105465</td>\n",
       "      <td>0.073256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.249986</td>\n",
       "      <td>0.013510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.196686</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>149.373125</td>\n",
       "      <td>71.799387</td>\n",
       "      <td>54.789069</td>\n",
       "      <td>62.433331</td>\n",
       "      <td>66.708150</td>\n",
       "      <td>16.388063</td>\n",
       "      <td>17.162369</td>\n",
       "      <td>88.76245</td>\n",
       "      <td>53.783787</td>\n",
       "      <td>11.534156</td>\n",
       "      <td>7.623800</td>\n",
       "      <td>3.905612</td>\n",
       "      <td>2.055000</td>\n",
       "      <td>0.660881</td>\n",
       "      <td>0.218681</td>\n",
       "      <td>0.783550</td>\n",
       "      <td>3.895581</td>\n",
       "      <td>9.806800</td>\n",
       "      <td>12.801825</td>\n",
       "      <td>8.915756</td>\n",
       "      <td>5.446219</td>\n",
       "      <td>6.384119</td>\n",
       "      <td>1.677969</td>\n",
       "      <td>15.360131</td>\n",
       "      <td>6.050400</td>\n",
       "      <td>2.071431</td>\n",
       "      <td>0.933763</td>\n",
       "      <td>1.591325</td>\n",
       "      <td>1.943287</td>\n",
       "      <td>5.907506</td>\n",
       "      <td>4.553938</td>\n",
       "      <td>1.12075</td>\n",
       "      <td>0.163806</td>\n",
       "      <td>0.199269</td>\n",
       "      <td>0.203594</td>\n",
       "      <td>7.505700</td>\n",
       "      <td>0.359981</td>\n",
       "      <td>0.442594</td>\n",
       "      <td>0.325388</td>\n",
       "      <td>0.327144</td>\n",
       "      <td>8.955763</td>\n",
       "      <td>1.145400</td>\n",
       "      <td>0.797769</td>\n",
       "      <td>1.566944</td>\n",
       "      <td>1.757069</td>\n",
       "      <td>1.761981</td>\n",
       "      <td>2.854931</td>\n",
       "      <td>2.181400</td>\n",
       "      <td>0.910044</td>\n",
       "      <td>0.462844</td>\n",
       "      <td>0.480525</td>\n",
       "      <td>1.801225</td>\n",
       "      <td>0.252956</td>\n",
       "      <td>0.231481</td>\n",
       "      <td>0.010756</td>\n",
       "      <td>1.208150</td>\n",
       "      <td>8.111631</td>\n",
       "      <td>3.241900</td>\n",
       "      <td>1.098881</td>\n",
       "      <td>2.213175</td>\n",
       "      <td>1.785962</td>\n",
       "      <td>0.384556</td>\n",
       "      <td>7.265406</td>\n",
       "      <td>6.288981</td>\n",
       "      <td>0.765519</td>\n",
       "      <td>17.468119</td>\n",
       "      <td>2.915563</td>\n",
       "      <td>11.037831</td>\n",
       "      <td>4.889250</td>\n",
       "      <td>2.436375</td>\n",
       "      <td>3.751388</td>\n",
       "      <td>2.768525</td>\n",
       "      <td>1.240731</td>\n",
       "      <td>0.022150</td>\n",
       "      <td>0.020550</td>\n",
       "      <td>0.406875</td>\n",
       "      <td>0.018712</td>\n",
       "      <td>0.043844</td>\n",
       "      <td>0.149638</td>\n",
       "      <td>0.181806</td>\n",
       "      <td>0.00905</td>\n",
       "      <td>14.055519</td>\n",
       "      <td>6.612544</td>\n",
       "      <td>3.591619</td>\n",
       "      <td>0.087137</td>\n",
       "      <td>0.066175</td>\n",
       "      <td>0.076775</td>\n",
       "      <td>0.767031</td>\n",
       "      <td>0.681212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.280112</td>\n",
       "      <td>0.526700</td>\n",
       "      <td>0.366150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>467.260647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033587</td>\n",
       "      <td>0.026239</td>\n",
       "      <td>0.027617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038522</td>\n",
       "      <td>0.014884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034197</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>1.118384</td>\n",
       "      <td>87.739431</td>\n",
       "      <td>18.697766</td>\n",
       "      <td>25.821830</td>\n",
       "      <td>26.023894</td>\n",
       "      <td>34.070231</td>\n",
       "      <td>7.226241</td>\n",
       "      <td>4.382680</td>\n",
       "      <td>4.14512</td>\n",
       "      <td>5.090643</td>\n",
       "      <td>3.915191</td>\n",
       "      <td>3.297535</td>\n",
       "      <td>3.034989</td>\n",
       "      <td>2.542078</td>\n",
       "      <td>1.105959</td>\n",
       "      <td>0.570362</td>\n",
       "      <td>1.037403</td>\n",
       "      <td>1.975704</td>\n",
       "      <td>2.581639</td>\n",
       "      <td>2.861762</td>\n",
       "      <td>2.497208</td>\n",
       "      <td>2.447376</td>\n",
       "      <td>1.966778</td>\n",
       "      <td>1.399532</td>\n",
       "      <td>3.391309</td>\n",
       "      <td>2.658416</td>\n",
       "      <td>1.498134</td>\n",
       "      <td>0.925727</td>\n",
       "      <td>1.507279</td>\n",
       "      <td>1.403120</td>\n",
       "      <td>2.870457</td>\n",
       "      <td>3.081086</td>\n",
       "      <td>1.28789</td>\n",
       "      <td>0.397944</td>\n",
       "      <td>0.464278</td>\n",
       "      <td>0.424580</td>\n",
       "      <td>4.030817</td>\n",
       "      <td>0.734593</td>\n",
       "      <td>0.696959</td>\n",
       "      <td>0.721457</td>\n",
       "      <td>0.650519</td>\n",
       "      <td>3.416747</td>\n",
       "      <td>1.065891</td>\n",
       "      <td>0.839687</td>\n",
       "      <td>1.235211</td>\n",
       "      <td>1.336183</td>\n",
       "      <td>1.384616</td>\n",
       "      <td>1.940218</td>\n",
       "      <td>1.597797</td>\n",
       "      <td>1.086196</td>\n",
       "      <td>0.745820</td>\n",
       "      <td>0.750665</td>\n",
       "      <td>1.694788</td>\n",
       "      <td>0.488442</td>\n",
       "      <td>0.484716</td>\n",
       "      <td>0.091442</td>\n",
       "      <td>1.498268</td>\n",
       "      <td>3.705509</td>\n",
       "      <td>3.115135</td>\n",
       "      <td>1.071992</td>\n",
       "      <td>1.435299</td>\n",
       "      <td>1.474134</td>\n",
       "      <td>0.623480</td>\n",
       "      <td>3.413554</td>\n",
       "      <td>3.136674</td>\n",
       "      <td>0.876047</td>\n",
       "      <td>4.175587</td>\n",
       "      <td>1.561330</td>\n",
       "      <td>3.249295</td>\n",
       "      <td>2.529072</td>\n",
       "      <td>1.699430</td>\n",
       "      <td>2.162818</td>\n",
       "      <td>1.720677</td>\n",
       "      <td>1.269930</td>\n",
       "      <td>0.142495</td>\n",
       "      <td>0.137384</td>\n",
       "      <td>0.680934</td>\n",
       "      <td>0.124303</td>\n",
       "      <td>0.211320</td>\n",
       "      <td>0.410125</td>\n",
       "      <td>0.454386</td>\n",
       "      <td>0.08024</td>\n",
       "      <td>5.047531</td>\n",
       "      <td>2.942552</td>\n",
       "      <td>2.465118</td>\n",
       "      <td>0.397933</td>\n",
       "      <td>0.322842</td>\n",
       "      <td>0.351067</td>\n",
       "      <td>1.384438</td>\n",
       "      <td>1.239694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.450216</td>\n",
       "      <td>1.094702</td>\n",
       "      <td>0.850661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115942</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>3.860000</td>\n",
       "      <td>3.480000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.230000</td>\n",
       "      <td>5.450000</td>\n",
       "      <td>71.79000</td>\n",
       "      <td>31.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.690000</td>\n",
       "      <td>1.090000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.220000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.540000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>487.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.075330</td>\n",
       "      <td>0.090526</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.223832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>60.275000</td>\n",
       "      <td>32.465000</td>\n",
       "      <td>42.347500</td>\n",
       "      <td>35.755000</td>\n",
       "      <td>12.725000</td>\n",
       "      <td>14.167500</td>\n",
       "      <td>86.30000</td>\n",
       "      <td>50.932500</td>\n",
       "      <td>8.890000</td>\n",
       "      <td>5.327500</td>\n",
       "      <td>1.390000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.610000</td>\n",
       "      <td>8.107500</td>\n",
       "      <td>10.987500</td>\n",
       "      <td>7.280000</td>\n",
       "      <td>3.730000</td>\n",
       "      <td>5.050000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>13.152500</td>\n",
       "      <td>4.210000</td>\n",
       "      <td>1.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.967500</td>\n",
       "      <td>3.920000</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.620000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.630000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.797500</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>1.470000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>0.617500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.230000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.095000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.777500</td>\n",
       "      <td>1.830000</td>\n",
       "      <td>8.847500</td>\n",
       "      <td>3.080000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>1.590000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>10.520000</td>\n",
       "      <td>4.960000</td>\n",
       "      <td>1.740000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.096541</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.072289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.247807</td>\n",
       "      <td>0.010363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>75.015000</td>\n",
       "      <td>54.525000</td>\n",
       "      <td>66.740000</td>\n",
       "      <td>81.230000</td>\n",
       "      <td>15.400000</td>\n",
       "      <td>16.985000</td>\n",
       "      <td>89.12500</td>\n",
       "      <td>54.430000</td>\n",
       "      <td>11.585000</td>\n",
       "      <td>7.765000</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>9.785000</td>\n",
       "      <td>12.850000</td>\n",
       "      <td>8.940000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>6.320000</td>\n",
       "      <td>1.490000</td>\n",
       "      <td>15.380000</td>\n",
       "      <td>5.710000</td>\n",
       "      <td>1.850000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.325000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>5.490000</td>\n",
       "      <td>3.965000</td>\n",
       "      <td>0.82000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.045000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.860000</td>\n",
       "      <td>1.030000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>1.610000</td>\n",
       "      <td>1.540000</td>\n",
       "      <td>2.675000</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.480000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>7.785000</td>\n",
       "      <td>2.455000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>1.520000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.505000</td>\n",
       "      <td>5.850000</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>17.430000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>10.820000</td>\n",
       "      <td>4.710000</td>\n",
       "      <td>2.150000</td>\n",
       "      <td>3.475000</td>\n",
       "      <td>2.610000</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>13.395000</td>\n",
       "      <td>6.095000</td>\n",
       "      <td>3.340000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>987.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.119300</td>\n",
       "      <td>0.121527</td>\n",
       "      <td>0.090109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141747</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.274336</td>\n",
       "      <td>0.020426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>87.052500</td>\n",
       "      <td>77.235000</td>\n",
       "      <td>84.275000</td>\n",
       "      <td>98.870000</td>\n",
       "      <td>18.632500</td>\n",
       "      <td>19.652500</td>\n",
       "      <td>91.55000</td>\n",
       "      <td>57.272500</td>\n",
       "      <td>14.180000</td>\n",
       "      <td>9.880000</td>\n",
       "      <td>5.940000</td>\n",
       "      <td>3.555000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>11.490000</td>\n",
       "      <td>14.750000</td>\n",
       "      <td>10.370000</td>\n",
       "      <td>6.850000</td>\n",
       "      <td>7.612500</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>17.687500</td>\n",
       "      <td>7.485000</td>\n",
       "      <td>2.940000</td>\n",
       "      <td>1.490000</td>\n",
       "      <td>2.352500</td>\n",
       "      <td>2.762500</td>\n",
       "      <td>7.320000</td>\n",
       "      <td>6.435000</td>\n",
       "      <td>1.81000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.232500</td>\n",
       "      <td>10.095000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.352500</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>1.722500</td>\n",
       "      <td>1.290000</td>\n",
       "      <td>2.290000</td>\n",
       "      <td>2.590000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.980000</td>\n",
       "      <td>3.030000</td>\n",
       "      <td>1.430000</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.580000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.870000</td>\n",
       "      <td>10.470000</td>\n",
       "      <td>5.072500</td>\n",
       "      <td>1.632500</td>\n",
       "      <td>3.030000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.702500</td>\n",
       "      <td>9.640000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.220000</td>\n",
       "      <td>20.132500</td>\n",
       "      <td>3.810000</td>\n",
       "      <td>13.060000</td>\n",
       "      <td>6.380000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>4.942500</td>\n",
       "      <td>3.722500</td>\n",
       "      <td>1.850000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>16.670000</td>\n",
       "      <td>7.690000</td>\n",
       "      <td>5.130000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.015000</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.052500</td>\n",
       "      <td>0.682500</td>\n",
       "      <td>0.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4159.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.206522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.418750</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>784.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>36.710000</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>67.530000</td>\n",
       "      <td>23.810000</td>\n",
       "      <td>20.950000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>7.530000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>8.570000</td>\n",
       "      <td>13.560000</td>\n",
       "      <td>18.450000</td>\n",
       "      <td>22.730000</td>\n",
       "      <td>19.120000</td>\n",
       "      <td>17.650000</td>\n",
       "      <td>15.620000</td>\n",
       "      <td>10.670000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>10.530000</td>\n",
       "      <td>4.650000</td>\n",
       "      <td>18.030000</td>\n",
       "      <td>8.330000</td>\n",
       "      <td>20.340000</td>\n",
       "      <td>18.870000</td>\n",
       "      <td>9.38000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.560000</td>\n",
       "      <td>3.360000</td>\n",
       "      <td>23.810000</td>\n",
       "      <td>5.660000</td>\n",
       "      <td>5.710000</td>\n",
       "      <td>7.740000</td>\n",
       "      <td>5.690000</td>\n",
       "      <td>23.480000</td>\n",
       "      <td>8.510000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.330000</td>\n",
       "      <td>9.260000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>11.340000</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>6.980000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>4.230000</td>\n",
       "      <td>5.130000</td>\n",
       "      <td>1.720000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>15.150000</td>\n",
       "      <td>10.530000</td>\n",
       "      <td>10.530000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.060000</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>20.690000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>33.330000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.400000</td>\n",
       "      <td>16.480000</td>\n",
       "      <td>13.330000</td>\n",
       "      <td>15.560000</td>\n",
       "      <td>13.240000</td>\n",
       "      <td>7.590000</td>\n",
       "      <td>2.170000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.870000</td>\n",
       "      <td>3.920000</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>1.15000</td>\n",
       "      <td>50.420000</td>\n",
       "      <td>37.820000</td>\n",
       "      <td>26.670000</td>\n",
       "      <td>8.330000</td>\n",
       "      <td>4.850000</td>\n",
       "      <td>5.450000</td>\n",
       "      <td>10.640000</td>\n",
       "      <td>12.680000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.450000</td>\n",
       "      <td>8.890000</td>\n",
       "      <td>6.830000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          deceptive   hotel     polarity source  \\\n",
       "count   1600.000000    1600  1600.000000   1600   \n",
       "unique          NaN      20          NaN      3   \n",
       "top             NaN  palmer          NaN  MTurk   \n",
       "freq            NaN      80          NaN    800   \n",
       "mean       0.500000     NaN     0.500000    NaN   \n",
       "std        0.500156     NaN     0.500156    NaN   \n",
       "min        0.000000     NaN     0.000000    NaN   \n",
       "25%        0.000000     NaN     0.000000    NaN   \n",
       "50%        0.500000     NaN     0.500000    NaN   \n",
       "75%        1.000000     NaN     1.000000    NaN   \n",
       "max        1.000000     NaN     1.000000    NaN   \n",
       "\n",
       "                                                     text  text_length  \\\n",
       "count                                                1600  1600.000000   \n",
       "unique                                               1596          NaN   \n",
       "top     I'd been searching for a cool, non-chain hotel...          NaN   \n",
       "freq                                                    2          NaN   \n",
       "mean                                                  NaN   806.391250   \n",
       "std                                                   NaN   467.260647   \n",
       "min                                                   NaN   151.000000   \n",
       "25%                                                   NaN   487.000000   \n",
       "50%                                                   NaN   700.000000   \n",
       "75%                                                   NaN   987.500000   \n",
       "max                                                   NaN  4159.000000   \n",
       "\n",
       "                                               lower_case  \\\n",
       "count                                                1600   \n",
       "unique                                               1596   \n",
       "top     my daughter and i woke in the morning wanting ...   \n",
       "freq                                                    2   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                              lc_no_punct  \\\n",
       "count                                                1600   \n",
       "unique                                               1596   \n",
       "top     the omni was chosen for it s location whichwor...   \n",
       "freq                                                    2   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                                     norm  \\\n",
       "count                                                1600   \n",
       "unique                                               1596   \n",
       "top     the omni was chosen for it s location whichwor...   \n",
       "freq                                                    2   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                               norm_lemma  \\\n",
       "count                                                1600   \n",
       "unique                                               1596   \n",
       "top     very disappointed in our stay in chicago monoc...   \n",
       "freq                                                    2   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                                norm_stem  \\\n",
       "count                                                1600   \n",
       "unique                                               1596   \n",
       "top     veri disappoint in our stay in chicago monoco ...   \n",
       "freq                                                    2   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                      norm_lemma_stopword  \\\n",
       "count                                                1600   \n",
       "unique                                               1596   \n",
       "top        search   cool non chain hotel   weekend get...   \n",
       "freq                                                    2   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                       norm_stem_stopword    ADJ_count  \\\n",
       "count                                                1600  1600.000000   \n",
       "unique                                               1596          NaN   \n",
       "top      omni wa chosen    locat whichwork  perfectli ...          NaN   \n",
       "freq                                                    2          NaN   \n",
       "mean                                                  NaN     0.099315   \n",
       "std                                                   NaN     0.033587   \n",
       "min                                                   NaN     0.019048   \n",
       "25%                                                   NaN     0.075330   \n",
       "50%                                                   NaN     0.096541   \n",
       "75%                                                   NaN     0.119300   \n",
       "max                                                   NaN     0.266667   \n",
       "\n",
       "          ADP_count    ADV_count  AUX_count  CCONJ_count    DET_count  \\\n",
       "count   1600.000000  1600.000000     1600.0       1600.0  1600.000000   \n",
       "unique          NaN          NaN        NaN          NaN          NaN   \n",
       "top             NaN          NaN        NaN          NaN          NaN   \n",
       "freq            NaN          NaN        NaN          NaN          NaN   \n",
       "mean       0.105465     0.073256        0.0          0.0     0.124403   \n",
       "std        0.026239     0.027617        0.0          0.0     0.028481   \n",
       "min        0.000000     0.000000        0.0          0.0     0.000000   \n",
       "25%        0.090526     0.054348        0.0          0.0     0.106557   \n",
       "50%        0.106667     0.072289        0.0          0.0     0.124160   \n",
       "75%        0.121527     0.090109        0.0          0.0     0.141747   \n",
       "max        0.192308     0.206522        0.0          0.0     0.236842   \n",
       "\n",
       "        INTJ_count   NOUN_count    NUM_count  PART_count   PRON_count  \\\n",
       "count       1600.0  1600.000000  1600.000000      1600.0  1600.000000   \n",
       "unique         NaN          NaN          NaN         NaN          NaN   \n",
       "top            NaN          NaN          NaN         NaN          NaN   \n",
       "freq           NaN          NaN          NaN         NaN          NaN   \n",
       "mean           0.0     0.249986     0.013510         0.0     0.063546   \n",
       "std            0.0     0.038522     0.014884         0.0     0.030471   \n",
       "min            0.0     0.115942     0.000000         0.0     0.000000   \n",
       "25%            0.0     0.223832     0.000000         0.0     0.041667   \n",
       "50%            0.0     0.247807     0.010363         0.0     0.061377   \n",
       "75%            0.0     0.274336     0.020426         0.0     0.083333   \n",
       "max            0.0     0.418750     0.180328         0.0     0.228571   \n",
       "\n",
       "        PROPN_count  PUNCT_count  SCONJ_count  SYM_count   VERB_count  \\\n",
       "count        1600.0       1600.0       1600.0     1600.0  1600.000000   \n",
       "unique          NaN          NaN          NaN        NaN          NaN   \n",
       "top             NaN          NaN          NaN        NaN          NaN   \n",
       "freq            NaN          NaN          NaN        NaN          NaN   \n",
       "mean            0.0          0.0          0.0        0.0     0.196686   \n",
       "std             0.0          0.0          0.0        0.0     0.034197   \n",
       "min             0.0          0.0          0.0        0.0     0.043478   \n",
       "25%             0.0          0.0          0.0        0.0     0.175676   \n",
       "50%             0.0          0.0          0.0        0.0     0.197346   \n",
       "75%             0.0          0.0          0.0        0.0     0.220000   \n",
       "max             0.0          0.0          0.0        0.0     0.315789   \n",
       "\n",
       "            X_count        class           WC     Analytic        Clout  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.000160     2.500000   149.373125    71.799387    54.789069   \n",
       "std        0.001135     1.118384    87.739431    18.697766    25.821830   \n",
       "min        0.000000     1.000000    25.000000     3.860000     3.480000   \n",
       "25%        0.000000     1.750000    89.000000    60.275000    32.465000   \n",
       "50%        0.000000     2.500000   128.000000    75.015000    54.525000   \n",
       "75%        0.000000     3.250000   183.000000    87.052500    77.235000   \n",
       "max        0.015625     4.000000   784.000000    99.000000    99.000000   \n",
       "\n",
       "          Authentic         Tone          WPS       Sixltr         Dic  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.000000  1600.00000   \n",
       "unique          NaN          NaN          NaN          NaN         NaN   \n",
       "top             NaN          NaN          NaN          NaN         NaN   \n",
       "freq            NaN          NaN          NaN          NaN         NaN   \n",
       "mean      62.433331    66.708150    16.388063    17.162369    88.76245   \n",
       "std       26.023894    34.070231     7.226241     4.382680     4.14512   \n",
       "min        1.000000     1.000000     5.230000     5.450000    71.79000   \n",
       "25%       42.347500    35.755000    12.725000    14.167500    86.30000   \n",
       "50%       66.740000    81.230000    15.400000    16.985000    89.12500   \n",
       "75%       84.275000    98.870000    18.632500    19.652500    91.55000   \n",
       "max       99.000000    99.000000    97.000000    36.710000   100.00000   \n",
       "\n",
       "           function      pronoun        ppron            i           we  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      53.783787    11.534156     7.623800     3.905612     2.055000   \n",
       "std        5.090643     3.915191     3.297535     3.034989     2.542078   \n",
       "min       31.750000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       50.932500     8.890000     5.327500     1.390000     0.000000   \n",
       "50%       54.430000    11.585000     7.765000     3.450000     0.935000   \n",
       "75%       57.272500    14.180000     9.880000     5.940000     3.555000   \n",
       "max       67.530000    23.810000    20.950000    15.000000    12.000000   \n",
       "\n",
       "                you        shehe         they        ipron      article  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.660881     0.218681     0.783550     3.895581     9.806800   \n",
       "std        1.105959     0.570362     1.037403     1.975704     2.581639   \n",
       "min        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%        0.000000     0.000000     0.000000     2.610000     8.107500   \n",
       "50%        0.000000     0.000000     0.490000     3.750000     9.785000   \n",
       "75%        0.980000     0.000000     1.200000     5.000000    11.490000   \n",
       "max        7.530000     6.500000     8.570000    13.560000    18.450000   \n",
       "\n",
       "               prep      auxverb       adverb         conj       negate  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      12.801825     8.915756     5.446219     6.384119     1.677969   \n",
       "std        2.861762     2.497208     2.447376     1.966778     1.399532   \n",
       "min        1.690000     1.090000     0.000000     0.000000     0.000000   \n",
       "25%       10.987500     7.280000     3.730000     5.050000     0.687500   \n",
       "50%       12.850000     8.940000     5.260000     6.320000     1.490000   \n",
       "75%       14.750000    10.370000     6.850000     7.612500     2.500000   \n",
       "max       22.730000    19.120000    17.650000    15.620000    10.670000   \n",
       "\n",
       "               verb          adj      compare     interrog       number  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      15.360131     6.050400     2.071431     0.933763     1.591325   \n",
       "std        3.391309     2.658416     1.498134     0.925727     1.507279   \n",
       "min        2.220000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       13.152500     4.210000     1.020000     0.000000     0.430000   \n",
       "50%       15.380000     5.710000     1.850000     0.800000     1.325000   \n",
       "75%       17.687500     7.485000     2.940000     1.490000     2.352500   \n",
       "max       27.500000    19.050000    10.530000     4.650000    18.030000   \n",
       "\n",
       "              quant       affect       posemo      negemo          anx  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.00000  1600.000000   \n",
       "unique          NaN          NaN          NaN         NaN          NaN   \n",
       "top             NaN          NaN          NaN         NaN          NaN   \n",
       "freq            NaN          NaN          NaN         NaN          NaN   \n",
       "mean       1.943287     5.907506     4.553938     1.12075     0.163806   \n",
       "std        1.403120     2.870457     3.081086     1.28789     0.397944   \n",
       "min        0.000000     0.000000     0.000000     0.00000     0.000000   \n",
       "25%        0.967500     3.920000     2.210000     0.00000     0.000000   \n",
       "50%        1.750000     5.490000     3.965000     0.82000     0.000000   \n",
       "75%        2.762500     7.320000     6.435000     1.81000     0.000000   \n",
       "max        8.330000    20.340000    18.870000     9.38000     5.000000   \n",
       "\n",
       "              anger          sad       social       family       friend  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.199269     0.203594     7.505700     0.359981     0.442594   \n",
       "std        0.464278     0.424580     4.030817     0.734593     0.696959   \n",
       "min        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%        0.000000     0.000000     4.620000     0.000000     0.000000   \n",
       "50%        0.000000     0.000000     7.045000     0.000000     0.000000   \n",
       "75%        0.000000     0.232500    10.095000     0.510000     0.760000   \n",
       "max        5.560000     3.360000    23.810000     5.660000     5.710000   \n",
       "\n",
       "             female         male      cogproc      insight        cause  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.325388     0.327144     8.955763     1.145400     0.797769   \n",
       "std        0.721457     0.650519     3.416747     1.065891     0.839687   \n",
       "min        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%        0.000000     0.000000     6.630000     0.000000     0.000000   \n",
       "50%        0.000000     0.000000     8.860000     1.030000     0.690000   \n",
       "75%        0.352500     0.480000    11.110000     1.722500     1.290000   \n",
       "max        7.740000     5.690000    23.480000     8.510000     4.600000   \n",
       "\n",
       "            discrep       tentat      certain       differ      percept  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       1.566944     1.757069     1.761981     2.854931     2.181400   \n",
       "std        1.235211     1.336183     1.384616     1.940218     1.597797   \n",
       "min        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%        0.690000     0.797500     0.810000     1.470000     1.100000   \n",
       "50%        1.450000     1.610000     1.540000     2.675000     1.950000   \n",
       "75%        2.290000     2.590000     2.500000     3.980000     3.030000   \n",
       "max        8.000000     8.330000     9.260000    12.500000    11.340000   \n",
       "\n",
       "                see         hear         feel          bio         body  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.910044     0.462844     0.480525     1.801225     0.252956   \n",
       "std        1.086196     0.745820     0.750665     1.694788     0.488442   \n",
       "min        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%        0.000000     0.000000     0.000000     0.577500     0.000000   \n",
       "50%        0.690000     0.000000     0.000000     1.480000     0.000000   \n",
       "75%        1.430000     0.780000     0.800000     2.580000     0.400000   \n",
       "max        8.250000     6.800000     6.980000    12.500000     4.230000   \n",
       "\n",
       "             health       sexual       ingest       drives  affiliation  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.231481     0.010756     1.208150     8.111631     3.241900   \n",
       "std        0.484716     0.091442     1.498268     3.705509     3.115135   \n",
       "min        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%        0.000000     0.000000     0.000000     5.260000     0.617500   \n",
       "50%        0.000000     0.000000     0.790000     7.785000     2.455000   \n",
       "75%        0.320000     0.000000     1.870000    10.470000     5.072500   \n",
       "max        5.130000     1.720000    12.500000    24.000000    15.150000   \n",
       "\n",
       "            achieve        power       reward         risk    focuspast  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       1.098881     2.213175     1.785962     0.384556     7.265406   \n",
       "std        1.071992     1.435299     1.474134     0.623480     3.413554   \n",
       "min        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%        0.000000     1.230000     0.760000     0.000000     5.000000   \n",
       "50%        0.950000     2.020000     1.520000     0.000000     7.505000   \n",
       "75%        1.632500     3.030000     2.500000     0.702500     9.640000   \n",
       "max       10.530000    10.530000    10.000000     6.060000    18.750000   \n",
       "\n",
       "        focuspresent  focusfuture      relativ       motion        space  \\\n",
       "count    1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "unique           NaN          NaN          NaN          NaN          NaN   \n",
       "top              NaN          NaN          NaN          NaN          NaN   \n",
       "freq             NaN          NaN          NaN          NaN          NaN   \n",
       "mean        6.288981     0.765519    17.468119     2.915563    11.037831   \n",
       "std         3.136674     0.876047     4.175587     1.561330     3.249295   \n",
       "min         0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%         4.095000     0.000000    14.777500     1.830000     8.847500   \n",
       "50%         5.850000     0.590000    17.430000     2.780000    10.820000   \n",
       "75%         8.000000     1.220000    20.132500     3.810000    13.060000   \n",
       "max        20.690000     7.270000    33.330000    10.000000    23.400000   \n",
       "\n",
       "               time         work      leisure         home        money  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       4.889250     2.436375     3.751388     2.768525     1.240731   \n",
       "std        2.529072     1.699430     2.162818     1.720677     1.269930   \n",
       "min        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%        3.080000     1.270000     2.200000     1.590000     0.000000   \n",
       "50%        4.710000     2.150000     3.475000     2.610000     0.970000   \n",
       "75%        6.380000     3.230000     4.942500     3.722500     1.850000   \n",
       "max       16.480000    13.330000    15.560000    13.240000     7.590000   \n",
       "\n",
       "              relig        death     informal        swear     netspeak  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       0.022150     0.020550     0.406875     0.018712     0.043844   \n",
       "std        0.142495     0.137384     0.680934     0.124303     0.211320   \n",
       "min        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%        0.000000     0.000000     0.680000     0.000000     0.000000   \n",
       "max        2.170000     1.750000     6.250000     2.000000     2.870000   \n",
       "\n",
       "             assent       nonflu      filler      AllPunc       Period  \\\n",
       "count   1600.000000  1600.000000  1600.00000  1600.000000  1600.000000   \n",
       "unique          NaN          NaN         NaN          NaN          NaN   \n",
       "top             NaN          NaN         NaN          NaN          NaN   \n",
       "freq            NaN          NaN         NaN          NaN          NaN   \n",
       "mean       0.149638     0.181806     0.00905    14.055519     6.612544   \n",
       "std        0.410125     0.454386     0.08024     5.047531     2.942552   \n",
       "min        0.000000     0.000000     0.00000     1.540000     0.000000   \n",
       "25%        0.000000     0.000000     0.00000    10.520000     4.960000   \n",
       "50%        0.000000     0.000000     0.00000    13.395000     6.095000   \n",
       "75%        0.000000     0.000000     0.00000    16.670000     7.690000   \n",
       "max        3.920000     6.250000     1.15000    50.420000    37.820000   \n",
       "\n",
       "              Comma        Colon        SemiC        QMark       Exclam  \\\n",
       "count   1600.000000  1600.000000  1600.000000  1600.000000  1600.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean       3.591619     0.087137     0.066175     0.076775     0.767031   \n",
       "std        2.465118     0.397933     0.322842     0.351067     1.384438   \n",
       "min        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%        1.740000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%        3.340000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%        5.130000     0.000000     0.000000     0.000000     1.015000   \n",
       "max       26.670000     8.330000     4.850000     5.450000    10.640000   \n",
       "\n",
       "               Dash   Quote      Apostro      Parenth       OtherP  \n",
       "count   1600.000000  1600.0  1600.000000  1600.000000  1600.000000  \n",
       "unique          NaN     NaN          NaN          NaN          NaN  \n",
       "top             NaN     NaN          NaN          NaN          NaN  \n",
       "freq            NaN     NaN          NaN          NaN          NaN  \n",
       "mean       0.681212     0.0     1.280112     0.526700     0.366150  \n",
       "std        1.239694     0.0     1.450216     1.094702     0.850661  \n",
       "min        0.000000     0.0     0.000000     0.000000     0.000000  \n",
       "25%        0.000000     0.0     0.000000     0.000000     0.000000  \n",
       "50%        0.000000     0.0     0.920000     0.000000     0.000000  \n",
       "75%        1.010000     0.0     2.052500     0.682500     0.380000  \n",
       "max       12.680000     0.0    10.450000     8.890000     6.830000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotels.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc = hotels.loc[:, \"WC\":\"OtherP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WC</th>\n",
       "      <th>Analytic</th>\n",
       "      <th>Clout</th>\n",
       "      <th>Authentic</th>\n",
       "      <th>Tone</th>\n",
       "      <th>WPS</th>\n",
       "      <th>Sixltr</th>\n",
       "      <th>Dic</th>\n",
       "      <th>function</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>ppron</th>\n",
       "      <th>i</th>\n",
       "      <th>we</th>\n",
       "      <th>you</th>\n",
       "      <th>shehe</th>\n",
       "      <th>they</th>\n",
       "      <th>ipron</th>\n",
       "      <th>article</th>\n",
       "      <th>prep</th>\n",
       "      <th>auxverb</th>\n",
       "      <th>adverb</th>\n",
       "      <th>conj</th>\n",
       "      <th>negate</th>\n",
       "      <th>verb</th>\n",
       "      <th>adj</th>\n",
       "      <th>compare</th>\n",
       "      <th>interrog</th>\n",
       "      <th>number</th>\n",
       "      <th>quant</th>\n",
       "      <th>affect</th>\n",
       "      <th>posemo</th>\n",
       "      <th>negemo</th>\n",
       "      <th>anx</th>\n",
       "      <th>anger</th>\n",
       "      <th>sad</th>\n",
       "      <th>social</th>\n",
       "      <th>family</th>\n",
       "      <th>friend</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>cogproc</th>\n",
       "      <th>insight</th>\n",
       "      <th>cause</th>\n",
       "      <th>discrep</th>\n",
       "      <th>tentat</th>\n",
       "      <th>certain</th>\n",
       "      <th>differ</th>\n",
       "      <th>percept</th>\n",
       "      <th>see</th>\n",
       "      <th>hear</th>\n",
       "      <th>feel</th>\n",
       "      <th>bio</th>\n",
       "      <th>body</th>\n",
       "      <th>health</th>\n",
       "      <th>sexual</th>\n",
       "      <th>ingest</th>\n",
       "      <th>drives</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>achieve</th>\n",
       "      <th>power</th>\n",
       "      <th>reward</th>\n",
       "      <th>risk</th>\n",
       "      <th>focuspast</th>\n",
       "      <th>focuspresent</th>\n",
       "      <th>focusfuture</th>\n",
       "      <th>relativ</th>\n",
       "      <th>motion</th>\n",
       "      <th>space</th>\n",
       "      <th>time</th>\n",
       "      <th>work</th>\n",
       "      <th>leisure</th>\n",
       "      <th>home</th>\n",
       "      <th>money</th>\n",
       "      <th>relig</th>\n",
       "      <th>death</th>\n",
       "      <th>informal</th>\n",
       "      <th>swear</th>\n",
       "      <th>netspeak</th>\n",
       "      <th>assent</th>\n",
       "      <th>nonflu</th>\n",
       "      <th>filler</th>\n",
       "      <th>AllPunc</th>\n",
       "      <th>Period</th>\n",
       "      <th>Comma</th>\n",
       "      <th>Colon</th>\n",
       "      <th>SemiC</th>\n",
       "      <th>QMark</th>\n",
       "      <th>Exclam</th>\n",
       "      <th>Dash</th>\n",
       "      <th>Quote</th>\n",
       "      <th>Apostro</th>\n",
       "      <th>Parenth</th>\n",
       "      <th>OtherP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>61.61</td>\n",
       "      <td>61.05</td>\n",
       "      <td>35.01</td>\n",
       "      <td>77.39</td>\n",
       "      <td>13.38</td>\n",
       "      <td>13.08</td>\n",
       "      <td>82.24</td>\n",
       "      <td>49.53</td>\n",
       "      <td>6.54</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>7.48</td>\n",
       "      <td>10.28</td>\n",
       "      <td>10.28</td>\n",
       "      <td>9.35</td>\n",
       "      <td>6.54</td>\n",
       "      <td>1.87</td>\n",
       "      <td>12.15</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.93</td>\n",
       "      <td>4.67</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.54</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.74</td>\n",
       "      <td>6.54</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.35</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.95</td>\n",
       "      <td>1.87</td>\n",
       "      <td>8.41</td>\n",
       "      <td>6.54</td>\n",
       "      <td>0.93</td>\n",
       "      <td>3.74</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.82</td>\n",
       "      <td>11.21</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>97.59</td>\n",
       "      <td>41.03</td>\n",
       "      <td>19.82</td>\n",
       "      <td>94.75</td>\n",
       "      <td>8.80</td>\n",
       "      <td>29.55</td>\n",
       "      <td>77.27</td>\n",
       "      <td>31.82</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.27</td>\n",
       "      <td>6.82</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.55</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.82</td>\n",
       "      <td>13.64</td>\n",
       "      <td>6.82</td>\n",
       "      <td>2.27</td>\n",
       "      <td>2.27</td>\n",
       "      <td>6.82</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.27</td>\n",
       "      <td>6.82</td>\n",
       "      <td>6.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.27</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.64</td>\n",
       "      <td>2.27</td>\n",
       "      <td>11.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.55</td>\n",
       "      <td>6.82</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>11.36</td>\n",
       "      <td>9.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    WC  Analytic  Clout  Authentic   Tone    WPS  Sixltr    Dic  function  \\\n",
       "0  107     61.61  61.05      35.01  77.39  13.38   13.08  82.24     49.53   \n",
       "1   44     97.59  41.03      19.82  94.75   8.80   29.55  77.27     31.82   \n",
       "\n",
       "   pronoun  ppron     i    we   you  shehe  they  ipron  article   prep  \\\n",
       "0     6.54   3.74  0.93  1.87  0.93    0.0   0.0   2.80     7.48  10.28   \n",
       "1     2.27   0.00  0.00  0.00  0.00    0.0   0.0   2.27     6.82  13.64   \n",
       "\n",
       "   auxverb  adverb  conj  negate   verb    adj  compare  interrog  number  \\\n",
       "0    10.28    9.35  6.54    1.87  12.15   3.74     0.00      0.00    4.67   \n",
       "1     4.55    4.55  2.27    0.00   6.82  13.64     6.82      2.27    2.27   \n",
       "\n",
       "   quant  affect  posemo  negemo  anx  anger  sad  social  family  friend  \\\n",
       "0   0.93    4.67    3.74    0.93  0.0    0.0  0.0    6.54    0.93     0.0   \n",
       "1   6.82    4.55    4.55    0.00  0.0    0.0  0.0    0.00    0.00     0.0   \n",
       "\n",
       "   female  male  cogproc  insight  cause  discrep  tentat  certain  differ  \\\n",
       "0     0.0   0.0     5.61      0.0    0.0     0.93    0.00     0.93    3.74   \n",
       "1     0.0   0.0     4.55      0.0    0.0     0.00    2.27     0.00    2.27   \n",
       "\n",
       "   percept   see  hear  feel   bio  body  health  sexual  ingest  drives  \\\n",
       "0     0.00  0.00   0.0   0.0  3.74   0.0     0.0     0.0    3.74    6.54   \n",
       "1     6.82  6.82   0.0   0.0  4.55   0.0     0.0     0.0    4.55    4.55   \n",
       "\n",
       "   affiliation  achieve  power  reward  risk  focuspast  focuspresent  \\\n",
       "0         3.74     0.93   0.93    1.87   0.0       9.35          1.87   \n",
       "1         0.00     0.00   2.27    2.27   0.0       6.82          0.00   \n",
       "\n",
       "   focusfuture  relativ  motion  space  time  work  leisure  home  money  \\\n",
       "0          0.0    14.95    1.87   8.41  6.54  0.93     3.74  2.80   1.87   \n",
       "1          0.0    13.64    2.27  11.36  0.00  4.55     4.55  6.82   2.27   \n",
       "\n",
       "   relig  death  informal  swear  netspeak  assent  nonflu  filler  AllPunc  \\\n",
       "0    0.0    0.0       0.0    0.0       0.0     0.0     0.0     0.0    16.82   \n",
       "1    0.0    0.0       0.0    0.0       0.0     0.0     0.0     0.0    25.00   \n",
       "\n",
       "   Period  Comma  Colon  SemiC  QMark  Exclam  Dash  Quote  Apostro  Parenth  \\\n",
       "0   11.21   1.87    0.0    0.0    0.0     0.0   0.0      0      0.0     3.74   \n",
       "1   11.36   9.09    0.0    0.0    0.0     0.0   0.0      0      0.0     0.00   \n",
       "\n",
       "   OtherP  \n",
       "0    0.00  \n",
       "1    4.55  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liwc.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WC', 'Analytic', 'Clout', 'Authentic', 'Tone', 'WPS', 'Sixltr', 'Dic',\n",
       "       'function', 'pronoun', 'ppron', 'i', 'we', 'you', 'shehe', 'they',\n",
       "       'ipron', 'article', 'prep', 'auxverb', 'adverb', 'conj', 'negate',\n",
       "       'verb', 'adj', 'compare', 'interrog', 'number', 'quant', 'affect',\n",
       "       'posemo', 'negemo', 'anx', 'anger', 'sad', 'social', 'family', 'friend',\n",
       "       'female', 'male', 'cogproc', 'insight', 'cause', 'discrep', 'tentat',\n",
       "       'certain', 'differ', 'percept', 'see', 'hear', 'feel', 'bio', 'body',\n",
       "       'health', 'sexual', 'ingest', 'drives', 'affiliation', 'achieve',\n",
       "       'power', 'reward', 'risk', 'focuspast', 'focuspresent', 'focusfuture',\n",
       "       'relativ', 'motion', 'space', 'time', 'work', 'leisure', 'home',\n",
       "       'money', 'relig', 'death', 'informal', 'swear', 'netspeak', 'assent',\n",
       "       'nonflu', 'filler', 'AllPunc', 'Period', 'Comma', 'Colon', 'SemiC',\n",
       "       'QMark', 'Exclam', 'Dash', 'Quote', 'Apostro', 'Parenth', 'OtherP'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liwc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(liwc.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. Choose input data and target__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = liwc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = hotels[\"deceptive\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. Split data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_train_test_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3. Build pipeline__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_lr = [\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', LogisticRegression()),\n",
    "]\n",
    "\n",
    "pipe_lr = Pipeline(steps_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4. Construct parameters for cross validation testing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lr = [\n",
    "    { \n",
    "        'clf__C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__5. Apply Grid Serach CV__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 3.492s\n",
      "best params:\n",
      "{'clf__C': 0.01}\n",
      "Best cross-validation score: 0.784\n",
      "Test-set score: 0.782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "log_reg_grid_search = apply_grid_search_cv(pipe_lr, param_grid_lr, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__6. Save Classification Report to File__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>truthful</th>\n",
       "      <td>0.758772</td>\n",
       "      <td>0.800926</td>\n",
       "      <td>0.720833</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deceptive</th>\n",
       "      <td>0.781746</td>\n",
       "      <td>0.746212</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.770259</td>\n",
       "      <td>0.773569</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.770259</td>\n",
       "      <td>0.773569</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1-score  precision    recall  support\n",
       "truthful      0.758772   0.800926  0.720833    240.0\n",
       "deceptive     0.781746   0.746212  0.820833    240.0\n",
       "micro avg     0.770833   0.770833  0.770833    480.0\n",
       "macro avg     0.770259   0.773569  0.770833    480.0\n",
       "weighted avg  0.770259   0.773569  0.770833    480.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_class_report_cv(log_reg_grid_search, X_test, y_test, [\"truthful\", \"deceptive\"], \"output/log_reg_liwc1_report.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  clf__C mean_test_score std_test_score rank_test_score mean_fit_time\n",
      "2   0.01        0.783725        0.02237               1     0.0433863\n",
      "3    0.1        0.782121      0.0147277               2     0.0640293\n",
      "4      1         0.78088      0.0227793               3     0.0909564\n",
      "6    100        0.780751      0.0224041               4      0.147403\n",
      "5     10        0.779676        0.02354               5      0.154388\n",
      "1  0.001        0.768232       0.016305               6     0.0456838\n"
     ]
    }
   ],
   "source": [
    "save_cross_validation_results(log_reg_grid_search, \"output/log_reg_liwc1_validation_res.csv\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__7. Save model to file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['output/log_reg_liwc1.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(log_reg_grid_search.best_estimator_, 'output/log_reg_liwc1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__7b. Identify important features for deceptive opinion spam__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with lowest scaled value:\n",
      "Index(['Quote', 'Tone', 'Authentic', 'Analytic', 'Clout', 'function', 'Dic',\n",
      "       'pronoun', 'we', 'ppron'],\n",
      "      dtype='object')\n",
      "Features with highest scaled value: \n",
      "Index(['Period', 'shehe', 'anx', 'anger', 'death', 'filler', 'relig', 'SemiC',\n",
      "       'sexual', 'Colon'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "scaler = log_reg_grid_search.best_estimator_.named_steps[\"scale\"]\n",
    "\n",
    "# transform the training dataset\n",
    "X_train1 = scaler.transform(X_train)\n",
    "\n",
    "max_value = X_train1.max(axis=0).ravel()\n",
    "sorted_by_scale = max_value.argsort()\n",
    "\n",
    "#feature_names = np.array(scaler.get_feature_names())\n",
    "feature_names = X_train.columns\n",
    "\n",
    "print(\"Features with lowest scaled value:\\n{}\".format(\n",
    "    feature_names[sorted_by_scale[:10]]))\n",
    "\n",
    "print(\"Features with highest scaled value: \\n{}\".format(\n",
    "    feature_names[sorted_by_scale[-10:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mglearn\n",
    "\n",
    "mglearn.tools.visualize_coefficients(\n",
    "    log_reg_grid_search.best_estimator_.named_steps[\"clf\"].coef_,\n",
    "    feature_names, n_top_features=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation:__ The negative coefficients on the left represent truthful reviews while the positive coefficients on the right represent the deceptive reviews. From here we can see that truthful reviews have more punctuations, numbers, informal and swear words, while the deceptive reviews have more \"I\" and pronouns, as well as being more family, leisoure words and 6 letter words(?). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__8. Sentiment Analysis__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.630s\n",
      "best params:\n",
      "{'clf__C': 0.01}\n",
      "Best cross-validation score: 0.908\n",
      "Test-set score: 0.898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "y = hotels[\"polarity\"]\n",
    "X_train, X_test, y_train, y_test = split_train_test_data(X, y)\n",
    "log_reg_grid_search_p = apply_grid_search_cv(pipe_lr, param_grid_lr, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  clf__C mean_test_score std_test_score rank_test_score mean_fit_time\n",
      "2   0.01        0.908074      0.0131457               1      0.041888\n",
      "3    0.1        0.903628      0.0166831               2     0.0656276\n",
      "1  0.001        0.898955      0.0111985               3     0.0287235\n",
      "5     10        0.894132      0.0164429               4      0.123071\n",
      "4      1        0.893159      0.0162789               5     0.0935479\n",
      "6    100         0.88982       0.013148               6      0.135834\n"
     ]
    }
   ],
   "source": [
    "save_cross_validation_results(log_reg_grid_search_p, \"output/log_reg_liwc_sent_validation_res.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>0.898129</td>\n",
       "      <td>0.896266</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.897704</td>\n",
       "      <td>0.899582</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.897917</td>\n",
       "      <td>0.897917</td>\n",
       "      <td>0.897917</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.897916</td>\n",
       "      <td>0.897924</td>\n",
       "      <td>0.897917</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.897916</td>\n",
       "      <td>0.897924</td>\n",
       "      <td>0.897917</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1-score  precision    recall  support\n",
       "negative      0.898129   0.896266  0.900000    240.0\n",
       "positive      0.897704   0.899582  0.895833    240.0\n",
       "micro avg     0.897917   0.897917  0.897917    480.0\n",
       "macro avg     0.897916   0.897924  0.897917    480.0\n",
       "weighted avg  0.897916   0.897924  0.897917    480.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_class_report_cv(log_reg_grid_search_p, X_test, y_test, [\"negative\", \"positive\"], \"output/log_reg_liwc_report_sent.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__8b. Identify important features for sentiment analysis__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with lowest scaled value:\n",
      "Index(['Quote', 'Tone', 'Authentic', 'Analytic', 'Clout', 'function', 'Dic',\n",
      "       'prep', 'pronoun', 'focuspast'],\n",
      "      dtype='object')\n",
      "Features with highest scaled value: \n",
      "Index(['death', 'netspeak', 'nonflu', 'QMark', 'SemiC', 'filler', 'relig',\n",
      "       'sexual', 'swear', 'Colon'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "scaler = log_reg_grid_search_p.best_estimator_.named_steps[\"scale\"]\n",
    "\n",
    "# transform the training dataset\n",
    "X_train1 = scaler.transform(X_train)\n",
    "\n",
    "max_value = X_train1.max(axis=0).ravel()\n",
    "sorted_by_scale = max_value.argsort()\n",
    "\n",
    "#feature_names = np.array(scaler.get_feature_names())\n",
    "feature_names = X_train.columns\n",
    "\n",
    "print(\"Features with lowest scaled value:\\n{}\".format(\n",
    "    feature_names[sorted_by_scale[:10]]))\n",
    "\n",
    "print(\"Features with highest scaled value: \\n{}\".format(\n",
    "    feature_names[sorted_by_scale[-10:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4QAAAE0CAYAAAB0G/1nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xe4VNXZ9/HvDQiCoKigIopgRbB7sFeE2HvvXaPB3ntXLLGAvcYWu0aiqNHYjQ2jMYkp+mhMfJMnmt6eVNf7x31vZ5/J4Zy958ycAeb3ua65zpk9M2vW7LL2utdae21LKSEiIiIiIiKtp1ezMyAiIiIiIiLNoYBQRERERESkRSkgFBERERERaVEKCEVERERERFqUAkIREREREZEWpYBQRERERESkRSkgFBERERERaVEKCEVERERERFqUAkIREREREZEW1afZGai3IUOGpJEjRzY7GyIiIiIiIk3x1ltv/SalNLTIe+e4gHDkyJHMmDGj2dkQERERERFpCjP7uOh7NWRURERERESkRSkgFBERERERaVEKCEVERERERFqUAkIREREREZEWpYBQRERERESkRSkgFBERERERaVEKCEVERERERFrUHHcfQhERERERkaLMHqj5syntXMecNId6CEVERERERFqUAkIREREREZEWpYBQRERERESkRSkgFBERERERaVEKCEVERERERFqUAkIREREREZEWpYBQRERERESkRSkgFBERERERaVEKCEVERERERFqUAkIREREREZEWpYBQRERERESkRSkgFBERERERaVEKCEVERERERFqUAkIREREREZEWpYBQRERERESkRSkgFBERERERaVEKCEVERERERFqUAkIREREREZEWpYBQRERERESkRSkgFBERERERaVEKCEVERERERFqUAkIREREREZEWpYBQRERERESkRSkgFBERERERaVFNDQjNbDMz+4mZfWBmJ3fyvp3MLJlZW0/mT0REREREZE7WtIDQzHoD1wCbA2OA3c1sTAfvGwQcCbzeszkUERERERGZszWzh3AN4IOU0ocppX8C9wLbdvC+84BLgL/3ZOZERERERETmdM0MCIcDv8g9/ySWfcHMVgUWTyk91llCZnaImc0wsxmfffZZ/XMqIiIiIiIyB2pmQGgdLEtfvGjWC7gCOK6rhFJKN6aU2lJKbUOHDq1jFkVEREREROZczQwIPwEWzz1fDPhl7vkgYAXgeTP7GbAWME0Ty4iIiIiIiNRHMwPCN4FlzGyUmfUFdgOmZS+mlP6YUhqSUhqZUhoJvAZsk1Ka0ZzsioiIiIiIzFmaFhCmlP4NTAKeAn4E3J9S+qGZnWtm2zQrXyIiIiIiIq2iTzO/PKU0HZhetezMmbx3o57Ik4iIiIiISKto6o3pRUREREREpHkUEIqIiIiIiLQoBYQiIiIiIiItSgGhiIiIiIhIi1JAKCIiIiIi0qIUEIqIiIiIiLQoBYQiIiIiIiItqqn3IRQRERERESnL7IGaP5vSznXMyeyvyx5Cc3uZ2ZnxfISZrdH4rImIiIiIiEgjFRkyei2wNrB7PP8zcE3DciQiIiIiIiI9osiQ0TVTSquZ2dsAKaXfm1nfBudLREREREREGqxID+G/zKw3kADMbCjweUNzJSIiIiIiIg1XJCCcAjwCLGRmFwAvAxc2NFciIiIiIiLScF0OGU0p3W1mbwGbAAZsl1L6UcNzJiIiIiIiIg0104DQzBbIPf0UuCf/Wkrpd43MmIiIiIiIiDRWZz2Eb+HXDRowAvh9/D8Y+DkwquG5ExERERERkYaZ6TWEKaVRKaUlgaeArVNKQ1JKCwJbAQ/3VAZFRERERESkMYpMKjMupTQ9e5JSegLYsHFZEhERERERkZ5Q5D6EvzGz04G78CGkewG/bWiuREREREREpOGK9BDuDgzFbz3xDWChWCYiIiIiIiKzsSK3nfgdcFQP5EVERERERER6UJcBoZk9hw8VbSelNL4hORIREREREZEeUeQawuNz/88N7Aj8uzHZERERERERkZ5SZMjoW1WLXjGzFxqUHxEREREREekhRYaMLpB72gtYHVikYTkSERERERGRHlFkyOhb+DWEhg8V/Qg4sJGZEhERERERkcYrEhAun1L6e36BmfVrUH5ERERERESkhxS5D+F3Olj2ar0zIiIiIiIiIj1rpj2EZrYIMBzob2ar4kNGAeYFBvRA3kRERERERKSBOhsyuimwH7AYcHlu+Z+BUxuYJxEREREREekBMw0IU0q3A7eb2Y4ppYd6ME8iIiIiIjKHMXug5s+mtHMdcyJ5nQ0Z3SuldBcw0syOrX49pXR5Bx8TERERERGR2URnk8rME38HAoM6eHSbmW1mZj8xsw/M7OQOXj/WzN4zs3fN7NtmtkQ9vldEREREREQ6HzJ6Q/w9pxFfbGa9gWuAicAnwJtmNi2l9F7ubW8DbSmlv5nZYcAlwK6NyI+IiIiIiEir6fI+hGY2FDgYGJl/f0rpgG5+9xrABymlD+N77gW2Bb4ICFNKz+Xe/xqwVze/U0REREREREKRG9M/CrwEPAP8p47fPRz4Re75J8Canbz/QOCJjl4ws0OAQwBGjBhRr/yJiIiIiIjM0YoEhANSSic14Lutg2Wpwzea7QW0ARt29HpK6UbgRoC2trYO0xAREREREZH2OptUJvOYmW3RgO/+BFg893wx4JfVbzKzCcBpwDYppX80IB8iIiIiIiItqUhAeBQeFP6fmf3JzP5sZn+qw3e/CSxjZqPMrC+wGzAt/wYzWxW4AQ8GP63Dd4qIiIiIiEjocshoSqkut5joIN1/m9kk4CmgN3BrSumHZnYuMCOlNA24FL/txQNmBvDzlNI2jciPiIiIiIhIqykyy+hqHSz+I/BxSunf3fnylNJ0YHrVsjNz/0/oTvoiIiIiIiIyc0UmlbkWWA34fjxfEfgesKCZfTml9K1GZU5EREREREQap0hA+DPgwJTSDwHMbAxwAnAe8DCggFBEREREZA5k9kDNn01p5zrmRBqlSEA4OgsGAVJK75nZqimlD+O6PhERERERmUUoiJMyigSEPzGz64B74/muwE/NrB/wr4blTERERERERBqqyG0n9gM+AI4GjgE+jGX/AjZuVMZERERERESksYrcduL/gK/Go9pf6p4jERERERER6RFFbjuxDHARMAaYO1ueUlqygfkSERERERGRBisyZPQ24Drg3/gQ0TuAOxuZKREREREREWm8IpPK9E8pfdvMLKX0MXC2mb0EnNXgvImIiIiItATNDCrNUiQg/LuZ9QLeN7NJwP8DFmpstkRERERERKTRigSERwMDgCPxm9GPB/ZtZKZERERERGZl3enRA/XqyayjyCyjb8a/fwH2b2x2REREREQaQ0GcyH8rMstoG3AasET+/SmllRqYLxERERERXVsn0mBFhozeDZwAfB/4vLHZERERERERkZ5SJCD8LKU0reE5EREREZE5gnr1RGYfRQLCs8zsZuDbwD+yhSmlhxuWKxEREREREWm4IgHh/sBoYC4qQ0YToIBQRERERERkNlYkIFw5pbRiw3MiIiIiIk2jYZ4iralIQPiamY1JKb3X8NyIiIiISGEK4kSku4oEhOsB+5rZR/g1hAYk3XZCREREWkU9Ay8FcSIyKykSEG7W8FyIiIiI1JFuQC4iUkyXAWFK6eOeyIiIiIiIiIj0rCI9hCIiIiINp149EZGep4BQREREaqYgTkRk9tZlQGhmF6eUTupqmYiIiDSOJjUREZFGKNJDOBGoDv4272CZiIiI5CjwEhGRWd1MA0IzOww4HFjSzN7NvTQIeKXRGRMREREREZHG6qyH8OvAE8BFwMm55X9OKf2uobkSERERERGRhptpQJhS+iPwR2B3M+sNLBzvH2hmA1NKP++hPIqIiIiIiEgDFJlUZhJwNvBr4PNYnICVGpctERERERERabQik8ocDSyXUvptozMjIiIiIiIiPadXgff8Ah86KiIiIiIiInOQIj2EHwLPm9njwD+yhSmly7v75Wa2GXAV0Bu4OaU0uer1fsAdwOrAb4FdU0o/6+73ioiIiIiISLEewp8DTwN98VtOZI9uiYlqrsHvaTgGn7xmTNXbDgR+n1JaGrgCuLi73ysiIiIiIiKuyx7ClNI5AGY2T0rpr3X87jWAD1JKH0b69wLbAu/l3rMtPqENwIPA1WZmKaVUx3yIiIiIiIi0JOsqtjKztYFbgIEppRFmtjJwaErp8G59sdlOwGYppYPi+d7AmimlSbn3/CDe80k8/594z2+q0joEOARgxIgRq3/88cfdyVpjjBrVvc9/9FH90lNazUurOr1ZNa3upqe05oy0qtPTPlY+LRERkSYws7dSSm1F3ltkyOiVwKb4NXyklL4HbFB79r5gHSyrjk6LvIeU0o0ppbaUUtvQoUPrkDUREREREZE5X5GAkJTSL6oW/acO3/0JsHju+WLAL2f2HjPrA8wH/K4O3y0iIiIiItLyCt12wszWAZKZ9TWz44Ef1eG73wSWMbNRZtYX2A2YVvWeacC+8f9OwLO6flBERERERKQ+igSEXwa+AgzHe+xWiefdklL6NzAJeAoPMO9PKf3QzM41s23ibbcAC5rZB8CxwMnd/V4RERERERFxRWYZ/Q2wZyO+PKU0HZhetezM3P9/B3ZuxHeLiIiIiIi0upkGhGZ2YkrpEjObSscTuRzZ0JyJiIiIiIhIQ3XWQ5hdJzijJzIiIiIiIiIiPWumAWFK6Zvx9/aey46IiIiIiIj0lC4nlTGzp81scO75/Gb2VGOzJSIiIiIiIo1WZJbRoSmlP2RPUkq/BxZqXJZERERERESkJxQJCP9jZiOyJ2a2BB1MMiMiIiIiIiKzly5vOwGcBrxsZi/E8w2AQxqXJREREREREekJRe5D+KSZrQasBRhwTNybUERERERERGZjMx0yamaj4+9qwAjgl8D/A0bEMhEREREREZmNddZDeCw+NPSrHbyWgPENyZGIiEgzffRRs3MgIiLSYzoLCJ+OvwemlD7sicyIiEgLqWfgpSBORESkJp0FhKcADwAPAhoiKiIyO1LQJSIiIp3oLCD8nZk9ByxpZtOqX0wpbdO4bImI9IBZNVhS4CUiIiI9pLOAcAu8Z/BOOr6OUESk5ylYEhEREambzgLCW1JKe5vZTSmlFzp5n4iIiIiIiMyGOgsIVzezJYA9zewm/B6EX0gp/a6hOROROYd69URERERmSZ0FhNcDTwJLAm/RPiBMsVxERERERERmUzMNCFNKU4ApZnZdSumwHsyTiMwK1KsnIiIiMsfr1dUbUkqHmdl6ZrY/gJkNMbNRjc+aiIiIiIiINFJnQ0YBMLOzgDZgOeA2oC9wF7BuY7MmIqWoR09ERERESuqyhxDYHtgG+CtASumXwKBGZkpEREREREQar0hA+M+UUsInksHM5mlslkRERERERKQndDlkFLjfzG4ABpvZwcABwE2NzZZIndVzOOWsmpaIiIiISEldBoQppcvMbCLwJ/w6wjNTSk83PGciIiIiIiLSUEV6CAHeBfrF/99rUF5ERERERESkB3V5DaGZ7QK8AewM7AK8bmY7NTpjIiIiIiIi0lhFeghPA8allD4FMLOhwDPAg43MmIiIiIiIiDRWkVlGe2XBYPhtwc+JiIiIiIjILKxID+GTZvYUcE883xV4onFZEhERERERkZ5QZJbRE8xsB2A9wIAbU0qPNDxnIrolg4iIiIhIQ800IDSzpYGFU0qvpJQeBh6O5RuY2VIppf/pqUyKiIiIiIhI/XV2LeCVwJ87WP63eE1ERERERERmY50FhCNTSu9WL0wpzQBGdudLzWwBM3vazN6Pv/N38J5VzOxVM/uhmb1rZrt25ztFRERERESkvc4Cwrk7ea1/N7/3ZODbKaVlgG/H82p/A/ZJKY0FNgOuNLPB3fxeERERERERCZ0FhG+a2cHVC83sQOCtbn7vtsDt8f/twHbVb0gp/TSl9H78/0vgU2BoN79XREREREREQmezjB4NPGJme1IJANuAvsD23fzehVNKvwJIKf3KzBbq7M1mtkZ8b4cT2ZjZIcAhACNGjOhm1kRERERERFrDTAPClNKvgXXMbGNghVj8eErp2SIJm9kzwCIdvHRamQya2TDgTmDflNLnM8nrjcCNAG1tbalM+iIiIiIiIq2qyH0InwOeK5twSmnCzF4zs1+b2bDoHRyGDwft6H3zAo8Dp6eUXiubBxEREREREZm5zq4hbKRpwL7x/77Ao9VvMLO+wCPAHSmlB3owbyIiIiIiIi2hWQHhZGCimb0PTIznmFmbmd0c79kF2ADYz8zeiccqzcmuiIiIiIjInKfLIaONkFL6LbBJB8tnAAfF/3cBd/Vw1kRERERERFpGs3oIRUREREREpMkUEIqIiIiIiLQoBYQiIiIiIiItSgGhiIiIiIhIi1JAKCIiIiIi0qIUEIqIiIiIiLQoBYQiIiIiIiItSgGhiIiIiIhIi1JAKCIiIiIi0qL6NDsDMof56KNm50BERERERApSQCgK4kREREREWpSGjIqIiIiIiLQoBYQiIiIiIiItSgGhiIiIiIhIi1JAKCIiIiIi0qIUEIqIiIiIiLQoBYQiIiIiIiItSgGhiIiIiIhIi1JAKCIiIiIi0qIUEIqIiIiIiLQoBYQiIiIiIiItSgGhiIiIiIhIi1JAKCIiIiIi0qIUEIqIiIiIiLQoBYQiIiIiIiItSgGhiIiIiIhIi1JAKCIiIiIi0qIUEIqIiIiIiLQoBYQiIiIiIiItSgGhiIiIiIhIi1JAKCIiIiIi0qIUEIqIiIiIiLSoPs34UjNbALgPGAn8DNglpfT7mbx3XuBHwCMppUk9lcdZ3kcfNTsHIiIiIiIym2tKQAicDHw7pTTZzE6O5yfN5L3nAS/0WM4aRQGciIiIiIjMYpo1ZHRb4Pb4/3Zgu47eZGarAwsD3+qhfImIiIiIiLSMZgWEC6eUfgUQfxeqfoOZ9QK+CpzQVWJmdoiZzTCzGZ999lndMysiIiIiIjInatiQUTN7Blikg5dOK5jE4cD0lNIvzKzTN6aUbgRuBGhra0tl8ikiIiIiItKqGhYQppQmzOw1M/u1mQ1LKf3KzIYBn3bwtrWB9c3scGAg0NfM/pJSOrlBWRYREREREWkpzZpUZhqwLzA5/j5a/YaU0p7Z/2a2H9CmYFBERERERKR+mnUN4WRgopm9D0yM55hZm5nd3KQ8iYiIiIiItBRLac665K6trS3NmDGj2dkQERERERFpCjN7K6XUVuS9zeohFBERERERkSZTQCgiIiIiItKi5rgho2b2GfBxs/PRZEOA38zhadU7PaWltBqdntJSWo1OT2kprUamVe/0lJbSanR6rZBWZ5ZIKQ0t8sY5LiAUMLMZRccMz65p1Ts9paW0Gp2e0lJajU5PaSmtRqZV7/SUltJqdHqtkFa9aMioiIiIiIhIi1JAKCIiIiIi0qIUEM6ZbmyBtOqdntJSWo1OT2kprUanp7SUViPTqnd6SktpNTq9VkirLnQNoYiIiIiISItSD6GIiIiIiEiLUkAoIiIiIiLSohQQipRgodn5aFVa9zI7qtd+q/1fOtIK+8Ws9hsblR8zU71cmkI73mxsVisg621W+31mNiqFWaXQNrORZrasmRW68WgN6de8DbLPmlnfOuSjd/zbv7tpVaU7wcx6q8Je3Kyy7+fl9rWa81bPbZfLzwAzWzDV4WJ9M+tfj3TqbRbdH+qSJzPbwMyObETa3ZXlw8wGzIr7RV43zyPbmlnf7DfW4zg1s2XrkNYS3c1HxswWNLM1zWxwSunzbqa1bKP20Vnp/DYr5aUrs0teZ4mCTWpTz5NANwvs7MS0g5ntX6f89AImm1m3AwAzW7kOaSwNvGBmV5rZvFmh3c0K6NZmNq6bWbsB2Jw6HssRIC1lZst0Zx+LwLkfcFg311MvYNl4+oCZ7VBrWlXprgqcgGe1HhX2PrlKS7e3R3cDaTPrE3/Hmdmi3c1PpNW/OxWW/HqZ2f/d0c3KVBbEnWJmS9bpJH4BcHjNGTKbN/f0BjMb1p3MNKhispOZTTSzQbUmkDuHDDezQWY2uBtpzZ1S+tzM5jKz/bPjoEY/xcucA8zsQqjsY3UMOkunY2YWv7EP8A0zW6weeWkEM+tVa/lqZmsAOwPnm9m60P16j5mNAY6JdZi6cUxsYGZrmdky3czPGsA04DjgZTPbrxtpDQO2jn1j2S4/UFJ31n29G9xi2y1lZqvVKc1hZjbazL5kZgvWmEZWjq1oZtuY2R5Q37p6IykgnA2Z2epmdqyZfSm3rNS2zLVg72pmxwCHmtlyteQnVwnbF3g50u09808UsjPQL6X0f905oZvZzsA1ZjZXdzKTUvoAWA8YDjxvZgfF8qxyUEthNwLYP1tXZdMwsxOBP6eUrkop/brqte783quAo4B3zey0WhOJ37MqsAHQy0INSQ0B9jOzl4BF8ZNnPWwKvFBLEBE/Jdtuq5rZCcCVZnYs1BaY5NLb2MyOB040s23KppNLa6sIem8Hlsu9Zvm/BfO0jpmdAUyP8qImuePlQOBsM5ts3sNRcyXbzM4GTjGzB8xs8VryZWb9ohLVG1ga6JuNBKjhuMwqK8OBpYDLYnktPdGrmdlbZvYc8IeU0q8inZrK11yDxTgzG29mm5rZwrWkFenMD2wMbAfsZWar1HAu6hXrfhngYWA6cJSZbV5jxWw7MzsZbywbkFL6d63lYUrpf1NKvwI+AFY2s1fMbMd47fMy2zP/XjNbzsw2y9Kpfr2EvYC3U0qf1LKv5vKTHecbmdl55gHwhuYNejUxs93M7GDgMqu94fOHwNV4XfVUMzvBzEbnvqOW3/tXYGFgiuUa8cpKKd2RUnoNuNzMftCN33gOcCu+Lc8Fxndjvf8abzhaFTjZzPYxsxE1ppXfL9Y0s0lmdrCZDakhHcuVPdub2RFmNk+NeeoH7GtmbcCFwHyxPN/AWMt+cSNwKbAbcEfUHQunlSvHlgDuxOstN5vZWjXkpSkUEM5mYie9Bt/ZppjZNDNbokwFNFdhWR84AvgPcAZf1HPL90yY2abAvMDiACml/2TfVUNaC+CF5D8jrX9342R3PHB6SulfucKtVOWgqvL1CfAhsI+ZvWRm4yOPhU8qud/xADAYmFxDGv2BXfH19EVvUPw/F16RLB1Im9lYYNWU0pHAm8B3Y/mqJdLY28wOj9G1r+G/ccnccNvRZjaqaHoppU+B04HPgN54oLRKfNciZrZn4R9YyeNoPFjd1cx2svK9G/Nm+zhwJTAMeANYy8yeMrPly+YppfSfOKldip/YdwWGRn7LVox74w0O0/Hj6K1sv8/2syL7W+43XoD/vg+B0ZGnhcpkKHu/eYv42Xhlbzjwjpl9Jb6vVCBtZvsAKwHvxN9/mNlAKzGywMzmA44zsw3j934fyI7rrLJeONDMrdf1geWB66OM/k/Z4eYppefxSuIYYAszWzfS+Y95w2DhfOXKv62AS/CycTPgrOz4LlvGppR+j59DXsB/6yRgNzNbskQa2TY/ErgZ+DLeW7stXvFbv2S+nsTX/S5An/iOf0G57ZiJ8+WLKaUt8SDzeDN71MxWLhlMZA0x5wDX40HvDDPbPvJYKK3c+XseYB1gIzNbNqX0ea09Xrnj/GJgELAKsA1wiNXQAxOV4uOAPwNfolJpL1zORrD2V3xo5nDgj3iD4HFmtqeVGIqdXycppY+BA/EystsjmlJKWwN7AveY2X3mjSSFxLZfPKV0S0rpn8BDwGLAimXzYWar48fQAOBj/Py9Or4Nt4lyrkx6FuXMIsDXgN/i+38tI67y+/5hwE74iKsvlymrw3+A/8UbhjcA3oV2ZXXpIdTmDUh/im15BnALXt4W3sdy5dj5ePn6MfBcSuk1Mxtj3vg2aw8dTSnpMRs9gGeBjXPPLweeAPrUkNZtQBswEbgvlo3BK6JWIp1ewD7A/cBdeO/ewjX+PgPmwisr/w+4BxhZY1rzR37miue94+81wHI1pPc48JX4fwBwMvARcB/em9nleso+W5XHa4FD8+8pmJ8pePCWX3fZb5ya309KpLkjflI5EHg0li0MzMBPXEXS2Bz4AfA83jN1FHAKHvjeh1fYRhdMK/s9Y4A18IrB9cC38RPLC8AlNe4fo2MbTo39bd0Sn70J+BlwEHBRbnmf+J371pin/YFz4v+3suM6tsn8NaR3HnA3fvI8IPK3M3B1iTQ2xU+Qc0eehsfyycAqBdMYDDwd2+xYYL/caxvjIwveyR8bBdN9MtI+H5gcyzYBDiqRxqpxLF0MHIIHOPfGtn0ED6rPr2HdD4lj4QrgOrwHYJ4Sn8/Ki9H46ITd8YaC6Xiw/zqwdg35eg0YF/8vH/vIxTWksykwMfd8GN4b/d2y+cIDkDeAEVXp31rLsYRX0M+O/f4FoizEG+GGFvh8Vu60AafivQcLxrJBeEPc94BJJbflwGz7xfM94ph6CVim5G+cGJ//WuRvf2BQDesqux/1mGw/wBui9ohj4kZgTMk0Lwd2wMvsZ2LZgsDBQP8yxwDwNt6gCH4+mYyXFZdR4HyZ+33zAqcBW+KB5YHA14ENyq6zmX0P3rv0T2CPgp/5Umz7KXiD1g7Z+srnvWBa2+K9qVcDG8ayZfBz3NXAScBaNaR7GXAoMAoPcMAv4TiwSDq5fX8Q8Bg++iLbf58BvgOsX8P6vg0vH94BzsvtY5cW2S+q0joYOCr3vA9+3ty3hnydFOvq29nvwsuiyfXYzxr5aHoG9Ci4obyw6RMH9g5Vr00rejLJH8BxkJ+Lt4gvGstuoYYKNt7a1h+v/F8JnBkFb+GCJ9LpD/SLx3D8hPRd/ATTq2RB1gcPUp8Elo1lmwOv1bj+r6BSsTBgATyY+ErJtC6NQvAEvDJ2Bl65W6fg5xfDr0u6Bq+wrlj1+pDYpkNK5mtxvDX2WuDHVE7C5wPXVe8/BfavI/ChVn/GGy12A9YCliiYn+xEMh9eiRqbe21srLtjOvruLtJdDliNCKaBdYGL8IrV8iXW1/HAL4Ff0T4w3xv4Vtl9LD67Qaz/F4A9Y9mewMtl9tX4249o+ADxNgpPAAAgAElEQVTWBr4J3IEH9zsXXWd4o8XFwINEoBXr73slj8ct43h8GT+RL0zuxE1UVkqur2PwCuIruWXfokRAGJ8ZhlcWL8Bb6X+CNyatH7+/yHrK7/vj8ABuMbyitz+VIUm9S+RrRbzcySoWhh/3bwAX1rC+5saDts1yyxaMdVZm3zfgaOApvMK4VCxfCbi9hnxthAeqM4Btc8sHAnMXTCML4uYmGujwc8bBwHt4j/RlRff7eN8P4zi/A/gD0VgTr40FHqVEQ02ss7vxCnWW3/6xX3TZgIcH8OvG+ro6li2HX65xBV6GtZXIT1bGDsYr+O8CE3KvjybKoZLbc0c8aP4OsEIsOwe4s2Q68+CNMwfmlvXBA7nVC3x+LrzcmRfYEB9p8kLss/cDf8cbLtcos1908Z39KHDupVJOL4qff57Hr1ndP79tSn73xDi+3yDXYIc3KF2Al+NFGq/zZdkusT1fIsoNvO5yb8m87YXXcw7I5yGOr/UKppEdMxsAK8f/bbGP/BivK365RJ6ybbAW3qN3TnY8x+/dpOx+gZ///0ics+OY/R41dmz05KPpGdCj5AbzSsZzceCPwHvzXi/42fxBvh7eIphVErOewveIFrzODoLcgbkhfiL6MXAifgJeLwrcUpWySG8K3vLzRYGPD3u4n5K9jniQOgivELyIV3qeAbbK/4YS6e2PBwBfjueL4z22A0uu+wVive2MV2jvxysWr1LsJLcl3ghwSHz+VDzYWhYPnh4Gzqxh3X8z9old8B6+KXjl5VlgcLxnpiepqt+YBc6D8Naxj/DK0Fwl8pMV1lcDZ2Tp4oX/Ufn8dJavqjRH4C3yp8ffa/HWvL7AlwqmkbVwtgGLxP76z9jnx+PDRfYqu/5z6V+CV453ju3xXWB8yXW2Jl5O3Bv71V6xfAIlKoy5dE+L33h6pP0CsHfBz86V+38UXjF4Bm9MWZMSvWa5dPrhFemxeBDxKh6EHQE8WyKdrBw7Cu+9HIEPWZyCN2ptQcGGqNy+eB7eI/gW0TCAV0xXL7vu8WDtcvx4P5NK4NW/6LGEDytsyz3fI9b/oZH+qsA7NWwDi3V+Nt7oNiW2w4759dHVvpp7PgQPbO7FRwGs2dH7ukoL7wX8CV52ZQ0ic+HB/Vxd5S23HTcEbs4tH4ufR/6Fl7XLAbcVXFe9Yn2dHutoaqTRZeW8Kp2V8KDvM6JXJNuP4/cdTpTVJdO9Aw8kLgf+hJ9/S/c2Rlrz4ue4x/Cya128YeOHVHpGy4yE2RT4Bt7TtRKwNdFTVeCzbXhl/Eoi6Ivli+ANB+Pxsu2rtfzWejzw0SYL4fWJy/CRSJOAxUqkkZX70/A6wfF40HZ3pLVo/N7XgZ1KpLtXrP8X8PpTf7zMfpcCDUh4WZM1CKyJN3zcipe1K5dcT9lxORIfnbNo1evrULLxAq+fZGXCCngQ/Qu8DLqnYBpfNETllm0Q63pGpHVSs/avUuuj2RnQo+CG8p6btfGK60S8Nen+KCizVoxOA5w4YWyOBxBZBXs7fBKRh/CK7TZF0sql+Rw+LGQKcEcsG4CfoMqe7I6IPKyDt9bMH793ntx7igwRWQlv3c8eh8YJYDtgoRL5yQqg/IG+ZhSMP8KDuDNK/sZt4ndulVvWOwrrw/DrHaHrnrjt8eu5XsV7DC6LAuhJSgwHzKW3EXBr7vkwPJBem0oltKsKXlYwnkpVRQmvaL8BHFwyX4NiH98p1s/teOX9bgoOYa1K7wG8UWV3vFJ8YRTaZxbct7LfuDh+jUZ2Il4Bb1H8nBI9N7n0FsWHD82Pt8qfgPfWPwQcXsPvvA5vMFgkjs/pwBEl8zQM2CoeC0e+HsSvIyk0VC7SacMr0zcQow/id14Q2+AS/JrMMr/vIiqt1SPxIO4tvHK3WsE08kPJ7iJXwcDLoAuAk0vmawHgO7ltkA0x3xJYoGAaXwwvzC1bHa9I/RS/Nmu+EnnaHh9tsR3eWDcgll2Gl7MPANuXSG+ROH5OjPRWifV1KXBIyd84AG9ouw0fLrc2Xn5fAHytRJ6ybXkSfh3iILwh6Xt4EFZquDVeHt8Rx/Sm5IIj2pfdpc5x8Zn58J6aZ/BzQaGKP5Xgdie84fZBPLAcE8v3JILokutsCeCBqvzdjZdlu5f8bXsAX8HPaWPwRsDX8bLsgPy2L5DW2Di2e+ENM6fjgf49FBjmSaVhezDeaPE83lizFFX1G7zBsvTw61oftB+SfGnVa5vgDQ/7lUxzReDV3PMReBn0GtF4V+T4zB2b2xK9/XiA8wJeVnwdOLJIOnjw3gc/Z6+YS/fyeOxHycudYp/P6knZSIBBRENtybQeiePwMrwcWibW2+K5tGdaF84dQ3Pj59i78RFf68YxsDolL4No5qPpGdCjwEbyQO7HeGX4TWCXWN6/s521g3RG4wHEX4ghY7G8LzCsRDpZl/oG+Il8AbxSnV1bdAsFhz/m0uyF99YsGwfUmbF8e3LXaBVM62W8pXQ8XhG7k9wQqaL5ib/zRQF4Ld56tAne0juWgpXYXOF/NN5adBZ+XUQ/2ge7BwIvdpHW+FwhtBBeAT4ttkV/aguSBuAV4jdjfReubHaQ1rx4q/BAKhWfJ4legxrT3Cy26WN4xbYXPiR22ZLpLEQlIHmRynDAR4ATS6Z1FXBVB8u3B1aq4Tc+i1dYfoAHN6PjhFLLtcE7xm9aKLdsXbwiNZjiw+Uewxs/puKt2HtTooc3l86m+MnyUzy4zA8THQecWzK98cCb8f/ceHCydTf2ryPxxoqLaB8UDqBy3ViZ4chn4D1dz+eWf5e4rqdgOn3wkRcH0v6a41uAh2v8nRfi13EejJdfg/FAv2yw9AIe/D2El4tHdfCeQr2D+DntOrzCfh1eMVuMgsPuqtKcFw/i8gHbynFsfb1EOlnZPx5v6LwRD3SW6+p3dZBWVvZvEcfRfXhFeD488H2eAhV/vGf98ziGB8SyJamUr3fh55TSQx5j/38HvzRgVG75OAoO74/3z403WOSH9v9XwNxZHnPrfkIckz+LfW0DvKzuR8FrEPHz7fJUeoCWxcuxp/DK/3C8jJ2Pgj299X7E+voZHQwnrGFfG4yfw4+lcu35sngDSalgCa/jnEFVgzclhpXn0pkHL1sfw4P6wfE4hhrqBXiDWNbQlm3bkynZcIo3wD4cx9GRwFfxBoNtS+xjvXLffz0eAJ8ax/pxxMiMWo7LpuyPzc6AHgU2klf4syFf4+ME8CJxrUWZnS12/HvxVqN7iAACPxl3OSQTD7AujAN9brxn5TEqrX/ZjH9lhoRkB9VukdY7ude+BexT9HfiLTuP554PxHuWbsAD36IVu6zC8rUoYE/BW2VvxseZFxrzXpWPdyIPtwFHx/KtqQyNWp5Oghx8+MavYx3tjAc0R+CVlkNr3Leydb8+fuK9BW+1W56SQ2ojndXwHr1j8crilPiN1+En8zJD7/oTQTceBGYtdtcA19aw7/fBK41DYhsMwU9Wj1PuOqC+eEXsH3gvROlegqr01iWux8B7Wu7FT1SHUvD6qar0Dscrj8/l9uPl8db1TvOae/8IKtcoLRnH5uV440iha/1ifWeNVwfgFbGpeM/laHwY3wkUGHJdle7deNA8Ah8KNj3ytXTJdLLfuhReLt6HD7VaixqG3eXSnYz3vGU9mEcREzSVSGOR+NzUWO9bxPKbgE3L7PPxdxe8seIevNfsNjzAX7BkvsbRftKLNfFg99gy6zz+H0bu2li8YfGG2P9ruX5qC/zc+CR+nsr36g2Nv50NFc2Ct0F4sJCVy1vigeu11NYD1wuvqB8cx/oF+Pl7ZP57C6Q3d2z/PwJn55avjzcyFhrynvtcVs4ujTdgXIef27YmerMpV77uBtwf/2fD6rPevbKTRT0Q62oAXkl/NH7jCiXSyHpOp+K9lgvH8wl4r9ANZfexej1y+8bCeHn2F6p63Yqs+9w2XBzv3VoTPyddg5e5TwDHxXsKNy7i9bhnYj/div8enllLw8PasS2mEddJ1rju1sU7SPbCzzHj8OHII0umswm5kS6Rv7PwEStlOlpG4HWIbP8ago92uIqo580uj6ZnQI8uNpBXVg7DW7SyIRB98EDgmIJp/NfBi/eWXIoPO3wRuKtgWo/ira6bxInohDhBnY+31Be+tiiX5qD42y9OSrfFgTkF+HaJdHrhlYwX4rNZADEab4kt1btBbigNXpndCQ+WfkL5iWTmwVvBtyY34QjwCrBRwTRG4y3gr+OB6iS8cvFjPAB4jPLDdOfFg9Wsd3crfGjaLRSv+E8iN4Qn1tGjVBox9gGml91XY194KvKStRAvircyzpdt84LpDsFPctn1DFPxFugngCvKrLNcmmNjO7xJiQvZ8/nGW6hXxHsh8kME98EDlFINGLnn/fFeg3/EbzyfysQkHbYWV637LfBextHxvA8e7B9KwQAOP1Hfifd07RTLJsQ6uxIPep+qYb1vjgc2H+KBzjx4papUuRNpDaJyIl8BbyW+A6+8lx3KNAAvMwbiFbLn8IptoUm/aN9zmu0fa+CB4UP4cf94ifxk1/1uhzdGTcYD36/H43XKD+HeH+9xm0ClfF0Tbx0vMuS6T+7/eWP9HE1uOC1eES3UQNPBfj8MLx+uwBulNqpetwXSvD/229fxkQhtkddzKHFdV/WxlOWDSu/LpCJ547+HN66AT9byc6ommCu7zvCemmwo37J4w+fNsc+VnRBuCTyYXyq3bDdyw1ELprNurPv8RF2rxb5SaPbOqvT2id90Ld4oku23S3e0fhv5yB3XA/Ee5+Xj+Tr4kPdfU/y8m6U1HK/DTccbrU/Bg8GHKTiEO79fEGVi5PEY/DxyAl7fK9tztgreoLJl9h14eTSduNSpQFpZQ82CeN1z0fibzWR+NwXrwrk0z4z96XNi+Gks70fJ61zxeQ1+E8fkMrnly1BgRuNZ6dH0DOjRycbxg+cVvML5DN4rtHR1QV204I6D++v4iXJgLFsmCo9saFSnF9vjLeifAr/JLV8hTgRn1Fhg3x8H9wp4BXnvXKG2WLyny0Ib76rfAW9dvxEfHnU+HlQc1dXv6yC9jaMQXIo4ocfyaUQAVXJbnotX0LNhi8dQsOeA9hNz7BvrZjRe8d8Sv57k1BrW/b148PxwFJJL4BXbScAiBdNYObbb1eRmCIzXhuEBa6ELyKmcSE7FK3Vr45McPIcHEW3EMNsSBfbccRydDvwfldnJJlD8erP80K8zY1/fILbrZniFu/C+T+Xkew1+InkTD6L3rn5PibQWjnydQuWakdXwBpLPyA2l62Ldn4KXN6/hvUm75t5TeOgRfnJdA2+8uglv5BkVy7eLY7VwDxUelK6EV85XojKF+lqx/oruD9m23B+vFNyCVxY3jOXbULCinUtrn9h+7+Pl2Si84jKSkr2NsX89gk9bnk2RPwwPsAsN7Y/v/QivyE3N7fND8OGP5+I93WV6DdbBh3TuHunugF9D+BBxrWVX+yxe1nyJylCviXhZfQDekHQlJWeijHT2jLT3wxsItsUbPKdQogcaDxieyz3fC+8BXTq3rEjPzVJURjcMxoe852d2PYC41VOJvF1K9BTH813w++K+h5fZRcuL7Dg/C2/8exCvF4yP5ZtQoic0fyzgvSvP4ufwI+K4XDf/vQXS2TaOpemRTqlJp3LH5NzxN5u5/EA80J9CyQlN6v3AGztvxAOa43LLJ1Hi9kfxmZtjPY3DGzCm49e+7kRutt0S6e2B93jtjZe5y+Pn4vspUP7k9q8lqFwC8QleD8tud1OoTKT9aKFX8LLxH1R615ejZECPd4a8ipepa+KXO70P7FYijY4aos7Cg/oLmY2uG2z3O5qdAT062Th+kjsr/j8Eb7mejJ+Iy7bUTMJb1XfGW0VmUHWPlc5OKHjvTDZl91N4S9aL2QEey2u53mkc3sv1bXxa71up7V5KC0Q6o+L5cLyifhkFZ2iMz2Unkz3wyvpc+Mn2bSo9ZzcVTCurqA/Fg+neeIXjMXyWrruI6y06K9Twyt3JVG5DsEjsB5M6ynuJ37o/HhCOxSuPl+EzjR5DZchPVxW8bH3tgA97eRevIGa/a0VyAUXBfM0bhf8QvDdpD7yx4HfUdr+0r1KZoe6VWLY4Be9FmduOC+CTCW2L32pih1jejxJDO3PH5FC8IjZv/L873tr5DXKt4yXSfSB+5yPEBE+513bFj/sOJ5bJ5WkAXkHMeu13j33/RUpcG0n7Xoj58IaV8/De/0Mocc1yLp2t8HLnDCq9egvgQyr3Kbkt++OVlaXxYel34I0il5K7jqqLtJbBg9EBeAC9Dt5AcCo+G3GhPFWt/y3xSvSQWE9P4GVOLWXreLwC/ClV12nGNi1b8VwCL/ufw8vGq2Jfu7REGtkQ1u8SMzviPUIX4uXrZIr3QGdlz5fx3vSD8DIoK7vmpzLtftFgaQsqDXZZOqdQYBKNfL7wgHkeKuXgbnjg9hBeVn6P4j0kWfB8NDC1ozzXsJ+NxBuxFsaDkqlxjN9CyV5QfEj56sR1vHGc3hzHaXbOKny7ong+BA/gsiHTtVwec2/sn9cRIxvwivsF5Hoxe/qBNzQ/H///iMps6rXM/rwwHqgNjOMy63H8LlF3rGHfWBa/Dv3qOCazhreys4I+iDeobIUH+Kfg583bKT/64vL4/Ep43cDwc/hKNewXB0Xe+uaW7QP8jQL31aX9uW0zfNTFRLwetSJ+Tn+Nbl5K0pR9s9kZ0GMmG8YrOu8DF+SWLYGfOEvdfwqvsL6NtzRfhl9jtB9eQfyviTFmksbFsaMvnX0GbxH5I16ZKnUdUC7dd4j7HuHB13TgtxS8JiWXzjXxe2baylOy0Hidysl8h/iNP8BPcmVuLr0jPjRxOh6Ur4O3ui1WNF94L8sleKDwP/jJbf8o9O/N5bPsEJ+r8Z6Mc2L7DsYD8xsoP7z2Yiqtdpfj9x+8nPK9I9lJaSweJD1NpaX9TirX9RRtbc4m51ggTgLZMNZDKTnVeHzmyFhP2T2G5sFnNiy9/+OV38epVFr74C2ep1J+wpzlgSfi/xeJa1zjWB+Te1+nJ+LYX3+KNwr0zi2/lIITM1EJuubCG2bWx3uj5saD6euJxqUa1tmyeMPWW3E8DaK24HJPfJbMxfHGsYFxjD1NwUApvv+t2M9vof2ENBvE8VV2YojLgVNyzwfiIxJKVxbj8/3wCtD7eKVsIh4oFh56mm3L3P/H0/6G9F9cL1YwrcF4D9oLeENU4YCmo3xFOoviDQ5nxfLdgc0LppGVOdvjvSpvAoflXn8w/7xgmovjQ9xuimNpFB6gno2fw2uZTCMbxr073hBxGCVmh61K6xC8B2gNKsHJRbH/l2qMwnujTsN7XR6ng2sZ6byxOVv/S+I918/hQ7YXxHtwzqTk6Bd8ZMST+Cia3fB6z7WUuOVCox6xjx2Ij/S5JZYtjfeslp7QDW+QWiiO77XwxudvULkMpJbrcefGg5uz8OCm7P1T58MbRXrF9swuV7iJ3PWvXaSxMl4H6I3XL7JzeDb65VBKnkfwxtfz8XPkefgIh1pH3J2Kl80P4OX2ebl1Xur8Pas8mp4BPTrYKN76kU248HO8ApQfl5+13heaJh+vFGyJ9yzlpyW+OSu8uzoI8GFUl+Eny/wMpYPxk9RvKdhrmfvsfPHblswtWxSvML5KifHv8dkz8OEEN1PDbIi5dNbGew02xk9Q0/AT1DFF0sUr9dn1IU/g97PaFu+pujLSKlvhz06am+K9ZhfgldDPgctr2L964T0cA2N9LROv3UnlHoJFK3hbAf+h/UQHS0ahW/Reddnvm6tq+Rl4JeMuYsKCGrbnnngg/Ww870/cH6vIuoq/Q/EhUFfgrfvZJB9HUfD6yA5+697x2+7GGwqyinUt02cvijeK3EXcOy2W/ZQuGh/wgCFrpV4SD5TuwSuupXqRqn7fJbGPPhjH0K6xfDjlJ4BZm9ysk3E8/QlvaCnUQBPreG088F4gtukeVGY03oXyMxqvgDeg/ACvEAyL5VsTM6EWSCN/rdQEvOFtWSpDox+kajRHDdtkfrwi9PfYJwq39uOTJpwe+8WS8Tu/n9ueRYZQLkZlYpdv5Y6r7PY57xHXstWwnx0T2/HZ3GtPExMaFUxjUbxhYBE8CPkBHuxfR8nr2HP/r4b3PEzGy429KDd8NVtH++Ll1V2x7T7Hz0v3F/mNufR2oHKPyHnw8+9hwAmx7HgK3poml+ZxeLkzIvaJgyKvT+AN2GUaYR+LPF4PTMvWQRyvXY4aon3PzXgqk6n0xYObQyOvpe97Ws8H3jiQjbLKrt+8BTi/m+keGvv9G8RImpLrf1e8B2+d3LIheHnU6eUG8d58A+JGcUzNE+t8fSqTr3TZSBz75rN4PXhg/LafZsciJc7hM0l/VbwB5Kv4hEPZduiqHrw23is7AK+jZnXx0Xhv6m304DWpdd83m50BPTrYKJUx7/3wytPk2Pmn4BX5IoHgFxcIV6V7E17JPpuCFew4qHvjFZP/xSvG65O7/oeqWahK/Naz8Wuolo3nm8UJYaPIa5eVY7zytET8vnnxoObPdGOGJ3x4zgzgtHi+BXF/sQKfHR/r6r78Oo687R/LS92Wo4PvWDp+9/EUnJQm99ls2FY2w+xX8OGYU6jtBtV98Rbn7N6MXQ676CStc/GW3YvxVtR18ettziemQC+y/+e2wzXx/+H4ye5u/ARX6l6Nsd3OxSvF38CD4In47GY1XY8Sx5XhQ96ewwOoQsNY4/PZMZ5dD7wn3uN+DH4PsDuISkZn6wy/pqtffC7rrRyHt8zfipcXZXuMR+Nl1nz49VMX4EPTHiYmqimR1pKRj5OiXMiuDToxOz4LpNEfD4aewXv2sgrAcrHvT8UrHNn1ToWGSueerxn7xbQ4vqdS4L5meKD0Ad4ok+3fl8Z+mk1f/lKtx1MH3zeWmBG6xGfa8ArZ3XiZfCF+Tep9xAQMBdIYF7/zEyLopn3wdDK5Xscu0sqCuKwB5Qi8QXIqlYbUZ4qklUvzKqp6LvDgpI1Kpa/Idexj8OGTpwCTY9kSePl4BV457nKmTLzimTXSDCBmfcYn6XikSBpV6fXD5w64ES/HsmtKV8CD8Ytj24wskWbvOAaHxW/LzpXXEsNuu/h8PoBbFS8b5sLLidVi+dUUuOdg1X5xeKT1D3KNynhgsVj1dzf6UbWfZ+feL+FBYDas9Xlq6MnrYBuvhp/3suHUZYfqnogPMX8IbzRri7wVafRZBW+oO5PKDNWGl9tP4QF/oVE5eHD6At6Id14sOwWvf9Z6Dt8e7/F8JdbTInij7NcoOHMzXsfZMNb1I3iDSn6irMepsS48KzyangE9OtgoXjG/LXb67KSwOt4i2OWtIarSuh+vtGYX826Id28/TOUeKZ1VFlelcuP7HfFes4viIDo48lXL1Pj9qMwUOQmvrD+ID09oiwPtlgLpHIAHlE/hlaovx/JN6OD+WCXz90VPLB4cdjkEiUpldSw+7PQXUbiukHtPoUpUA/evqVGofiv2s/54z+MhVG5CX8stJ+bHexKyae17U27q7F1jO26AV/IuAg6qem+ZFs/58Vb1E/EhMMPwQH+5svssPrTkLTxYvSrW4e2UmNmSykl6P7wH7tE4DkfjQ37up8SF7ZFW/9jvF8dbcw/FK3cvxrbI1m2H643KzMXrx+97O35fNkPlTtQ2vG3/KC82Ap6OZWfjQdOYkmnNhQff5+MVzxMj/dcpd7uQU/Ah0afgFYN9Y79YCg8iNi+yj+W24zh8qNxRRC9f/OZ3yU0U0UVa2+OV/6vwHpZjYvn4yNMh1HA9aaMeVK7dXB5vXb+X4tf8rYYH3X8ATsot34raZu88hwi68fPaa3il83oqDRtFb+lwLFU9NHEsnV4iP3Ph553r8WtID616fV0K9sDhvYnD8ZE969G+9+V8KtdflpksZGisp3OoDGWdBx+atxcFZ7eMtLLGqAH4+fF8Ktf5PUaBof3khkfGcXgCfl7K5ioYHMdElzM15vIzEG+AGoU34s7Ae802bvSxUSCP2TX7F+HnopXwIZ6bFPmNNXxfmXPvHlQuPZkb7xn/BB+BsW+BdPrgvbBX4gHlaVWvb07BUSFULhG5C7+u74bca8Op4Rwev+n7eFn/I3KXJFF8oq5TyN0DFu+8uDG26wZ4fbjT+0jP6o+mZ0CPqg3iFeHb8JaRj/FKbV/a38C8q2mqs4M8m7DlGeD3eCV0nqr3dlX5ORbvIl8fr0BlN8XdHK+I3k75GTdXxa87uAUPTpeN37gyXqldEA9iO53lMj7zRBzko/BK1K1UXVdRpGDs5Dv6xLYo2hOxB17ZvCsKrgXxk+XjeMtZqZtAN2D/ym6GPDbW20VR6JeeyKeT7xhLyWAcb0m8m/az6E3Ae5kKV1Ryn80mF1ojtkfhoVWdpLkQHtRs2Y00skrORLyX90C8JbTscLmsAnQJ0Quae20A7VstOywv8MrTyXgv88t4T8aCcVy/XXYbVqU9f+TjECpD0k6n/O1aFsJ70YbjFe6to0y7h/K3+hiFB6TTIy9TYv/fkNoatV7Ch4uehVcMzsCHRc1T5HiKPDxCJcgahzcefYeS95TryQfte3Y+oMDw9yhH+8U+tzQevP0MD0R+TPEJnrJz23Z4o0fWALdO7B+lh1vH51fAe3f3w89D8+O3F8puTVCmIepU/NKKi/BzQNZYsC/FZmk8Ar/ubQE86H4R72VZLl5fmRLzCNC+h6ovfj7fCb8E5Dq8V6fsjcsH4z332b02N8DrK/cSDUAF0jgF71EdEs+/jF8icyjeO/soJQLySGN/4MmqZcfjjRCr98TxUfXdY/EybAR+2cKWsZ+9jA8nrvnSljrkLTuWRsdxnA3pHhb7yfyU74CYgtc3L8aDw01j+YkUnMgn9vexcQy8hDfCPkuJyQE7SPNovLwdTWViuYGR3yINDgvjvZPZzadJSF8AACAASURBVOezSwN2x0dMvIifNwuP8JkVH03PgB65jeEtbdfiAdIZVK5t2Z6S17bE5zqasOU3FL+J8EZUbiR9Pd4reCbeotUHr/CVrhzHSeikOIkciQdPZ1NpoVqMApMoRL7eoP2EB3vilb4Fyuark+8xirc0zxMnsj/TfjrplaNwK3WCa8A+djPRSh2Ffl98WE6pmUAbkK9xeKD6fXKVYbx1t8vrF6rSmhtvAPkGHnB9A5+84npKBuR4sHAG3vMzME5sT1Hw2tsO0tuUuOcnlZ6m44hJE8qkhw9Bfo7K8MesZXU9Cg79wivn7+Mnu42qtscvge1q2JaDqPTcjMUr/NfgFcZCtzKJz86HD+85Dz/hnkZtky4Mya3rufBK40ZUrpe8iwLDO/PbBw8us+G4C+IBfna7iHEF0lkEr4QN6eC13aNce4FZdPryKBMXAc7o4n3Zeh+NB3Hr517bEw/sS9+kGh+uOi627aV4q//7xDD4Gn/TBLxy9wbec39iLC9yiUY+6Jor1s8EvMHzMnz0S5fXlMY6/RG5BiL8PPkU3via9RwWnsGQSsX/CirDdS2OzQNjG5SatAivS9yDX0f1Y7yhcRF8xFA28qezmbN7U7lk4R6817I/lXuXfpXy95brjwfTb+CNzeNzr/X4dYOxH1yKNwxcSvte8S3wMu1lotxuQv6yY/MeYtIkvAPgtVh/Ra/Nzs9cezcePK2OB+I34cHcKwXTGoOP4lgMb+zMGguOiu36EDUMycQbfI7ER0VlI952o6rxoJPP34rXzQ/A68RnEhPSEJdxNWMfq/s+0ewM6BEbonJQ7YYPuXgn99q3iCnMKT4DUrcnbIkTz35RmF2IV1xviDSOo7ap8beIgyu7/mMRfBjq5ZSsGMS6+jFeKc4O8i9Rw82u67wt14/C8MEo8CdGwfEmlZk4e+wahuz78JbKD4G/0r4n7l4K9oDWOU/tJpLBh5SdFvvYw5S4zrWDtA/FWyo3jX3uJXz4bpeV9ap1tifeuvgqfk3epfikDoUnkqF9ZXFQnNj2yy2bRNVtIgqmO1esr69ULf8hJXoc8WtuJsW++nAc96sAt5ZIIx/cXhe/8Z5YNhYPBsr2gt6Kn8R3jPV/fRzrx2bbp0AaO+MThDyKB4I7ULn/1xqxDgsNJ6MSDPaN/WsG7RsvRhFT7xdI6wDi9jVUTcYVx+mq1NAzPis9cuurFz6M/Gz8thC3UfCWCx2liTdGno43Hj1HDM3EA6aaJpnIpT8A7/0aUv07Cn4+u05vWhxDg2P/PYC4JUAXn7+eCLLxnpo9Iq078QaCGdQWQC8X62uBquW9yNURCqa1Ou2vjd8ntm/h6xpz+8YE/Px4JV7vKd0A1UHay+O9tDfjFfcVym7Hej3w4eAnx3Z9DT8f5RuwC10324B85W+5cAIekL8ced0wjqVtSqZ5Arl6BB4YrodPSLhMwTSymXl/StyPNLevDI9ja0LJfA3Bz7sP40NQ16cym3DWcNnVbb9ezz0fH2XZVDxQrWkG6Fnx0fQM6BEbonK9Wj+8QnUbPhRpCiVmOatK84wohLIZJAtP2ELl4ufN44Q0Iwrt4/DevQepYRgeXvn8HHiwavlICl4IHe9ZMv7Oj18L8R28ZfUhKpMzNG04RrYO8YuWvx+PLif46KF8HYjfLuQdfMKic3KvNeOkeQdREcCHSU2M/f+h2NcKb0e80SPrFT8Z72FcFu81LDQ5QSdpr4oPs90TWKPE57L9+jA8ILkC7y17Bm/R/jEFJ+KhcnLcJI7FzfFhVl+Pk9ztwI21bEv8xHkmlVkfC91mIvf5wVFODI1tenQsH0PJezLFfnB5/P8Efp3Z4rE9J5dI5yC8l/FtvFdju1j/P6HqGq8S6/5KvLHtWnwY2EWUv3n2GLxczVcOs+GPE/DKS+l7D85KDyoNPufgE5kMjDLnQnwI3xRyE5MVWff5dRXlRHbvu42B7zb5d2b3kFwZD0g+pMDkKrl0sh6l7DrSKXggeCHeqHUx3tBbyz0pt6DqFlNxvJ9aNj28AfEqvJcva9g9GTi5ZDor4MMB58YbQbaP8usJivfYZ9/fhjf+nEkEvXEcXUfcaqiH94n8cb1N7BsXx/Y9nCZeF4zXtb6Vez4UD2yy8np+/FKNwtc14ufF++Nzm3Wn7Irj53W8B/VEvDGjpvTw8+QVuef74j2Qk4n5CarLlpmkU92QMgg/307G69Jjm7U967pvNDsDesSG8IPpB1FI9sYDiVPwlsVsZqxOhy1CuwurV8ZbU7+CT298HyUnbIm0vksloJwYJ4NvRgFStpI3HG81WgqvDH8KHF7DumrDg8qbqUx+MRY/gT4YhUjdromrw7Y1vDei0wk+GpyHHfFey/yU0pfgLWZfa0J+snXxpSj4+8V6OgAffrQY3jp+LT7kqujMoofirdXT8WDpJnL3ZGrC78z2z+3wBovr8UrYhXEcnUjJnrNIbwoR4OK9GtkMhofmvrOmhge8QlC4JzX3uY3xVuKVifs0xvJHKXFT+/jMkXGcD8WD3Wwm1QcpN+x0IbxSsDNexp6DD+uehxK3ycmVrcNif8qeL48PE/0lxXsHDR/e9gje4r1i1esP0Y3rN2elB94odgEezN9MTJqEB9WFzkFV6/8oPPj4GpWZKPvF8b57PG/KtO+RpyNyzxeOfaVwDxx+npiOj2h4j/bl9SvAhmXXWfy/GD5C4lAqIzLOLrMN4jOr4SOWfhbbYb7Ylx+gQM99rJNT4v+jaT+Msi8+hH0SBSZeq/p9b+MNdW/jjTSnxXE2kErjdk/OLDoOr8NdSQQk+GioffGg8Jrq476H99V58cDtb/l9Cg90biEuVyqRXh+8vJ6Mj/Y6nJJlfi6tNfEgejkqk6/tR233m/0eldFjE4AdOtuPCqaZ3+9G0uTLbeq6XzQ7A3p8UXhcgLdc/AEfKlUqoKFywlwNb2G7FfhJLBsUB1nhCVvicwvHyWmT3LJFI5+FWvCqPvdS5O0lvMV/b3x20Wkl0zonCp6n8Z6u/DCFLGjdqNnbdVZ5RMH6XuwTj8S+tla8NgwfPvcZzbnOYmqcmFaIbfoeXvFZHh/OtCYFW9/wIcTXxf9b4kHXkXjjwVlN+G0j8WsXT4iT5OhYviHeu3cO3uhT9oS0c+z7XyF3jRntW6V7pPJD1ZTqcfL+iOhBxSeKKDWEG78f4GN4j0kvPKh/Am/UuqtgGkPwa2PvxXtQs+D7Mrxn7pBa1hFe6fwg9tvhueU7Uv5WACPw3sWpsS9sh1dkX+vpfbXO+0Q/vIEiPzNm31j3l+CV0W9ScKgV7c9t34ny4kf4RDKGn6dKz1Jap9+arxxuiV/vOoBKg9c3KVFhjN+zAj60cLnc8onUePsR4mbseMPIlfg5/Sp8NtzCk4bg5/BHYvuOxXtDX8Ur7flAuLOA8IYoE8bjAeo7sd/3z72n0AQ3sa57xTFzGR70vobP5voePktmoYlMGrBfLB/H9P/iveP5Sb7WoeSEWPXcX6v22QNiOzxHZdTVegXTyka+LBv7/vp4XXNvPOi9geLn7iytvfAGwPfw3vGJ+JDkNyh5L1a8gfLh+P9o/JzyHt4Q0q1Go8728dn50fQM6JGg48lffkvByV+q0vomPjxkP2JYZhywi8T/wykx5hm/7uZOfDjHkCjMSt2IO9K5OQqKcfj48Cfjd25CpQeyyMX7XyF3ITBeSfgV3hI0PpaVmhlrTn/gldgD4/+V8UroXbQPpEvdKLyb+cmfkLbHKxYvUmnhv5Uahvngw0xWyqV7Gx5c9Kdkb3Ydf+v4OH5+RbSMx/L58Nts1DKD6tqR5rPxO4cWOXYa9Pvyw2F3wodF/QKfBOMM/FYWZa8dfJWYtj637Fw8ECi0HfGexMtjfx+KV1Dejr8T8J6bgwqm9cVQ9iifd8SHol2NN0LUvG/hvbG74IHSy3hluWk9B3XcL9bDJ+25jZjIKbbFvXGsf62GNC+L42k88GgsG0bcVqYJvzEL+gbEvpkFWVPjWDiPgveu7eQ7DG9YeocCtz3q4POr40HS/2/vzOP1mu88/v4QQSyxxnhZh6nR6JQQL8tLTSodWjsjtBplKrV0Hdoa1KjSmpQ21aqlFIklSKuWorSNrSi1NSnGUjvToWNpEBHlO398f497chvJ89z73Ofcm/t5v17ndZ977nl+53vOPcvvu69f5BxVrt9P0kR12G5jnUNXs/eNSQPeDDKy6SoWUmGx3DtfJ5XSW8ky/V8u5+3fu9/zCxlrHPDz8vlYMhLgFLp6IR4BHN/pa6Jyzv+NVD5uKsf4Q7oU86/RYt5mG2VrGFfWpOIUKM+fV2gyb7xy7a9IpsM0DK+NdiPr0EJLpsq4t5PP62+SObN3kQbBD9F6Jdx1yXfkM+ScZzWyNcaldZz7gbAMwdSKpOGktfNxgIh4S9IE8iE3TtJrEXFWk2P9HWkVu5G8mSaUP32ODP2cEhHPAc+1IOJFpOX/Q6Rl5QWyAljTSFqNtApfTiqsu0bEQ5JmkkUApgNExDtNDPcM+QCifOdeSY2KpYdJujcinm9FvkUZSSPJicDeki6PiBnADEm7knlaSFosIv7YKZkiIiQtQVdT2GeBuRExQ9I2ZOjJhCKbojzdF4SkrYBZwMqSTiAf/NPJ3LxpktQ3R7NgIuIGSbeRx3q4pM3JBtgzSY9XUzTOQzlvD0XEfuV/+AUyNPZiSTc3eQ+1BUkrRMQrknYnJwQ3k964KaQH4QVyEvREC2MOI6tFrtrtTysD70TEm02MMYo0Mu1VWf3Vsv5UUlk9tMi3UCLi7fLxOlIROb38T3cnQ543k3R0RLzVzHjdxn6ZDGWd1up3+yOSViKfN7eTz5cRwK2SziCV6M+THqa/NDneYpVr+mbSg7A5ed4hwxaXjIg5bTuIJqnI9WMyf/Z3wFukR2MpMrTy2l7uptEm4syI+EUzX6ies4i4R9IUMvT0AtIocp+kYRExu1khyv91beAqSYeRRql7yFDRs0kF7ApJm7zXPVrmNicWGVYnvWfTylgfBj5T5jsPNCHSXOANSVOBmyLiBUmPAsPKfGMnssBP92uoT5F0DBkBMpNUerckFZP7gdGSDgfmRMS3OiFPN9kWj4i3JW1CGuuWkDQH+ExEHCHpFPJ9slAq5/M4Muz9WrJf7Z2S1iPDOy9oUb6xpPFiKFlZfBNJm5LzxksjYm4r40XEk5J2IQ1sd0gaQs5nf1z217HrYsBQt0bqJaAXxV/mM9b3SavdN8rvG5GWqpbLtXcbdwXSqtSjst7kJGEEGVK2JWn5fDe3i+ZzxFYnrUbnk9ap5Ukr0Gbkjd5SZaxFfSHDgyeRD+z7KInj3bapI6fxg6SX8iwqxUvKun3L55bCOkgr8910WYk/SiWXre6FnCAfU+7Pc8hc4WYS2htW3Y3Jl+OZlKIAZC7c8VQS5zt0LOsy/3DYMaRF/AR6EA5bxtiXDEPbrdzvO9FCGCVpUDir8vsQurx8R5LRE++nRa8SGebeKBW/dWVfW7cyzqK8kHnKt5EeqMY535ZUEG9oPJ9bvS7K/21F0oB0e7lGPka+23qVM9vD42zck0uTnrLGsW5M5vc+TQser2b31+J39ivn7VrgbXJucCv53t20B+PtQRp0LyvPshUpxpvy96baJxS59iYjAX5N5k2OoMUKo+VaeIP0+i9NVnW9kXyHdNwLROYIPk4l3YeMYLqWNPrvXJ6PtYQ3V2SaTumtDFxS1rWS51qN8DmUfJdfR+n/TBb5ayk3tTLe0kW2a+jqAX1ei2NsQM4FzyXfs43CU7sAl9V57vv7UrsAg3mhDcVfYJ5GvfuTlvp7yMqFX6fkGpVtakm27ybvwUWm3wHfLuuamRQvR1ooR5MT6UnlZXQBaXlegpxoj6j7GPvLQlpdz6j8Pra80B8ik/dri4MnLegbk7lcZ5MhKxvRi8qwpOehUa13MVI5bDnMqgPHvhE9KBpC5tHtThaluaisW6f8bBRO6OSkeEHhsHvTw7YJZSIwodzjD5E5JU2XGicnl/dTqSJaOT97lefGIyykqAzzTnyqnw8qY5zPfPoIDtaFroqP48hJ8Dz/N9I7eHuzzx26lKw9G+9BcrJ3QBn/pMb9Xde7jQwZnkwqqI0+oCJ7SXY8f40M1V2rPF8nk97KT5Hh9FPI1ig9MmCQ791hjfuGnHSfXD736LldrolHyrXSapG60aRyeSFpGGiktSzTGKuT1wVZSKXRSmbZbs+MydTXYqLa/mVt8n07gjQONAx5Z1NphdTkuAeQFcsfBH5V1q1LzsOaqpq9gOvsFFIpfJjWq11PJz3WO5Pvoal0GaIaxclqnwv3x6V2AQbrQlfxl/PoffGXRn+5c8nY62PKQ/J7dbyUFiLrkuXYt6O1NhPTyMnnXaTCO5K0UK5AKoP/CZxQ9/H1l6Wc54tIj8ZYSvGRcq4+UbNsIyufVyJzXm8lrYy9zv+ky7LY8d6KfXjO1qHkd5DGlEYz+u/Qht5dvZBrSVJ5e5BsldCjynLvMfZyZLhcT5rRjyW9jF+hK690eTJ0/kCabHdQvjeeLFSxbGXdBFLpbGmysigvpLFvmfJ5cbIi6E3lPTSyrG/VM7g8GdlwbGVdre046DLC7lXeRb8gjQMHABvWJR/pobqF+bQLIMNsz2vTfkQqlt+gywjQY+MiqWQe2kuZtic9jjNpsuddH5z/RgRHtYBMw0D5FTK/uo5onLW7/X44mXbTKMC2JpmjutDnLF1ztr0ptSRIA9D/kHmkl9CGeRg5L9icUheihe/9PUU5bZx/0klyankm1dryq78vDcuB6TCSfk56tlYDdoqIvSRtAMyKiP+VtAYZh333AsZo5BV9sXxvcokP34q8oVYl85Ve6fsj6hnN5IhJ2gP4YkR8uPy+H/lQ+1RE/KHkVa0XEQ/3vcT9n0ZsvKTtKBXcyFCaO4HHG+e72fy8Nsu2DhlqeDnpwfm/sn4iMDMiprZpPyIf/m8vdOMBgqRzyVDHGyPi6JIfehkZmjarZtlWIi3k40jP7EFkzl8tLxhJi5FGp+1J49EqpLX5jYg4pJnvR8kvKTmpW5EW66sj4lFJ48neVD/oq2MYSEjamvQOXEX2Dr06Mp9odfJZPRb4bkRc1OK4w0hj30HktX5URLzYTtl7Ssm5Oq1yPWxHhjBeHxFX1SDPj4CXIuIoSR8gUzPOLX9emvSqTo6I89q0vyUi8wL7TS5Wqb8wJXqQz9vL/TZayVxMRnr9ICLur/z9CvK5/f1OylX2/RmyqM1BETGl3JPfIZW4tUilaXpETGphzN+S/TLvqKwbT97/r9V5PUi6GfhFREwsv7+P9GbvEDXkGg8krBDWQCn+8nXyRXkzWe1upqTvk811p7Qw1hqklfL2iNizsn4safH5WXul7zySdiTbSBwhaWhEzJV0FKkEn1a3fP0NScuRlvU1y6RsR7Ki5WzSSvy7muVbkrTY7UO+qH5FhqxsGREv1qGo9kcqiv1HSYVmC9Iyezd5znYgrbSnNgoG1CguAJI2IsMEOz7xmR/lXhhB5rncAbwcEXNaKFZ0ADnB24r0Ov+Z7HP2aTJccUZfyT5QkLQCGY2wO1nM6XNkeNp9ZCXIJ4rC+EI0Ubyqct0PiYi/lnXrl3H/mSwl3/GiHN1k3JnMhz8qIk4q60aQRpHfRsT1HZZnWzIFY6vy+3QyrPzcyjYbAE8PhklxXUpqMXgeQoatvkQ+q/+JzGPbutPyVORamQwZXo2sgPooaaRZFfhjRNzWwljDyDz2aRFxdWX9OcDUKEUCO015T65MpsqMIUNXbyQjkG6KiJP6k/GiP2KFsCaK8jeGrFp3bJlI/ZScFDdVga0y1lhSwRwCfKehBFY8iAN2gl28g4uTVudzI+KMsv6npFXrjIF8fH2BpGnAm2S+zTDyBfAIWezj7Ih4tsPyNKqbNULKJpX1I8lwsqeB24qHu18oNv2FMsm8mVQAHyPzD9ciz9mFEfGbGsUbcDQZkdBQSPYie1neQFZmfocMy7sN+G8rg4mkfchcsP8gq0afrKyAuwtZdfNeUjl5o8VxTyDDxmaQ3t1rSA/514BPR8Qz7TuK1pA0lHyufoGcXB9X5/VQvDPnk9XAlye9QXtU5gDfJRXppif+pmdIWpGMTBhN5nReAtwSEffVKhhQIsguI0O5D+tpZImkfcn7+xIyhWEUGda9ZZtEbVWe6nvycbJQ0VrAU8BPIuLKOuQaaFgh7DDKEu3Dy7I/aUm6mHxwXBERp/VkUixpcTKR/aCyah/g+YFsDSmhDT8nk4PXIStGvUk+gDaIiLE1itcvmU947XjSE713wzrfSQW6MiEZTuZ/bh9ZDvrda7xbeJ6Ve+Y5b4eRYY5nlonGSLKQxSkR8Vh12zrlXRSR9D2y3P/DksaQlYxHkP26Jvqcg6TlI2KWpAvJ4i8XRMTB5W/DyLy6LYDPRsTrTYzXUMb3Ib2wJ5K5WWsAT0XE6d23bftBtUC3UOl7yN56tYRKV7xAOwKfb5wrSbsBX42IbTotk+l/lPDWj5PXyqcj4sIejDGEvLdHktfbvaTB/tdtFLUVearvyRWKXPsCkyLi8bKN35MLwQphBylWjDtIN/afgDlkEvqfgR82Jni93MdKZNGEUzodR99uihf15Yg4rrJuT9I78nBEvGqP0rwsILz29agx30nSJ8jiJ/tU5BoK7EqGPTbdE2uwUMLB7yXDyD9WWT8VmBER365NuEWcEhJ4BXBMdOWiDCfDdJ+OSu7MYEbSLWQ17Eao6OtkH7FvRsQNZZvhrUS9lAnrhaRX8dqybizZXuDgiLirvUfRe/pTqLQyf/AKMlzxQNLgfFqnw1hN/6akbiwXJY+/h2MsR0YhzWk1sq1d+D3ZPharW4BBxseB4yPiQDI89EWyP43K514TES9FxMlRkr3bMWaNPEWGwVZZlazs9yrM0zR60FO8g8OAD0s6NLoauW5Ghm7VyS3kXG/DilzjSc+llcH5EBHPUcrZS7pL0gGSNiQr614J706eTfv5Jen5GS/pZ5I+GBF/iYhpVgaTEvL9FtlkflOyD9lHyWtzoqTLJK3Zg4niaNIj+G1J2wOUvKQXyRyofkdEPNAflEGAyGIm7yP/Dy+TYfpWBs08RMSbvVEGyxivRsTzdSmDRQa/J9uEPYQdQoOg+Eu7KZbOE8ly9veRnsE7yKqsf3QIQBcDIbxW0jFkeMlUMmR6D7Kg0u/7Q/hXf6WEg48nG2C/RXr/m64IZ3qO+ln11P5ECVGcSBZ6uTMi9quEOq9B5rVPayaMrBIq2qhcuSnZeH5t0gg4k2xdsXffHdGiR4nCWDYiXqpbFmP6Er8ne48Vwg6iRbj4S18h6SNkOe+PAM8Cd4SrRf0N/S28thIWOopMOB9NPqjXI5PRnwKejIirfN03R8khPIDMPb6TzBOq2/M7KOhPIYH9CUkbA2eRxqerSYv8Y1Gqg/ZgvPPJ4idXFGV8M4r1nzRuTfI1b4x5L/ye7DlWCDvMolj8pa8pxQmGkg1fG33rrERUkHQ42RftmMq6g8kmxd/ssCzv/m8kzQQmkz3KdiHbXhz/XtubhVOUk7F15oQaAyBpCzKM82HgODJk/XKyF9+fmhyj4R3cHjgG+BdgLlnF826yfP+2ZOG12cARfl8aYxaE35OtY4WwJhal4i+mfvpTeK2yXPy3SGPHTo0wr1JUaSpZQOmKTshijGkv6mojM54MAd+ETIc4H1idbEFxWrTQT7eMeyrZWuJZMvRrVzIHbgKpcG5ONr1+oF3HYowxJhnoRUcGLItY8RdTM6WQwA/I3oNnkzmE5xRlcLEOKoPjgFGRzY9XAd6QNKLI8AJwKdl/0xgzAKmEnX8W+BJphFqbNEh9iOx3enEzY3Ur9nADcAJwOlkdcCSpCG4WEe9ExJ1WBo0xpm/oXsHR1IDDX0w7iIhfS7odOIlKeC3QyTCAucDsUvJ5JvAqcCpwauldtD/wX9A/+ogZY1qn5MPfQYby7xwRm5RCMJcDl1YqCS+Qkju/BLAfGVr+LDA3ImZI2obMPZ5Q9unQcmOM6SPsmTJmESIiZkfEK9Vy0p2cREXElWSezx7kZPFIsiH90WTj6ukRcU3Z1sqgMQOQ0gbia2RF4+eKsWcp4IZmqop24/1k4bAzgZUjYkZZfwgwseQXLm5l0Bhj+g7nEBpj2oqk0eQkbydgQ+BY4KaImFXZxt5BYwY4pUjad8m+d/8AfCkirmtxjKWAfwS2IPMEXwamAI84v94YYzqDFUJjTJ8haQey+uDypNfwUVv6jVl0KAXS1geWi4gbWvzuyIh4sDLOlmQ0wWvA/hHxfLvlNcYY87dYITTG9DmSDgTOt8XfGAMgaR3gCTLv8OBKS6GJwMyImFqnfMYYM5hwDqExps+JiHNcUdcY0yAingKWBl4EHpP0LUljgH8Froe/qUJqjDGmj7CH0BhjjDF9TqWH4cHAMhExqawfCXyP7J96W0RMbmxbp7zGGDNYsEJojDHGmD6l0TZC0nCy8vD2EfFkVfGrFptymwljjOkcDt8yxhhjTJ9SUe52BO4ryuDQ4jEcKmkvsnVF9+2NMcb0MVYIjTHGGNMpbiEdgBtWGtiPB/aOiNk1ymWMMYOWIXULYIwxxpjBQUQ8J2kmcK6kqcBwsiXNBHCPUmOMqQPnEBpjjDGmTyhhoXMljQJGAaOBicB6wC7AU8CTEXGV8waNMaYe7CE0xhhjTNspCl4jLHQKMBn4K3AzcF5EfLku2YwxxnThHEJjjDHG9AXHS1pK0v7AQxExKSK+CGwBbCtp9+rG9g4aY0w9WCE0xhhjTFuRNA4YFRFzgFWANySNKDmCLwCXAmPqlNEYY0xihdAYY4wx7WYuMLsUjlkCeBU4Fdha0hhgf+BXkIVk6hLSGGOMFUJjjDHGtJmIuBKYTVYQHQocSTakPxrYE5geEdeUbV1V1BhjasRVRo0xxhjTdiSNQnkQ2QAAAsRJREFUBt4P7ARsCBwL3BQRsyrbuM2EMcbUjBVCY4wxxvQpknYAjgOWJ72Gj7qIjDHG9A+sEBpjjDGmI0g6EDg/It6qWxZjjDGJFUJjjDHGdBSHihpjTP/BCqExxhhjjDHGDFJcZdQYY4wxxhhjBilWCI0xxhhjjDFmkGKF0BhjjDHGGGMGKVYIjTHGmIKktyX9vrKs24MxVpD02fZLZ4wxxrQfF5UxxhhjCpJei4hleznGusDVEfGBFr+3eES83Zt9G2OMMa1iD6ExxhizACQtLulkSXdJminp4LJ+WUnTJd0r6Q+SditfmQisXzyMJ0saI+nqyng/lHRA+fykpGMl3QqMk7S+pOsk3SPpN5I27PTxGmOMGVwMqVsAY4wxph+xtKTfl89PRMQewIHAXyJic0lLArdJ+iXwDLBHRMyStApwh6SrgCOBD0TEJgCSxixkn3MiYpuy7XTgkIh4VNIWwOnAdu0+SGOMMaaBFUJjjDGmizcailyF7YEPStqr/D4ceB/wLHCipG2Bd4A1gNV6sM9LIT2OwNbATyQ1/rZkD8YzxhhjmsYKoTHGGLNgBHwhIq6fZ2WGfa4KbBYRb0l6ElhqPt//K/OmaHTf5vXyczHglfkopMYYY0yf4RxCY4wxZsFcDxwqaQkASRtIWob0FL5QlMEPA+uU7V8Flqt8/ylgpKQlJQ0Hxs5vJxExC3hC0riyH0nauG8OyRhjjEmsEBpjjDEL5sfAg8C9ku4HfkRG2FwEjJZ0N/BJ4CGAiHiRzDO8X9LJEfEMMA2YWb5z3wL29UngQEkzgAeA3RawrTHGGNNr3HbCGGOMMcYYYwYp9hAaY4wxxhhjzCDFCqExxhhjjDHGDFKsEBpjjDHGGGPMIMUKoTHGGGOMMcYMUqwQGmOMMcYYY8wgxQqhMcYYY4wxxgxSrBAaY4wxxhhjzCDl/wGWDnhNq3eVQAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mglearn\n",
    "\n",
    "mglearn.tools.visualize_coefficients(\n",
    "    log_reg_grid_search_p.best_estimator_.named_steps[\"clf\"].coef_,\n",
    "    feature_names, n_top_features=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observation:__ The negative coefficients on the left represent negative sentiments while the positive coefficients on the right represent positive sentiments. The negitive reviews have negative emotions and words, as one would expect, and shows anger, sadness and the content shows more comparisons. The positive reviews have positive emotions, showing affection and with emphasise on leisure and family. Again the sentiment analysis results show more clear distinctions than the deceptive opinion spam results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Combined TFIDF with LIWC Analysis__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>norm</th>\n",
       "      <th>WC</th>\n",
       "      <th>Analytic</th>\n",
       "      <th>Clout</th>\n",
       "      <th>Authentic</th>\n",
       "      <th>Tone</th>\n",
       "      <th>WPS</th>\n",
       "      <th>Sixltr</th>\n",
       "      <th>Dic</th>\n",
       "      <th>function</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>ppron</th>\n",
       "      <th>i</th>\n",
       "      <th>we</th>\n",
       "      <th>you</th>\n",
       "      <th>shehe</th>\n",
       "      <th>they</th>\n",
       "      <th>ipron</th>\n",
       "      <th>article</th>\n",
       "      <th>prep</th>\n",
       "      <th>auxverb</th>\n",
       "      <th>adverb</th>\n",
       "      <th>conj</th>\n",
       "      <th>negate</th>\n",
       "      <th>verb</th>\n",
       "      <th>adj</th>\n",
       "      <th>compare</th>\n",
       "      <th>interrog</th>\n",
       "      <th>number</th>\n",
       "      <th>quant</th>\n",
       "      <th>affect</th>\n",
       "      <th>posemo</th>\n",
       "      <th>negemo</th>\n",
       "      <th>anx</th>\n",
       "      <th>anger</th>\n",
       "      <th>sad</th>\n",
       "      <th>social</th>\n",
       "      <th>family</th>\n",
       "      <th>friend</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>cogproc</th>\n",
       "      <th>insight</th>\n",
       "      <th>cause</th>\n",
       "      <th>discrep</th>\n",
       "      <th>tentat</th>\n",
       "      <th>certain</th>\n",
       "      <th>differ</th>\n",
       "      <th>percept</th>\n",
       "      <th>see</th>\n",
       "      <th>hear</th>\n",
       "      <th>feel</th>\n",
       "      <th>bio</th>\n",
       "      <th>body</th>\n",
       "      <th>health</th>\n",
       "      <th>sexual</th>\n",
       "      <th>ingest</th>\n",
       "      <th>drives</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>achieve</th>\n",
       "      <th>power</th>\n",
       "      <th>reward</th>\n",
       "      <th>risk</th>\n",
       "      <th>focuspast</th>\n",
       "      <th>focuspresent</th>\n",
       "      <th>focusfuture</th>\n",
       "      <th>relativ</th>\n",
       "      <th>motion</th>\n",
       "      <th>space</th>\n",
       "      <th>time</th>\n",
       "      <th>work</th>\n",
       "      <th>leisure</th>\n",
       "      <th>home</th>\n",
       "      <th>money</th>\n",
       "      <th>relig</th>\n",
       "      <th>death</th>\n",
       "      <th>informal</th>\n",
       "      <th>swear</th>\n",
       "      <th>netspeak</th>\n",
       "      <th>assent</th>\n",
       "      <th>nonflu</th>\n",
       "      <th>filler</th>\n",
       "      <th>AllPunc</th>\n",
       "      <th>Period</th>\n",
       "      <th>Comma</th>\n",
       "      <th>Colon</th>\n",
       "      <th>SemiC</th>\n",
       "      <th>QMark</th>\n",
       "      <th>Exclam</th>\n",
       "      <th>Dash</th>\n",
       "      <th>Quote</th>\n",
       "      <th>Apostro</th>\n",
       "      <th>Parenth</th>\n",
       "      <th>OtherP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we stayed for a one night getaway with family ...</td>\n",
       "      <td>107</td>\n",
       "      <td>61.61</td>\n",
       "      <td>61.05</td>\n",
       "      <td>35.01</td>\n",
       "      <td>77.39</td>\n",
       "      <td>13.38</td>\n",
       "      <td>13.08</td>\n",
       "      <td>82.24</td>\n",
       "      <td>49.53</td>\n",
       "      <td>6.54</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>7.48</td>\n",
       "      <td>10.28</td>\n",
       "      <td>10.28</td>\n",
       "      <td>9.35</td>\n",
       "      <td>6.54</td>\n",
       "      <td>1.87</td>\n",
       "      <td>12.15</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.93</td>\n",
       "      <td>4.67</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.54</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.74</td>\n",
       "      <td>6.54</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.35</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.95</td>\n",
       "      <td>1.87</td>\n",
       "      <td>8.41</td>\n",
       "      <td>6.54</td>\n",
       "      <td>0.93</td>\n",
       "      <td>3.74</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.82</td>\n",
       "      <td>11.21</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>triple a rate with upgrade to view room was le...</td>\n",
       "      <td>44</td>\n",
       "      <td>97.59</td>\n",
       "      <td>41.03</td>\n",
       "      <td>19.82</td>\n",
       "      <td>94.75</td>\n",
       "      <td>8.80</td>\n",
       "      <td>29.55</td>\n",
       "      <td>77.27</td>\n",
       "      <td>31.82</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.27</td>\n",
       "      <td>6.82</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.55</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.82</td>\n",
       "      <td>13.64</td>\n",
       "      <td>6.82</td>\n",
       "      <td>2.27</td>\n",
       "      <td>2.27</td>\n",
       "      <td>6.82</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.27</td>\n",
       "      <td>6.82</td>\n",
       "      <td>6.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.27</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.64</td>\n",
       "      <td>2.27</td>\n",
       "      <td>11.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.55</td>\n",
       "      <td>6.82</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>11.36</td>\n",
       "      <td>9.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                norm   WC  Analytic  Clout  \\\n",
       "0  we stayed for a one night getaway with family ...  107     61.61  61.05   \n",
       "1  triple a rate with upgrade to view room was le...   44     97.59  41.03   \n",
       "\n",
       "   Authentic   Tone    WPS  Sixltr    Dic  function  pronoun  ppron     i  \\\n",
       "0      35.01  77.39  13.38   13.08  82.24     49.53     6.54   3.74  0.93   \n",
       "1      19.82  94.75   8.80   29.55  77.27     31.82     2.27   0.00  0.00   \n",
       "\n",
       "     we   you  shehe  they  ipron  article   prep  auxverb  adverb  conj  \\\n",
       "0  1.87  0.93    0.0   0.0   2.80     7.48  10.28    10.28    9.35  6.54   \n",
       "1  0.00  0.00    0.0   0.0   2.27     6.82  13.64     4.55    4.55  2.27   \n",
       "\n",
       "   negate   verb    adj  compare  interrog  number  quant  affect  posemo  \\\n",
       "0    1.87  12.15   3.74     0.00      0.00    4.67   0.93    4.67    3.74   \n",
       "1    0.00   6.82  13.64     6.82      2.27    2.27   6.82    4.55    4.55   \n",
       "\n",
       "   negemo  anx  anger  sad  social  family  friend  female  male  cogproc  \\\n",
       "0    0.93  0.0    0.0  0.0    6.54    0.93     0.0     0.0   0.0     5.61   \n",
       "1    0.00  0.0    0.0  0.0    0.00    0.00     0.0     0.0   0.0     4.55   \n",
       "\n",
       "   insight  cause  discrep  tentat  certain  differ  percept   see  hear  \\\n",
       "0      0.0    0.0     0.93    0.00     0.93    3.74     0.00  0.00   0.0   \n",
       "1      0.0    0.0     0.00    2.27     0.00    2.27     6.82  6.82   0.0   \n",
       "\n",
       "   feel   bio  body  health  sexual  ingest  drives  affiliation  achieve  \\\n",
       "0   0.0  3.74   0.0     0.0     0.0    3.74    6.54         3.74     0.93   \n",
       "1   0.0  4.55   0.0     0.0     0.0    4.55    4.55         0.00     0.00   \n",
       "\n",
       "   power  reward  risk  focuspast  focuspresent  focusfuture  relativ  motion  \\\n",
       "0   0.93    1.87   0.0       9.35          1.87          0.0    14.95    1.87   \n",
       "1   2.27    2.27   0.0       6.82          0.00          0.0    13.64    2.27   \n",
       "\n",
       "   space  time  work  leisure  home  money  relig  death  informal  swear  \\\n",
       "0   8.41  6.54  0.93     3.74  2.80   1.87    0.0    0.0       0.0    0.0   \n",
       "1  11.36  0.00  4.55     4.55  6.82   2.27    0.0    0.0       0.0    0.0   \n",
       "\n",
       "   netspeak  assent  nonflu  filler  AllPunc  Period  Comma  Colon  SemiC  \\\n",
       "0       0.0     0.0     0.0     0.0    16.82   11.21   1.87    0.0    0.0   \n",
       "1       0.0     0.0     0.0     0.0    25.00   11.36   9.09    0.0    0.0   \n",
       "\n",
       "   QMark  Exclam  Dash  Quote  Apostro  Parenth  OtherP  \n",
       "0    0.0     0.0   0.0      0      0.0     3.74    0.00  \n",
       "1    0.0     0.0   0.0      0      0.0     0.00    4.55  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotels_comb = pd.concat([hotels[\"norm\"], liwc], axis=1)\n",
    "hotels_comb.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. Choose input data and target__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hotels_comb\n",
    "y = hotels[\"deceptive\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. Split data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_train_test_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3. Build pipeline__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4. Construct parameters for cross validation testing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemExcluder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_frame):\n",
    "        #df = data_frame.loc[:, data_frame.columns != self.key]\n",
    "        df = data_frame.drop([self.key], axis=1)\n",
    "        return df\n",
    "    \n",
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_frame):\n",
    "        df = data_frame[self.key]\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_combined = [\n",
    "    ('preprocess', FeatureUnion(\n",
    "        transformer_list=[\n",
    "            ('terms', Pipeline([\n",
    "                ('selector', ItemSelector(key='norm')),\n",
    "                ('vect', CountVectorizer()),                \n",
    "                ('tfidf', TfidfTransformer())\n",
    "            ])),\n",
    "            ('liwc', Pipeline([\n",
    "                ('selector', ItemExcluder(key='norm')),     \n",
    "                ('scale', StandardScaler())\n",
    "            ]))                        \n",
    "        ]    \n",
    "    )),        \n",
    "    ('clf', LogisticRegression())\n",
    "]\n",
    "\n",
    "pipe_comb = Pipeline(steps_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_comb = [\n",
    "    {'preprocess__terms__vect__stop_words': ['english', None],\n",
    "        'preprocess__terms__vect__min_df': [1, 2, 5], \n",
    "        'preprocess__terms__vect__ngram_range': [(1, 1), (1, 2), (1, 3)],     \n",
    "         'clf__C': [0.1, 1, 10, 100, 1000]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 116.153s\n",
      "best params:\n",
      "{'clf__C': 100, 'preprocess__terms__vect__min_df': 5, 'preprocess__terms__vect__ngram_range': (1, 3), 'preprocess__terms__vect__stop_words': 'english'}\n",
      "Best cross-validation score: 0.867\n",
      "Test-set score: 0.865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "lr_lwic_comb_grid_search = apply_grid_search_cv(pipe_comb, param_grid_comb, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__6. Save Reports to File__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   clf__C preprocess__terms__vect__min_df  \\\n",
      "71    100                               5   \n",
      "89   1000                               5   \n",
      "87   1000                               5   \n",
      "69    100                               5   \n",
      "83   1000                               2   \n",
      "81   1000                               2   \n",
      "\n",
      "   preprocess__terms__vect__ngram_range preprocess__terms__vect__stop_words  \\\n",
      "71                               (1, 3)                             english   \n",
      "89                               (1, 3)                             english   \n",
      "87                               (1, 2)                             english   \n",
      "69                               (1, 2)                             english   \n",
      "83                               (1, 3)                             english   \n",
      "81                               (1, 2)                             english   \n",
      "\n",
      "   mean_test_score std_test_score rank_test_score mean_fit_time  \n",
      "71        0.866701      0.0181484               1       1.37046  \n",
      "89        0.865373      0.0158239               2       1.27343  \n",
      "87        0.861831      0.0146131               3      0.880845  \n",
      "69        0.860949      0.0201591               4         0.861  \n",
      "83        0.860019      0.0215652               5        1.4581  \n",
      "81        0.859001      0.0205455               6       1.30457  \n"
     ]
    }
   ],
   "source": [
    "save_cross_validation_results(lr_lwic_comb_grid_search, \"output/lr_lwic_comb1_validation_res.csv\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>truthful</th>\n",
       "      <td>0.860169</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.845833</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deceptive</th>\n",
       "      <td>0.864754</td>\n",
       "      <td>0.850806</td>\n",
       "      <td>0.879167</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.862462</td>\n",
       "      <td>0.862903</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.862462</td>\n",
       "      <td>0.862903</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1-score  precision    recall  support\n",
       "truthful      0.860169   0.875000  0.845833    240.0\n",
       "deceptive     0.864754   0.850806  0.879167    240.0\n",
       "micro avg     0.862500   0.862500  0.862500    480.0\n",
       "macro avg     0.862462   0.862903  0.862500    480.0\n",
       "weighted avg  0.862462   0.862903  0.862500    480.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_class_report_cv(lr_lwic_comb_grid_search, X_test, y_test, [\"truthful\", \"deceptive\"], \"output/lr_lwic_comb1_report.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__7. Save model to file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['output/lr_lwic_comb1.pkl']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(lr_lwic_comb_grid_search.best_estimator_, 'output/lr_lwic_comb1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__8. Sentiment__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 98.879s\n",
      "best params:\n",
      "{'clf__C': 1000, 'preprocess__terms__vect__min_df': 5, 'preprocess__terms__vect__ngram_range': (1, 3), 'preprocess__terms__vect__stop_words': 'english'}\n",
      "Best cross-validation score: 0.920\n",
      "Test-set score: 0.920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "y = hotels[\"polarity\"]\n",
    "X_train, X_test, y_train, y_test = split_train_test_data(X, y)\n",
    "lr_lwic_comb_grid_search_p = apply_grid_search_cv(pipe_comb, param_grid_comb, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   clf__C preprocess__terms__vect__min_df  \\\n",
      "89   1000                               5   \n",
      "87   1000                               5   \n",
      "79   1000                               2   \n",
      "88   1000                               5   \n",
      "90   1000                               5   \n",
      "71    100                               5   \n",
      "\n",
      "   preprocess__terms__vect__ngram_range preprocess__terms__vect__stop_words  \\\n",
      "89                               (1, 3)                             english   \n",
      "87                               (1, 2)                             english   \n",
      "79                               (1, 1)                             english   \n",
      "88                               (1, 2)                                None   \n",
      "90                               (1, 3)                                None   \n",
      "71                               (1, 3)                             english   \n",
      "\n",
      "   mean_test_score std_test_score rank_test_score mean_fit_time  \n",
      "89        0.919895      0.0168727               1       1.21976  \n",
      "87        0.918279      0.0187185               2      0.939812  \n",
      "79        0.918046       0.012898               3      0.800679  \n",
      "88        0.917283      0.0103262               4       1.18835  \n",
      "90        0.915458      0.0132448               5       1.65491  \n",
      "71        0.915398      0.0165093               6       1.22889  \n"
     ]
    }
   ],
   "source": [
    "save_cross_validation_results(lr_lwic_comb_grid_search_p, \"output/lr_lwic_comb1_validation_res_sent.csv\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Susan\\Anaconda3\\envs\\thesis\\lib\\site-packages\\sklearn\\pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>0.917895</td>\n",
       "      <td>0.927660</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.919588</td>\n",
       "      <td>0.910204</td>\n",
       "      <td>0.929167</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.918750</td>\n",
       "      <td>0.918750</td>\n",
       "      <td>0.918750</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.918741</td>\n",
       "      <td>0.918932</td>\n",
       "      <td>0.918750</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.918741</td>\n",
       "      <td>0.918932</td>\n",
       "      <td>0.918750</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1-score  precision    recall  support\n",
       "negative      0.917895   0.927660  0.908333    240.0\n",
       "positive      0.919588   0.910204  0.929167    240.0\n",
       "micro avg     0.918750   0.918750  0.918750    480.0\n",
       "macro avg     0.918741   0.918932  0.918750    480.0\n",
       "weighted avg  0.918741   0.918932  0.918750    480.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_class_report_cv(lr_lwic_comb_grid_search_p, X_test, y_test, [\"negative\", \"positive\"], \"output/lr_lwic_comb1_report_sent.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thesis]",
   "language": "python",
   "name": "conda-env-thesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
