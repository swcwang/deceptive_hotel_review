{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Bayes Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn import decomposition\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.utils.multiclass import unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels=pd.read_csv(\"data/reviews_mod5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels = hotels.drop(hotels.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Function Definitions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_data(input_data, target, ratio=0.3, rand_state=42):\n",
    "    return train_test_split(input_data, target, test_size=ratio, stratify=target, random_state=rand_state)\n",
    "\n",
    "def apply_grid_search_cv(pipe, param_grid, X_train, y_train, X_test, y_test, print_flag=True, score_matrix=f1_score, n_jobs=-1, cv=5):\n",
    "    grid_search = GridSearchCV(pipe, param_grid=param_grid, scoring=make_scorer(score_matrix), n_jobs=n_jobs, cv=cv)\n",
    "    t0 = time()\n",
    "    res = grid_search.fit(X_train, y_train)\n",
    "    if print_flag:\n",
    "        print(\"done in %0.3fs\" % (time() - t0))\n",
    "        print(\"best params:\")\n",
    "        print(res.best_params_)\n",
    "        print(\"Best cross-validation score: {:.3f}\".format(grid_search.best_score_))\n",
    "        print(\"Test-set score: {:.3f}\".format(grid_search.score(X_test, y_test)))        \n",
    "    return grid_search\n",
    "\n",
    "def save_class_report_cv(grid_search, X_test, y_test, target_names, filename):\n",
    "    y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    df.to_csv(filename)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cross_validation_results(grid_search, filename, print_flag=True):\n",
    "    param_keys = list(grid_search.cv_results_[\"params\"][0].keys())\n",
    "    matrix_list = [\"mean_test_score\", \"std_test_score\", \"rank_test_score\", \"mean_fit_time\"] \n",
    "    col = param_keys + matrix_list\n",
    "\n",
    "    cv_results = []\n",
    "    cv_results.append(col)    \n",
    "    \n",
    "    for param, score, std, rank, time in zip(grid_search.cv_results_[\"params\"], grid_search.cv_results_[\"mean_test_score\"],grid_search.cv_results_[\"std_test_score\"],\n",
    "                                             grid_search.cv_results_[\"rank_test_score\"], grid_search.cv_results_[\"mean_fit_time\"]):\n",
    "        row_item = list(param.values())\n",
    "        row_item.append(score)\n",
    "        row_item.append(std)\n",
    "        row_item.append(rank)\n",
    "        row_item.append(time)\n",
    "        cv_results.append(row_item)        \n",
    "    cv_results = pd.DataFrame(cv_results) \n",
    "    header = cv_results.iloc[0] \n",
    "    cv_results = cv_results[1:]\n",
    "    cv_results = cv_results.rename(columns = header)\n",
    "    cv_results = cv_results.sort_values(by=['rank_test_score'])\n",
    "    cv_results.to_csv(filename)\n",
    "    if print_flag:\n",
    "        print(cv_results.head(6))\n",
    "        print(cv_results.tail(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. Choose input data and target__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hotels[\"norm\"]\n",
    "y = hotels[\"deceptive\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. Split data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_train_test_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3. Build pipeline__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "]\n",
    "\n",
    "pipe = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4. Construct parameters for cross validation testing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'vect__stop_words': ['english', None],\n",
    "        'vect__min_df': [1, 2, 5], \n",
    "        'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "        'clf__alpha': (1, 1e-2, 1e-3)}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__5. Apply Grid Serach CV__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 54.964s\n",
      "best params:\n",
      "{'clf__alpha': 0.01, 'vect__min_df': 2, 'vect__ngram_range': (1, 3), 'vect__stop_words': None}\n",
      "Best cross-validation score: 0.883\n",
      "Test-set score: 0.888\n"
     ]
    }
   ],
   "source": [
    "nb_grid_search = apply_grid_search_cv(pipe, param_grid, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__6. Save Classification Report to File__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   clf__alpha vect__min_df vect__ngram_range vect__stop_words mean_test_score  \\\n",
      "30       0.01            2            (1, 3)             None        0.883126   \n",
      "16          1            5            (1, 2)             None        0.881645   \n",
      "11          1            2            (1, 3)          english        0.881515   \n",
      "12          1            2            (1, 3)             None        0.880358   \n",
      "9           1            2            (1, 2)          english        0.879127   \n",
      "22       0.01            1            (1, 2)             None        0.879048   \n",
      "\n",
      "   std_test_score rank_test_score mean_fit_time  \n",
      "30      0.0173371               1       1.89402  \n",
      "16      0.0128866               2      0.934683  \n",
      "11      0.0318756               3       1.14633  \n",
      "12      0.0176003               4       1.94367  \n",
      "9       0.0184544               5      0.608048  \n",
      "22      0.0148647               6      0.892472  \n",
      "   clf__alpha vect__min_df vect__ngram_range vect__stop_words mean_test_score  \\\n",
      "20       0.01            1            (1, 1)             None        0.826961   \n",
      "44      0.001            2            (1, 1)             None        0.821368   \n",
      "19       0.01            1            (1, 1)          english        0.816355   \n",
      "43      0.001            2            (1, 1)          english        0.808165   \n",
      "38      0.001            1            (1, 1)             None        0.785655   \n",
      "37      0.001            1            (1, 1)          english        0.778152   \n",
      "\n",
      "   std_test_score rank_test_score mean_fit_time  \n",
      "20      0.0379792              49      0.260723  \n",
      "44      0.0336247              50      0.252099  \n",
      "19      0.0291943              51      0.329408  \n",
      "43      0.0267183              52      0.265309  \n",
      "38      0.0455836              53      0.269695  \n",
      "37      0.0400203              54      0.277675  \n"
     ]
    }
   ],
   "source": [
    "save_cross_validation_results(nb_grid_search, \"output/nb_norm1_validation_res.csv\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>truthful</th>\n",
       "      <td>0.883227</td>\n",
       "      <td>0.900433</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deceptive</th>\n",
       "      <td>0.887526</td>\n",
       "      <td>0.871486</td>\n",
       "      <td>0.904167</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.885376</td>\n",
       "      <td>0.885959</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.885376</td>\n",
       "      <td>0.885959</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1-score  precision    recall  support\n",
       "truthful      0.883227   0.900433  0.866667    240.0\n",
       "deceptive     0.887526   0.871486  0.904167    240.0\n",
       "micro avg     0.885417   0.885417  0.885417    480.0\n",
       "macro avg     0.885376   0.885959  0.885417    480.0\n",
       "weighted avg  0.885376   0.885959  0.885417    480.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_class_report_cv(nb_grid_search, X_test, y_test, [\"truthful\", \"deceptive\"], \"output/nb_norm1_report.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__7. Save model to file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['output/nb_norm1.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(nb_grid_search.best_estimator_, 'output/nb_norm1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__8. Sentiment Analysis__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 55.699s\n",
      "best params:\n",
      "{'clf__alpha': 0.01, 'vect__min_df': 1, 'vect__ngram_range': (1, 3), 'vect__stop_words': None}\n",
      "Best cross-validation score: 0.956\n",
      "Test-set score: 0.958\n"
     ]
    }
   ],
   "source": [
    "y = hotels[\"polarity\"]\n",
    "X_train, X_test, y_train, y_test = split_train_test_data(X, y)\n",
    "nb_grid_search_p = apply_grid_search_cv(pipe, param_grid, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   clf__alpha vect__min_df vect__ngram_range vect__stop_words mean_test_score  \\\n",
      "30       0.01            2            (1, 3)             None        0.883126   \n",
      "16          1            5            (1, 2)             None        0.881645   \n",
      "11          1            2            (1, 3)          english        0.881515   \n",
      "12          1            2            (1, 3)             None        0.880358   \n",
      "9           1            2            (1, 2)          english        0.879127   \n",
      "22       0.01            1            (1, 2)             None        0.879048   \n",
      "\n",
      "   std_test_score rank_test_score mean_fit_time  \n",
      "30      0.0173371               1       1.89402  \n",
      "16      0.0128866               2      0.934683  \n",
      "11      0.0318756               3       1.14633  \n",
      "12      0.0176003               4       1.94367  \n",
      "9       0.0184544               5      0.608048  \n",
      "22      0.0148647               6      0.892472  \n",
      "   clf__alpha vect__min_df vect__ngram_range vect__stop_words mean_test_score  \\\n",
      "20       0.01            1            (1, 1)             None        0.826961   \n",
      "44      0.001            2            (1, 1)             None        0.821368   \n",
      "19       0.01            1            (1, 1)          english        0.816355   \n",
      "43      0.001            2            (1, 1)          english        0.808165   \n",
      "38      0.001            1            (1, 1)             None        0.785655   \n",
      "37      0.001            1            (1, 1)          english        0.778152   \n",
      "\n",
      "   std_test_score rank_test_score mean_fit_time  \n",
      "20      0.0379792              49      0.260723  \n",
      "44      0.0336247              50      0.252099  \n",
      "19      0.0291943              51      0.329408  \n",
      "43      0.0267183              52      0.265309  \n",
      "38      0.0455836              53      0.269695  \n",
      "37      0.0400203              54      0.277675  \n"
     ]
    }
   ],
   "source": [
    "save_cross_validation_results(nb_grid_search, \"output/nb_norm1_validation_res_sent.csv\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>480.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              f1-score  precision    recall  support\n",
       "negative      0.958333   0.958333  0.958333    240.0\n",
       "positive      0.958333   0.958333  0.958333    240.0\n",
       "micro avg     0.958333   0.958333  0.958333    480.0\n",
       "macro avg     0.958333   0.958333  0.958333    480.0\n",
       "weighted avg  0.958333   0.958333  0.958333    480.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_class_report_cv(nb_grid_search_p, X_test, y_test, [\"negative\", \"positive\"], \"output/nb_norm1_report_sent.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['output/nb_norm1_sent.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(nb_grid_search.best_estimator_, 'output/nb_norm1_sent.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:thesis]",
   "language": "python",
   "name": "conda-env-thesis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
